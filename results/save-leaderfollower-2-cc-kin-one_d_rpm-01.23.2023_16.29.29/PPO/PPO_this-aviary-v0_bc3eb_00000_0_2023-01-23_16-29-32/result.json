{"episode_reward_max": -14.226175436926018, "episode_reward_min": -490.71693732685355, "episode_reward_mean": -80.015642618673, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -438.1833810648422, "pol1": -57.19919073988645}, "policy_reward_max": {"pol0": -10.800807330783492, "pol1": -0.05491852711279488}, "policy_reward_mean": {"pol0": -66.44361624628993, "pol1": -13.572026372383052}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.01548748507665, -94.67733542599869, -14.226175436926018, -42.558036067673335, -79.68116631998726, -48.86852461282289, -191.51413392450658, -16.570420779623355, -24.902132224158514, -39.11426658999418, -25.7732076911894, -64.69628234089963, -58.22596247303097, -490.71693732685355, -31.858078151506305, -55.029219425881735, -31.838558241311752], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-49.96056895796385, -37.47814468611221, -10.800807330783492, -40.15922255840221, -40.76533620848645, -47.25920721999152, -190.60447904749674, -15.83918885674793, -23.697145141565713, -35.388148247570086, -19.74956847828619, -38.20923374260108, -44.0425358869718, -438.1833810648422, -16.714744910751683, -50.984188555070666, -29.705575293285094], "policy_pol1_reward": [-0.05491852711279488, -57.19919073988645, -3.425368106142528, -2.398813509271128, -38.915830111500824, -1.6093173928313405, -0.9096548770099148, -0.7312319228754252, -1.2049870825927815, -3.726118342424103, -6.023639212903209, -26.487048598298568, -14.183426586059174, -52.53355626201131, -15.143333240754616, -4.045030870811055, -2.1329829480266707]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18429420118922885, "mean_inference_ms": 0.6581561968074534, "mean_action_processing_ms": 0.045035908028103165, "mean_env_wait_ms": 0.28426035930869936, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 4114, "timesteps_this_iter": 0, "agent_timesteps_total": 8228, "timers": {"sample_time_ms": 4833.058, "sample_throughput": 851.221, "load_time_ms": 0.155, "load_throughput": 26587621.966, "learn_time_ms": 5210.152, "learn_throughput": 789.612}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2010.3590252171502, "policy_loss": -0.00492072002380155, "vf_loss": 2010.3627073869886, "vf_explained_var": -0.040942200397451715, "kl": 0.006213317358888896, "entropy": 1.4244209937751293, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 61.56525522454273, "policy_loss": 0.0009625033630679051, "vf_loss": 61.5638992774467, "vf_explained_var": -0.18347242946426073, "kl": 0.001967921480665306, "entropy": 1.415144389246901, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4114, "num_agent_steps_sampled": 8228, "num_steps_trained": 4114, "num_agent_steps_trained": 8228}, "done": false, "episodes_total": 17, "training_iteration": 1, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-29-46", "timestamp": 1674487786, "time_this_iter_s": 10.040546178817749, "time_total_s": 10.040546178817749, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x17f53f430>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29d29e040>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10.040546178817749, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 20.71333333333333, "ram_util_percent": 64.34666666666665}}
{"episode_reward_max": -14.226175436926018, "episode_reward_min": -1321.533513153415, "episode_reward_mean": -135.00560872749543, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -1313.7251470117892, "pol1": -57.19919073988645}, "policy_reward_max": {"pol0": -10.800807330783492, "pol1": -0.05491852711279488}, "policy_reward_mean": {"pol0": -126.3034191370309, "pol1": -8.702189590464537}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.01548748507665, -94.67733542599869, -14.226175436926018, -42.558036067673335, -79.68116631998726, -48.86852461282289, -191.51413392450658, -16.570420779623355, -24.902132224158514, -39.11426658999418, -25.7732076911894, -64.69628234089963, -58.22596247303097, -490.71693732685355, -31.858078151506305, -55.029219425881735, -31.838558241311752, -47.30850210043588, -66.60325371818172, -38.07445553023889, -40.701191409781735, -148.50816062376614, -1321.533513153415, -27.445564205094396, -39.44343352684541, -20.742573973228104, -29.161566254975554, -1260.5381371224894, -14.856551349096696, -21.539688507011654, -26.46225148415061, -36.68476526527157, -63.46360193020492, -26.857562063215457], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-49.96056895796385, -37.47814468611221, -10.800807330783492, -40.15922255840221, -40.76533620848645, -47.25920721999152, -190.60447904749674, -15.83918885674793, -23.697145141565713, -35.388148247570086, -19.74956847828619, -38.20923374260108, -44.0425358869718, -438.1833810648422, -16.714744910751683, -50.984188555070666, -29.705575293285094, -43.040442632227936, -65.57858250669476, -37.86486000421813, -35.96875845134827, -135.98543760118739, -1313.7251470117892, -20.13566499524812, -38.90310933548619, -15.073511693338666, -24.890460623001275, -1255.5114690318492, -13.757626797455098, -21.34302835493289, -22.136092052706108, -34.828948759863515, -61.49013994140101, -24.54149467937317], "policy_pol1_reward": [-0.05491852711279488, -57.19919073988645, -3.425368106142528, -2.398813509271128, -38.915830111500824, -1.6093173928313405, -0.9096548770099148, -0.7312319228754252, -1.2049870825927815, -3.726118342424103, -6.023639212903209, -26.487048598298568, -14.183426586059174, -52.53355626201131, -15.143333240754616, -4.045030870811055, -2.1329829480266707, -4.268059468207969, -1.0246712114869645, -0.20959552602075648, -4.732432958433444, -12.522723022578775, -7.808366141626132, -7.30989920984627, -0.5403241913592334, -5.66906227988944, -4.271105631974293, -5.026668090639994, -1.098924551641597, -0.19666015207875964, -4.326159431444483, -1.85581650540804, -1.9734619888039284, -2.3160673838422934]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18535700199706268, "mean_inference_ms": 0.6579577682755513, "mean_action_processing_ms": 0.04504542411772812, "mean_env_wait_ms": 0.28314817784200086, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 8228, "timesteps_this_iter": 0, "agent_timesteps_total": 16456, "timers": {"sample_time_ms": 7439.402, "sample_throughput": 553.001, "load_time_ms": 0.164, "load_throughput": 25098715.136, "learn_time_ms": 5189.558, "learn_throughput": 792.746}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 30653.376413083217, "policy_loss": -0.0026720091855774323, "vf_loss": 30653.378301503944, "vf_explained_var": -0.28986226016034683, "kl": 0.0033797933805544745, "entropy": 1.420804926753044, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6104644065121345, "policy_loss": -0.007182156480848789, "vf_loss": 2.6172931839653755, "vf_explained_var": -0.47690155350913604, "kl": 0.003533903836493361, "entropy": 1.416455744827787, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8228, "num_agent_steps_sampled": 16456, "num_steps_trained": 8228, "num_agent_steps_trained": 16456, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 34, "training_iteration": 2, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-29-56", "timestamp": 1674487796, "time_this_iter_s": 9.99387812614441, "time_total_s": 20.034424304962158, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d29e0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29d28b9d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20.034424304962158, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 19.821428571428573, "ram_util_percent": 64.37857142857142}}
{"episode_reward_max": -14.226175436926018, "episode_reward_min": -1321.533513153415, "episode_reward_mean": -103.50090663083752, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -1313.7251470117892, "pol1": -65.43603566664521}, "policy_reward_max": {"pol0": -10.228412499273057, "pol1": -0.05491852711279488}, "policy_reward_mean": {"pol0": -93.89909477035216, "pol1": -9.601811860485379}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.01548748507665, -94.67733542599869, -14.226175436926018, -42.558036067673335, -79.68116631998726, -48.86852461282289, -191.51413392450658, -16.570420779623355, -24.902132224158514, -39.11426658999418, -25.7732076911894, -64.69628234089963, -58.22596247303097, -490.71693732685355, -31.858078151506305, -55.029219425881735, -31.838558241311752, -47.30850210043588, -66.60325371818172, -38.07445553023889, -40.701191409781735, -148.50816062376614, -1321.533513153415, -27.445564205094396, -39.44343352684541, -20.742573973228104, -29.161566254975554, -1260.5381371224894, -14.856551349096696, -21.539688507011654, -26.46225148415061, -36.68476526527157, -63.46360193020492, -26.857562063215457, -15.59737507972919, -16.469202578510412, -71.93451902900229, -40.74220064375983, -49.02234555470557, -28.227946429951626, -24.78647007704585, -112.57519771569754, -40.121820253577994, -42.15175242123618, -40.25458613338343, -38.03275039515272, -27.98465929492658, -22.274633944551635, -22.561311868963948, -60.32565054528134, -35.29311947239411], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-49.96056895796385, -37.47814468611221, -10.800807330783492, -40.15922255840221, -40.76533620848645, -47.25920721999152, -190.60447904749674, -15.83918885674793, -23.697145141565713, -35.388148247570086, -19.74956847828619, -38.20923374260108, -44.0425358869718, -438.1833810648422, -16.714744910751683, -50.984188555070666, -29.705575293285094, -43.040442632227936, -65.57858250669476, -37.86486000421813, -35.96875845134827, -135.98543760118739, -1313.7251470117892, -20.13566499524812, -38.90310933548619, -15.073511693338666, -24.890460623001275, -1255.5114690318492, -13.757626797455098, -21.34302835493289, -22.136092052706108, -34.828948759863515, -61.49013994140101, -24.54149467937317, -14.778542574845378, -10.228412499273057, -71.56352681309278, -33.386920670969886, -42.684023152887484, -24.308599982923905, -11.935194965111927, -47.13916204905232, -30.35932120895931, -37.16233487987682, -37.44539942246539, -26.999400154644718, -15.760834409439035, -16.931777298117137, -18.242013211621725, -23.07691302476889, -32.535206310860474], "policy_pol1_reward": [-0.05491852711279488, -57.19919073988645, -3.425368106142528, -2.398813509271128, -38.915830111500824, -1.6093173928313405, -0.9096548770099148, -0.7312319228754252, -1.2049870825927815, -3.726118342424103, -6.023639212903209, -26.487048598298568, -14.183426586059174, -52.53355626201131, -15.143333240754616, -4.045030870811055, -2.1329829480266707, -4.268059468207969, -1.0246712114869645, -0.20959552602075648, -4.732432958433444, -12.522723022578775, -7.808366141626132, -7.30989920984627, -0.5403241913592334, -5.66906227988944, -4.271105631974293, -5.026668090639994, -1.098924551641597, -0.19666015207875964, -4.326159431444483, -1.85581650540804, -1.9734619888039284, -2.3160673838422934, -0.818832504883821, -6.240790079237342, -0.3709922159095311, -7.355279972789995, -6.338322401818093, -3.9193464470277357, -12.85127511193391, -65.43603566664521, -9.7624990446187, -4.989417541359367, -2.8091867109180337, -11.033350240507994, -12.223824885487542, -5.342856646434507, -4.319298657342211, -37.248737520512464, -2.75791316153362]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18542374208023282, "mean_inference_ms": 0.6575584319183744, "mean_action_processing_ms": 0.04499860922588024, "mean_env_wait_ms": 0.28226479164926693, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 12342, "timesteps_this_iter": 0, "agent_timesteps_total": 24684, "timers": {"sample_time_ms": 8280.554, "sample_throughput": 496.827, "load_time_ms": 0.163, "load_throughput": 25301124.129, "learn_time_ms": 5150.681, "learn_throughput": 798.729}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 51.56483970781167, "policy_loss": -0.0028751169797033072, "vf_loss": 51.56739561756452, "vf_explained_var": -0.3613118070488175, "kl": 0.0031927337582336197, "entropy": 1.3648497102161248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 35.30131497138961, "policy_loss": -0.0013995262561365962, "vf_loss": 35.30238828083384, "vf_explained_var": -0.3626072800407807, "kl": 0.006514543517490286, "entropy": 1.4152966247250636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12342, "num_agent_steps_sampled": 24684, "num_steps_trained": 12342, "num_agent_steps_trained": 24684, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 51, "training_iteration": 3, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-30-06", "timestamp": 1674487806, "time_this_iter_s": 9.855791091918945, "time_total_s": 29.890215396881104, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d770940>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x17f2cf940>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 29.890215396881104, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 19.964285714285715, "ram_util_percent": 64.37857142857142}}
{"episode_reward_max": -14.226175436926018, "episode_reward_min": -1321.533513153415, "episode_reward_mean": -97.85826156105242, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -1313.7251470117892, "pol1": -88.76250869789135}, "policy_reward_max": {"pol0": -10.228412499273057, "pol1": -0.05491852711279488}, "policy_reward_mean": {"pol0": -85.74569154627385, "pol1": -12.112570014778584}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.01548748507665, -94.67733542599869, -14.226175436926018, -42.558036067673335, -79.68116631998726, -48.86852461282289, -191.51413392450658, -16.570420779623355, -24.902132224158514, -39.11426658999418, -25.7732076911894, -64.69628234089963, -58.22596247303097, -490.71693732685355, -31.858078151506305, -55.029219425881735, -31.838558241311752, -47.30850210043588, -66.60325371818172, -38.07445553023889, -40.701191409781735, -148.50816062376614, -1321.533513153415, -27.445564205094396, -39.44343352684541, -20.742573973228104, -29.161566254975554, -1260.5381371224894, -14.856551349096696, -21.539688507011654, -26.46225148415061, -36.68476526527157, -63.46360193020492, -26.857562063215457, -15.59737507972919, -16.469202578510412, -71.93451902900229, -40.74220064375983, -49.02234555470557, -28.227946429951626, -24.78647007704585, -112.57519771569754, -40.121820253577994, -42.15175242123618, -40.25458613338343, -38.03275039515272, -27.98465929492658, -22.274633944551635, -22.561311868963948, -60.32565054528134, -35.29311947239411, -25.393092627216596, -51.751444689562035, -21.787642778869053, -31.414773748965406, -26.7553802822598, -55.90468508454374, -36.39900957464616, -542.594865147139, -84.48587118912901, -17.46641418459061, -33.739759302464606, -40.04786763046796, -194.10892418505006, -95.36939902117815, -45.93220976772157, -31.475096926005563, -41.18911183904083], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-49.96056895796385, -37.47814468611221, -10.800807330783492, -40.15922255840221, -40.76533620848645, -47.25920721999152, -190.60447904749674, -15.83918885674793, -23.697145141565713, -35.388148247570086, -19.74956847828619, -38.20923374260108, -44.0425358869718, -438.1833810648422, -16.714744910751683, -50.984188555070666, -29.705575293285094, -43.040442632227936, -65.57858250669476, -37.86486000421813, -35.96875845134827, -135.98543760118739, -1313.7251470117892, -20.13566499524812, -38.90310933548619, -15.073511693338666, -24.890460623001275, -1255.5114690318492, -13.757626797455098, -21.34302835493289, -22.136092052706108, -34.828948759863515, -61.49013994140101, -24.54149467937317, -14.778542574845378, -10.228412499273057, -71.56352681309278, -33.386920670969886, -42.684023152887484, -24.308599982923905, -11.935194965111927, -47.13916204905232, -30.35932120895931, -37.16233487987682, -37.44539942246539, -26.999400154644718, -15.760834409439035, -16.931777298117137, -18.242013211621725, -23.07691302476889, -32.535206310860474, -23.430546771606178, -46.113363263436504, -19.951409338126986, -26.595446091460417, -12.562945285165933, -22.10440668435401, -23.764753878500294, -540.1022877212662, -34.17179836805838, -17.279768306283525, -16.538174859439216, -39.82733682217074, -105.34641548715862, -39.66822137291833, -19.67500826465795, -25.59606377305552, -29.12524557100195], "policy_pol1_reward": [-0.05491852711279488, -57.19919073988645, -3.425368106142528, -2.398813509271128, -38.915830111500824, -1.6093173928313405, -0.9096548770099148, -0.7312319228754252, -1.2049870825927815, -3.726118342424103, -6.023639212903209, -26.487048598298568, -14.183426586059174, -52.53355626201131, -15.143333240754616, -4.045030870811055, -2.1329829480266707, -4.268059468207969, -1.0246712114869645, -0.20959552602075648, -4.732432958433444, -12.522723022578775, -7.808366141626132, -7.30989920984627, -0.5403241913592334, -5.66906227988944, -4.271105631974293, -5.026668090639994, -1.098924551641597, -0.19666015207875964, -4.326159431444483, -1.85581650540804, -1.9734619888039284, -2.3160673838422934, -0.818832504883821, -6.240790079237342, -0.3709922159095311, -7.355279972789995, -6.338322401818093, -3.9193464470277357, -12.85127511193391, -65.43603566664521, -9.7624990446187, -4.989417541359367, -2.8091867109180337, -11.033350240507994, -12.223824885487542, -5.342856646434507, -4.319298657342211, -37.248737520512464, -2.75791316153362, -1.9625458556104411, -5.638081426125553, -1.8362334407420822, -4.819327657504991, -14.192434997093859, -33.80027840018973, -12.63425569614588, -2.492577425872742, -50.314072821070646, -0.18664587830709192, -17.201584443025364, -0.2205308082972369, -88.76250869789135, -55.70117764825989, -26.25720150306359, -5.87903315295006, -12.063866268038865]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18550024859565384, "mean_inference_ms": 0.6574606445101044, "mean_action_processing_ms": 0.04497894355885082, "mean_env_wait_ms": 0.28154643996082107, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 16456, "timesteps_this_iter": 0, "agent_timesteps_total": 32912, "timers": {"sample_time_ms": 8682.254, "sample_throughput": 473.84, "load_time_ms": 0.159, "load_throughput": 25879815.007, "learn_time_ms": 5149.872, "learn_throughput": 798.855}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 2521.331795288374, "policy_loss": -0.0063534809150345, "vf_loss": 2521.337589353323, "vf_explained_var": -0.12476619978745779, "kl": 0.010830542401041992, "entropy": 1.3645319605867068, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 77.72349269144858, "policy_loss": -0.007220692303963006, "vf_loss": 77.72960740715887, "vf_explained_var": -0.3408776918426156, "kl": 0.02212466870356972, "entropy": 1.4271209622422854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16456, "num_agent_steps_sampled": 32912, "num_steps_trained": 16456, "num_agent_steps_trained": 32912, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 68, "training_iteration": 4, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-30-16", "timestamp": 1674487816, "time_this_iter_s": 9.9508638381958, "time_total_s": 39.841079235076904, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d7a9ee0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29d8a2280>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 39.841079235076904, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 19.550000000000004, "ram_util_percent": 64.37142857142855}}
{"episode_reward_max": -13.73005745423083, "episode_reward_min": -1321.533513153415, "episode_reward_mean": -93.30822877484832, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -1313.7251470117892, "pol1": -88.76250869789135}, "policy_reward_max": {"pol0": -8.809899868336908, "pol1": -0.05491852711279488}, "policy_reward_mean": {"pol0": -81.53613207046799, "pol1": -11.772096704380328}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.01548748507665, -94.67733542599869, -14.226175436926018, -42.558036067673335, -79.68116631998726, -48.86852461282289, -191.51413392450658, -16.570420779623355, -24.902132224158514, -39.11426658999418, -25.7732076911894, -64.69628234089963, -58.22596247303097, -490.71693732685355, -31.858078151506305, -55.029219425881735, -31.838558241311752, -47.30850210043588, -66.60325371818172, -38.07445553023889, -40.701191409781735, -148.50816062376614, -1321.533513153415, -27.445564205094396, -39.44343352684541, -20.742573973228104, -29.161566254975554, -1260.5381371224894, -14.856551349096696, -21.539688507011654, -26.46225148415061, -36.68476526527157, -63.46360193020492, -26.857562063215457, -15.59737507972919, -16.469202578510412, -71.93451902900229, -40.74220064375983, -49.02234555470557, -28.227946429951626, -24.78647007704585, -112.57519771569754, -40.121820253577994, -42.15175242123618, -40.25458613338343, -38.03275039515272, -27.98465929492658, -22.274633944551635, -22.561311868963948, -60.32565054528134, -35.29311947239411, -25.393092627216596, -51.751444689562035, -21.787642778869053, -31.414773748965406, -26.7553802822598, -55.90468508454374, -36.39900957464616, -542.594865147139, -84.48587118912901, -17.46641418459061, -33.739759302464606, -40.04786763046796, -194.10892418505006, -95.36939902117815, -45.93220976772157, -31.475096926005563, -41.18911183904083, -525.2904248914366, -38.91502008372533, -65.33764438824724, -67.36259760130518, -37.14573260661498, -28.44095626427275, -24.115263595121835, -16.30127091737998, -19.321486432412335, -58.74624353255305, -82.75988915273729, -15.772436533039565, -16.79974082458883, -40.76661940164259, -22.644908849784787, -13.73005745423083, -203.38736718144938], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-49.96056895796385, -37.47814468611221, -10.800807330783492, -40.15922255840221, -40.76533620848645, -47.25920721999152, -190.60447904749674, -15.83918885674793, -23.697145141565713, -35.388148247570086, -19.74956847828619, -38.20923374260108, -44.0425358869718, -438.1833810648422, -16.714744910751683, -50.984188555070666, -29.705575293285094, -43.040442632227936, -65.57858250669476, -37.86486000421813, -35.96875845134827, -135.98543760118739, -1313.7251470117892, -20.13566499524812, -38.90310933548619, -15.073511693338666, -24.890460623001275, -1255.5114690318492, -13.757626797455098, -21.34302835493289, -22.136092052706108, -34.828948759863515, -61.49013994140101, -24.54149467937317, -14.778542574845378, -10.228412499273057, -71.56352681309278, -33.386920670969886, -42.684023152887484, -24.308599982923905, -11.935194965111927, -47.13916204905232, -30.35932120895931, -37.16233487987682, -37.44539942246539, -26.999400154644718, -15.760834409439035, -16.931777298117137, -18.242013211621725, -23.07691302476889, -32.535206310860474, -23.430546771606178, -46.113363263436504, -19.951409338126986, -26.595446091460417, -12.562945285165933, -22.10440668435401, -23.764753878500294, -540.1022877212662, -34.17179836805838, -17.279768306283525, -16.538174859439216, -39.82733682217074, -105.34641548715862, -39.66822137291833, -19.67500826465795, -25.59606377305552, -29.12524557100195, -524.9674559001049, -36.47982892442921, -27.59821970212838, -61.65294950914698, -33.82765211252379, -19.40512508787034, -19.432699925197138, -15.796427232082685, -8.809899868336908, -24.816976906322335, -35.11357665557915, -11.080658873865456, -10.784236776787422, -39.967243919227656, -18.954733077475957, -13.580259754432358, -197.5962566176477], "policy_pol1_reward": [-0.05491852711279488, -57.19919073988645, -3.425368106142528, -2.398813509271128, -38.915830111500824, -1.6093173928313405, -0.9096548770099148, -0.7312319228754252, -1.2049870825927815, -3.726118342424103, -6.023639212903209, -26.487048598298568, -14.183426586059174, -52.53355626201131, -15.143333240754616, -4.045030870811055, -2.1329829480266707, -4.268059468207969, -1.0246712114869645, -0.20959552602075648, -4.732432958433444, -12.522723022578775, -7.808366141626132, -7.30989920984627, -0.5403241913592334, -5.66906227988944, -4.271105631974293, -5.026668090639994, -1.098924551641597, -0.19666015207875964, -4.326159431444483, -1.85581650540804, -1.9734619888039284, -2.3160673838422934, -0.818832504883821, -6.240790079237342, -0.3709922159095311, -7.355279972789995, -6.338322401818093, -3.9193464470277357, -12.85127511193391, -65.43603566664521, -9.7624990446187, -4.989417541359367, -2.8091867109180337, -11.033350240507994, -12.223824885487542, -5.342856646434507, -4.319298657342211, -37.248737520512464, -2.75791316153362, -1.9625458556104411, -5.638081426125553, -1.8362334407420822, -4.819327657504991, -14.192434997093859, -33.80027840018973, -12.63425569614588, -2.492577425872742, -50.314072821070646, -0.18664587830709192, -17.201584443025364, -0.2205308082972369, -88.76250869789135, -55.70117764825989, -26.25720150306359, -5.87903315295006, -12.063866268038865, -0.3229689913316595, -2.435191159296137, -37.73942468611886, -5.709648092158213, -3.3180804940911774, -9.035831176402406, -4.682563669924696, -0.5048436852972985, -10.511586564075468, -33.92926662623072, -47.64631249715813, -4.691777659174108, -6.015504047801425, -0.7993754824149543, -3.6901757723088635, -0.14979769979847146, -5.791110563801663]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1856084251795131, "mean_inference_ms": 0.6575410376083333, "mean_action_processing_ms": 0.04497203944566676, "mean_env_wait_ms": 0.28108370288402335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 20570, "timesteps_this_iter": 0, "agent_timesteps_total": 41140, "timers": {"sample_time_ms": 8942.971, "sample_throughput": 460.026, "load_time_ms": 0.158, "load_throughput": 26081267.618, "learn_time_ms": 5139.451, "learn_throughput": 800.475}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05000000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 2654.7078461476913, "policy_loss": -0.03515102709449517, "vf_loss": 2654.740975765884, "vf_explained_var": -0.3256462124486764, "kl": 0.040143773389960793, "entropy": 1.3861536295463641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 30.792556295916437, "policy_loss": 0.00043351586597661175, "vf_loss": 30.79188169054687, "vf_explained_var": -0.39149292577058076, "kl": 0.003213981121715411, "entropy": 1.4592576637864112, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 20570, "num_agent_steps_sampled": 41140, "num_steps_trained": 20570, "num_agent_steps_trained": 41140, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 85, "training_iteration": 5, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-30-26", "timestamp": 1674487826, "time_this_iter_s": 9.925793647766113, "time_total_s": 49.76687288284302, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d29e0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29d78c1f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 49.76687288284302, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 18.571428571428573, "ram_util_percent": 64.34999999999998}}
{"episode_reward_max": -13.73005745423083, "episode_reward_min": -1321.533513153415, "episode_reward_mean": -92.77601842980812, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -1313.7251470117892, "pol1": -105.45274933917288}, "policy_reward_max": {"pol0": -8.809899868336908, "pol1": -0.14979769979847146}, "policy_reward_mean": {"pol0": -79.04420976796929, "pol1": -13.731808661838807}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-14.226175436926018, -42.558036067673335, -79.68116631998726, -48.86852461282289, -191.51413392450658, -16.570420779623355, -24.902132224158514, -39.11426658999418, -25.7732076911894, -64.69628234089963, -58.22596247303097, -490.71693732685355, -31.858078151506305, -55.029219425881735, -31.838558241311752, -47.30850210043588, -66.60325371818172, -38.07445553023889, -40.701191409781735, -148.50816062376614, -1321.533513153415, -27.445564205094396, -39.44343352684541, -20.742573973228104, -29.161566254975554, -1260.5381371224894, -14.856551349096696, -21.539688507011654, -26.46225148415061, -36.68476526527157, -63.46360193020492, -26.857562063215457, -15.59737507972919, -16.469202578510412, -71.93451902900229, -40.74220064375983, -49.02234555470557, -28.227946429951626, -24.78647007704585, -112.57519771569754, -40.121820253577994, -42.15175242123618, -40.25458613338343, -38.03275039515272, -27.98465929492658, -22.274633944551635, -22.561311868963948, -60.32565054528134, -35.29311947239411, -25.393092627216596, -51.751444689562035, -21.787642778869053, -31.414773748965406, -26.7553802822598, -55.90468508454374, -36.39900957464616, -542.594865147139, -84.48587118912901, -17.46641418459061, -33.739759302464606, -40.04786763046796, -194.10892418505006, -95.36939902117815, -45.93220976772157, -31.475096926005563, -41.18911183904083, -525.2904248914366, -38.91502008372533, -65.33764438824724, -67.36259760130518, -37.14573260661498, -28.44095626427275, -24.115263595121835, -16.30127091737998, -19.321486432412335, -58.74624353255305, -82.75988915273729, -15.772436533039565, -16.79974082458883, -40.76661940164259, -22.644908849784787, -13.73005745423083, -203.38736718144938, -392.0841130264171, -63.99447939518865, -88.58346140738549, -55.33357057786868, -100.52075195864066, -34.79439759246238, -50.94746438291117, -102.5860318050316, -31.416112062374214, -20.83954293700915, -213.47509440980323, -114.6295760654115, -33.96282528657823, -36.77456298293979, -22.63591812590621, -70.23045471158356, -58.28686330226573], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-10.800807330783492, -40.15922255840221, -40.76533620848645, -47.25920721999152, -190.60447904749674, -15.83918885674793, -23.697145141565713, -35.388148247570086, -19.74956847828619, -38.20923374260108, -44.0425358869718, -438.1833810648422, -16.714744910751683, -50.984188555070666, -29.705575293285094, -43.040442632227936, -65.57858250669476, -37.86486000421813, -35.96875845134827, -135.98543760118739, -1313.7251470117892, -20.13566499524812, -38.90310933548619, -15.073511693338666, -24.890460623001275, -1255.5114690318492, -13.757626797455098, -21.34302835493289, -22.136092052706108, -34.828948759863515, -61.49013994140101, -24.54149467937317, -14.778542574845378, -10.228412499273057, -71.56352681309278, -33.386920670969886, -42.684023152887484, -24.308599982923905, -11.935194965111927, -47.13916204905232, -30.35932120895931, -37.16233487987682, -37.44539942246539, -26.999400154644718, -15.760834409439035, -16.931777298117137, -18.242013211621725, -23.07691302476889, -32.535206310860474, -23.430546771606178, -46.113363263436504, -19.951409338126986, -26.595446091460417, -12.562945285165933, -22.10440668435401, -23.764753878500294, -540.1022877212662, -34.17179836805838, -17.279768306283525, -16.538174859439216, -39.82733682217074, -105.34641548715862, -39.66822137291833, -19.67500826465795, -25.59606377305552, -29.12524557100195, -524.9674559001049, -36.47982892442921, -27.59821970212838, -61.65294950914698, -33.82765211252379, -19.40512508787034, -19.432699925197138, -15.796427232082685, -8.809899868336908, -24.816976906322335, -35.11357665557915, -11.080658873865456, -10.784236776787422, -39.967243919227656, -18.954733077475957, -13.580259754432358, -197.5962566176477, -390.6119993168592, -33.81980702246156, -35.110491831893334, -35.67938514493914, -60.923310496219436, -16.99815048279172, -33.23205526050868, -50.91527627365333, -18.55143955973478, -20.2197990940667, -108.02234507063042, -103.94286108026617, -33.59115925352741, -33.31931211417811, -18.194536099986703, -45.490604746343, -22.665931603165454], "policy_pol1_reward": [-3.425368106142528, -2.398813509271128, -38.915830111500824, -1.6093173928313405, -0.9096548770099148, -0.7312319228754252, -1.2049870825927815, -3.726118342424103, -6.023639212903209, -26.487048598298568, -14.183426586059174, -52.53355626201131, -15.143333240754616, -4.045030870811055, -2.1329829480266707, -4.268059468207969, -1.0246712114869645, -0.20959552602075648, -4.732432958433444, -12.522723022578775, -7.808366141626132, -7.30989920984627, -0.5403241913592334, -5.66906227988944, -4.271105631974293, -5.026668090639994, -1.098924551641597, -0.19666015207875964, -4.326159431444483, -1.85581650540804, -1.9734619888039284, -2.3160673838422934, -0.818832504883821, -6.240790079237342, -0.3709922159095311, -7.355279972789995, -6.338322401818093, -3.9193464470277357, -12.85127511193391, -65.43603566664521, -9.7624990446187, -4.989417541359367, -2.8091867109180337, -11.033350240507994, -12.223824885487542, -5.342856646434507, -4.319298657342211, -37.248737520512464, -2.75791316153362, -1.9625458556104411, -5.638081426125553, -1.8362334407420822, -4.819327657504991, -14.192434997093859, -33.80027840018973, -12.63425569614588, -2.492577425872742, -50.314072821070646, -0.18664587830709192, -17.201584443025364, -0.2205308082972369, -88.76250869789135, -55.70117764825989, -26.25720150306359, -5.87903315295006, -12.063866268038865, -0.3229689913316595, -2.435191159296137, -37.73942468611886, -5.709648092158213, -3.3180804940911774, -9.035831176402406, -4.682563669924696, -0.5048436852972985, -10.511586564075468, -33.92926662623072, -47.64631249715813, -4.691777659174108, -6.015504047801425, -0.7993754824149543, -3.6901757723088635, -0.14979769979847146, -5.791110563801663, -1.4721137095579233, -30.174672372727102, -53.472969575492165, -19.654185432929534, -39.59744146242118, -17.79624710967067, -17.715409122402512, -51.670755531378305, -12.864672502639426, -0.619743842942456, -105.45274933917288, -10.686714985145256, -0.3716660330508036, -3.455250868761699, -4.441382025919497, -24.739849965240513, -35.62093169910025]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1857989522515402, "mean_inference_ms": 0.6576842156280671, "mean_action_processing_ms": 0.0449765075224122, "mean_env_wait_ms": 0.2806455934218131, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 24684, "timesteps_this_iter": 0, "agent_timesteps_total": 49368, "timers": {"sample_time_ms": 9109.66, "sample_throughput": 451.608, "load_time_ms": 0.159, "load_throughput": 25799202.576, "learn_time_ms": 5140.352, "learn_throughput": 800.334}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1434.1765140260259, "policy_loss": -0.012954719018550047, "vf_loss": 1434.1876321181655, "vf_explained_var": -0.13054731544107198, "kl": 0.024596307413988446, "entropy": 1.2760117218984912, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 101.59156832986822, "policy_loss": 4.775245518734058e-05, "vf_loss": 101.59138546654334, "vf_explained_var": -0.253427368029952, "kl": 0.003612247804994695, "entropy": 1.3990913901478053, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 24684, "num_agent_steps_sampled": 49368, "num_steps_trained": 24684, "num_agent_steps_trained": 49368, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 102, "training_iteration": 6, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-30-36", "timestamp": 1674487836, "time_this_iter_s": 9.97931170463562, "time_total_s": 59.74618458747864, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d770940>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29d28b700>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 59.74618458747864, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 18.771428571428576, "ram_util_percent": 64.39285714285714}}
{"episode_reward_max": -13.73005745423083, "episode_reward_min": -2124.940568045615, "episode_reward_mean": -123.77291515983141, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -2121.6919212172197, "pol1": -105.45274933917288}, "policy_reward_max": {"pol0": -8.809899868336908, "pol1": -0.14979769979847146}, "policy_reward_mean": {"pol0": -110.65567621000324, "pol1": -13.117238949828172}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.07445553023889, -40.701191409781735, -148.50816062376614, -1321.533513153415, -27.445564205094396, -39.44343352684541, -20.742573973228104, -29.161566254975554, -1260.5381371224894, -14.856551349096696, -21.539688507011654, -26.46225148415061, -36.68476526527157, -63.46360193020492, -26.857562063215457, -15.59737507972919, -16.469202578510412, -71.93451902900229, -40.74220064375983, -49.02234555470557, -28.227946429951626, -24.78647007704585, -112.57519771569754, -40.121820253577994, -42.15175242123618, -40.25458613338343, -38.03275039515272, -27.98465929492658, -22.274633944551635, -22.561311868963948, -60.32565054528134, -35.29311947239411, -25.393092627216596, -51.751444689562035, -21.787642778869053, -31.414773748965406, -26.7553802822598, -55.90468508454374, -36.39900957464616, -542.594865147139, -84.48587118912901, -17.46641418459061, -33.739759302464606, -40.04786763046796, -194.10892418505006, -95.36939902117815, -45.93220976772157, -31.475096926005563, -41.18911183904083, -525.2904248914366, -38.91502008372533, -65.33764438824724, -67.36259760130518, -37.14573260661498, -28.44095626427275, -24.115263595121835, -16.30127091737998, -19.321486432412335, -58.74624353255305, -82.75988915273729, -15.772436533039565, -16.79974082458883, -40.76661940164259, -22.644908849784787, -13.73005745423083, -203.38736718144938, -392.0841130264171, -63.99447939518865, -88.58346140738549, -55.33357057786868, -100.52075195864066, -34.79439759246238, -50.94746438291117, -102.5860318050316, -31.416112062374214, -20.83954293700915, -213.47509440980323, -114.6295760654115, -33.96282528657823, -36.77456298293979, -22.63591812590621, -70.23045471158356, -58.28686330226573, -29.83575621383677, -39.73566984949155, -25.046626298830926, -58.51670265938564, -32.32136521200822, -21.727169292562188, -16.690383196726465, -24.61472985133992, -2124.940568045615, -24.059763209973386, -36.299537195044124, -35.398675429017736, -1794.5124758748568, -45.11229483026421, -30.79223466838268, -56.7504462242933, -32.82013237568637], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-37.86486000421813, -35.96875845134827, -135.98543760118739, -1313.7251470117892, -20.13566499524812, -38.90310933548619, -15.073511693338666, -24.890460623001275, -1255.5114690318492, -13.757626797455098, -21.34302835493289, -22.136092052706108, -34.828948759863515, -61.49013994140101, -24.54149467937317, -14.778542574845378, -10.228412499273057, -71.56352681309278, -33.386920670969886, -42.684023152887484, -24.308599982923905, -11.935194965111927, -47.13916204905232, -30.35932120895931, -37.16233487987682, -37.44539942246539, -26.999400154644718, -15.760834409439035, -16.931777298117137, -18.242013211621725, -23.07691302476889, -32.535206310860474, -23.430546771606178, -46.113363263436504, -19.951409338126986, -26.595446091460417, -12.562945285165933, -22.10440668435401, -23.764753878500294, -540.1022877212662, -34.17179836805838, -17.279768306283525, -16.538174859439216, -39.82733682217074, -105.34641548715862, -39.66822137291833, -19.67500826465795, -25.59606377305552, -29.12524557100195, -524.9674559001049, -36.47982892442921, -27.59821970212838, -61.65294950914698, -33.82765211252379, -19.40512508787034, -19.432699925197138, -15.796427232082685, -8.809899868336908, -24.816976906322335, -35.11357665557915, -11.080658873865456, -10.784236776787422, -39.967243919227656, -18.954733077475957, -13.580259754432358, -197.5962566176477, -390.6119993168592, -33.81980702246156, -35.110491831893334, -35.67938514493914, -60.923310496219436, -16.99815048279172, -33.23205526050868, -50.91527627365333, -18.55143955973478, -20.2197990940667, -108.02234507063042, -103.94286108026617, -33.59115925352741, -33.31931211417811, -18.194536099986703, -45.490604746343, -22.665931603165454, -19.446100496880046, -35.668263391961624, -16.48404306716454, -32.588522186993096, -32.12773920627723, -18.029722324899378, -14.077268269941337, -21.760243910908642, -2121.6919212172197, -22.99222626965996, -35.73012782471864, -34.970464128168175, -1792.496384315576, -16.863854886807793, -25.093559617009028, -56.398557952963685, -15.449432818022068], "policy_pol1_reward": [-0.20959552602075648, -4.732432958433444, -12.522723022578775, -7.808366141626132, -7.30989920984627, -0.5403241913592334, -5.66906227988944, -4.271105631974293, -5.026668090639994, -1.098924551641597, -0.19666015207875964, -4.326159431444483, -1.85581650540804, -1.9734619888039284, -2.3160673838422934, -0.818832504883821, -6.240790079237342, -0.3709922159095311, -7.355279972789995, -6.338322401818093, -3.9193464470277357, -12.85127511193391, -65.43603566664521, -9.7624990446187, -4.989417541359367, -2.8091867109180337, -11.033350240507994, -12.223824885487542, -5.342856646434507, -4.319298657342211, -37.248737520512464, -2.75791316153362, -1.9625458556104411, -5.638081426125553, -1.8362334407420822, -4.819327657504991, -14.192434997093859, -33.80027840018973, -12.63425569614588, -2.492577425872742, -50.314072821070646, -0.18664587830709192, -17.201584443025364, -0.2205308082972369, -88.76250869789135, -55.70117764825989, -26.25720150306359, -5.87903315295006, -12.063866268038865, -0.3229689913316595, -2.435191159296137, -37.73942468611886, -5.709648092158213, -3.3180804940911774, -9.035831176402406, -4.682563669924696, -0.5048436852972985, -10.511586564075468, -33.92926662623072, -47.64631249715813, -4.691777659174108, -6.015504047801425, -0.7993754824149543, -3.6901757723088635, -0.14979769979847146, -5.791110563801663, -1.4721137095579233, -30.174672372727102, -53.472969575492165, -19.654185432929534, -39.59744146242118, -17.79624710967067, -17.715409122402512, -51.670755531378305, -12.864672502639426, -0.619743842942456, -105.45274933917288, -10.686714985145256, -0.3716660330508036, -3.455250868761699, -4.441382025919497, -24.739849965240513, -35.62093169910025, -10.389655716956742, -4.067406457529922, -8.562583231666384, -25.928180472392548, -0.19362600573100622, -3.697446967662814, -2.613114926785112, -2.8544859404312564, -3.2486468283946337, -1.0675369403134334, -0.5694093703254464, -0.42821130084955855, -2.0160915592810165, -28.248439943456418, -5.6986750513736695, -0.35188827132960404, -17.370699557664285]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18611806236381112, "mean_inference_ms": 0.657783887315061, "mean_action_processing_ms": 0.044969498630185976, "mean_env_wait_ms": 0.27972616510141335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 28798, "timesteps_this_iter": 0, "agent_timesteps_total": 57596, "timers": {"sample_time_ms": 9232.126, "sample_throughput": 445.618, "load_time_ms": 0.16, "load_throughput": 25666716.233, "learn_time_ms": 5134.869, "learn_throughput": 801.189}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 73849.11208044886, "policy_loss": -0.04166907788312528, "vf_loss": 73849.13123382082, "vf_explained_var": -0.2048863349482417, "kl": 0.20611577089365105, "entropy": 1.1324590335250833, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 17.830201417704423, "policy_loss": -0.0020916449167998506, "vf_loss": 17.832216502058632, "vf_explained_var": -0.48706394427766403, "kl": 0.004084785245989527, "entropy": 1.4100565856943528, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 28798, "num_agent_steps_sampled": 57596, "num_steps_trained": 28798, "num_agent_steps_trained": 57596, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 119, "training_iteration": 7, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-30-46", "timestamp": 1674487846, "time_this_iter_s": 9.913041830062866, "time_total_s": 69.6592264175415, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d7a9ee0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dac8940>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 69.6592264175415, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 23.993333333333332, "ram_util_percent": 64.41333333333333}}
{"episode_reward_max": -13.73005745423083, "episode_reward_min": -3739.2474709275853, "episode_reward_mean": -138.4190018883663, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -3738.674516789818, "pol1": -105.45274933917288}, "policy_reward_max": {"pol0": -8.809899868336908, "pol1": -0.14979769979847146}, "policy_reward_mean": {"pol0": -124.10191093212526, "pol1": -14.317090956241032}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-71.93451902900229, -40.74220064375983, -49.02234555470557, -28.227946429951626, -24.78647007704585, -112.57519771569754, -40.121820253577994, -42.15175242123618, -40.25458613338343, -38.03275039515272, -27.98465929492658, -22.274633944551635, -22.561311868963948, -60.32565054528134, -35.29311947239411, -25.393092627216596, -51.751444689562035, -21.787642778869053, -31.414773748965406, -26.7553802822598, -55.90468508454374, -36.39900957464616, -542.594865147139, -84.48587118912901, -17.46641418459061, -33.739759302464606, -40.04786763046796, -194.10892418505006, -95.36939902117815, -45.93220976772157, -31.475096926005563, -41.18911183904083, -525.2904248914366, -38.91502008372533, -65.33764438824724, -67.36259760130518, -37.14573260661498, -28.44095626427275, -24.115263595121835, -16.30127091737998, -19.321486432412335, -58.74624353255305, -82.75988915273729, -15.772436533039565, -16.79974082458883, -40.76661940164259, -22.644908849784787, -13.73005745423083, -203.38736718144938, -392.0841130264171, -63.99447939518865, -88.58346140738549, -55.33357057786868, -100.52075195864066, -34.79439759246238, -50.94746438291117, -102.5860318050316, -31.416112062374214, -20.83954293700915, -213.47509440980323, -114.6295760654115, -33.96282528657823, -36.77456298293979, -22.63591812590621, -70.23045471158356, -58.28686330226573, -29.83575621383677, -39.73566984949155, -25.046626298830926, -58.51670265938564, -32.32136521200822, -21.727169292562188, -16.690383196726465, -24.61472985133992, -2124.940568045615, -24.059763209973386, -36.299537195044124, -35.398675429017736, -1794.5124758748568, -45.11229483026421, -30.79223466838268, -56.7504462242933, -32.82013237568637, -76.83192770068214, -32.68840199177839, -55.218695166932605, -28.068087715236146, -225.72958173780003, -29.592897626197953, -30.81441826140837, -39.06315305974218, -29.300460513939807, -59.225195889632424, -3739.2474709275853, -38.25959096337602, -65.70279812187636, -26.84502547222475, -58.81049686726013, -39.77549799468603, -37.51456690015647], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-71.56352681309278, -33.386920670969886, -42.684023152887484, -24.308599982923905, -11.935194965111927, -47.13916204905232, -30.35932120895931, -37.16233487987682, -37.44539942246539, -26.999400154644718, -15.760834409439035, -16.931777298117137, -18.242013211621725, -23.07691302476889, -32.535206310860474, -23.430546771606178, -46.113363263436504, -19.951409338126986, -26.595446091460417, -12.562945285165933, -22.10440668435401, -23.764753878500294, -540.1022877212662, -34.17179836805838, -17.279768306283525, -16.538174859439216, -39.82733682217074, -105.34641548715862, -39.66822137291833, -19.67500826465795, -25.59606377305552, -29.12524557100195, -524.9674559001049, -36.47982892442921, -27.59821970212838, -61.65294950914698, -33.82765211252379, -19.40512508787034, -19.432699925197138, -15.796427232082685, -8.809899868336908, -24.816976906322335, -35.11357665557915, -11.080658873865456, -10.784236776787422, -39.967243919227656, -18.954733077475957, -13.580259754432358, -197.5962566176477, -390.6119993168592, -33.81980702246156, -35.110491831893334, -35.67938514493914, -60.923310496219436, -16.99815048279172, -33.23205526050868, -50.91527627365333, -18.55143955973478, -20.2197990940667, -108.02234507063042, -103.94286108026617, -33.59115925352741, -33.31931211417811, -18.194536099986703, -45.490604746343, -22.665931603165454, -19.446100496880046, -35.668263391961624, -16.48404306716454, -32.588522186993096, -32.12773920627723, -18.029722324899378, -14.077268269941337, -21.760243910908642, -2121.6919212172197, -22.99222626965996, -35.73012782471864, -34.970464128168175, -1792.496384315576, -16.863854886807793, -25.093559617009028, -56.398557952963685, -15.449432818022068, -39.068940993225524, -27.892760688296164, -38.32652429327798, -12.738385653620222, -219.666558144741, -27.996058038608346, -13.115124231634985, -35.81435156903055, -12.35094618178002, -58.80946997763657, -3738.674516789818, -37.914395457933445, -24.688627400208592, -25.63795344775887, -37.27939797000974, -38.69761048348349, -37.114555298457056], "policy_pol1_reward": [-0.3709922159095311, -7.355279972789995, -6.338322401818093, -3.9193464470277357, -12.85127511193391, -65.43603566664521, -9.7624990446187, -4.989417541359367, -2.8091867109180337, -11.033350240507994, -12.223824885487542, -5.342856646434507, -4.319298657342211, -37.248737520512464, -2.75791316153362, -1.9625458556104411, -5.638081426125553, -1.8362334407420822, -4.819327657504991, -14.192434997093859, -33.80027840018973, -12.63425569614588, -2.492577425872742, -50.314072821070646, -0.18664587830709192, -17.201584443025364, -0.2205308082972369, -88.76250869789135, -55.70117764825989, -26.25720150306359, -5.87903315295006, -12.063866268038865, -0.3229689913316595, -2.435191159296137, -37.73942468611886, -5.709648092158213, -3.3180804940911774, -9.035831176402406, -4.682563669924696, -0.5048436852972985, -10.511586564075468, -33.92926662623072, -47.64631249715813, -4.691777659174108, -6.015504047801425, -0.7993754824149543, -3.6901757723088635, -0.14979769979847146, -5.791110563801663, -1.4721137095579233, -30.174672372727102, -53.472969575492165, -19.654185432929534, -39.59744146242118, -17.79624710967067, -17.715409122402512, -51.670755531378305, -12.864672502639426, -0.619743842942456, -105.45274933917288, -10.686714985145256, -0.3716660330508036, -3.455250868761699, -4.441382025919497, -24.739849965240513, -35.62093169910025, -10.389655716956742, -4.067406457529922, -8.562583231666384, -25.928180472392548, -0.19362600573100622, -3.697446967662814, -2.613114926785112, -2.8544859404312564, -3.2486468283946337, -1.0675369403134334, -0.5694093703254464, -0.42821130084955855, -2.0160915592810165, -28.248439943456418, -5.6986750513736695, -0.35188827132960404, -17.370699557664285, -37.762986707456584, -4.795641303482234, -16.892170873654642, -15.329702061615942, -6.063023593059015, -1.596839587589603, -17.699294029773394, -3.2488014907116387, -16.949514332159794, -0.41572591199580944, -0.5729541377675601, -0.34519550544255967, -41.014170721667746, -1.2070720244658657, -21.531098897250384, -1.077887511202534, -0.4000116016994149]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18606907195685934, "mean_inference_ms": 0.6578862373924349, "mean_action_processing_ms": 0.044954696944851644, "mean_env_wait_ms": 0.27913853641845643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 32912, "timesteps_this_iter": 0, "agent_timesteps_total": 65824, "timers": {"sample_time_ms": 9314.86, "sample_throughput": 441.66, "load_time_ms": 0.161, "load_throughput": 25629954.186, "learn_time_ms": 5120.869, "learn_throughput": 803.379}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 118999.66707970997, "policy_loss": -0.01306539736688137, "vf_loss": 118999.68045199166, "vf_explained_var": -0.13558745334545771, "kl": 0.00818504750283561, "entropy": 1.4898247189819813, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 19.57103564205269, "policy_loss": 0.002369576118265589, "vf_loss": 19.568640077486634, "vf_explained_var": -0.3318567461023728, "kl": 0.0027866360687767155, "entropy": 1.4363614867130916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 32912, "num_agent_steps_sampled": 65824, "num_steps_trained": 32912, "num_agent_steps_trained": 65824, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 136, "training_iteration": 8, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-30-56", "timestamp": 1674487856, "time_this_iter_s": 9.803625106811523, "time_total_s": 79.46285152435303, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d29e0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dace9d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 79.46285152435303, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 26.484615384615385, "ram_util_percent": 64.61538461538463}}
{"episode_reward_max": -11.357288056349114, "episode_reward_min": -3739.2474709275853, "episode_reward_mean": -147.94564243037325, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -3738.674516789818, "pol1": -105.45274933917288}, "policy_reward_max": {"pol0": -8.809899868336908, "pol1": -0.14979769979847146}, "policy_reward_mean": {"pol0": -134.24538203557725, "pol1": -13.700260394796015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-21.787642778869053, -31.414773748965406, -26.7553802822598, -55.90468508454374, -36.39900957464616, -542.594865147139, -84.48587118912901, -17.46641418459061, -33.739759302464606, -40.04786763046796, -194.10892418505006, -95.36939902117815, -45.93220976772157, -31.475096926005563, -41.18911183904083, -525.2904248914366, -38.91502008372533, -65.33764438824724, -67.36259760130518, -37.14573260661498, -28.44095626427275, -24.115263595121835, -16.30127091737998, -19.321486432412335, -58.74624353255305, -82.75988915273729, -15.772436533039565, -16.79974082458883, -40.76661940164259, -22.644908849784787, -13.73005745423083, -203.38736718144938, -392.0841130264171, -63.99447939518865, -88.58346140738549, -55.33357057786868, -100.52075195864066, -34.79439759246238, -50.94746438291117, -102.5860318050316, -31.416112062374214, -20.83954293700915, -213.47509440980323, -114.6295760654115, -33.96282528657823, -36.77456298293979, -22.63591812590621, -70.23045471158356, -58.28686330226573, -29.83575621383677, -39.73566984949155, -25.046626298830926, -58.51670265938564, -32.32136521200822, -21.727169292562188, -16.690383196726465, -24.61472985133992, -2124.940568045615, -24.059763209973386, -36.299537195044124, -35.398675429017736, -1794.5124758748568, -45.11229483026421, -30.79223466838268, -56.7504462242933, -32.82013237568637, -76.83192770068214, -32.68840199177839, -55.218695166932605, -28.068087715236146, -225.72958173780003, -29.592897626197953, -30.81441826140837, -39.06315305974218, -29.300460513939807, -59.225195889632424, -3739.2474709275853, -38.25959096337602, -65.70279812187636, -26.84502547222475, -58.81049686726013, -39.77549799468603, -37.51456690015647, -22.288686336215886, -22.520863512801366, -11.357288056349114, -994.4136822153226, -31.909865300891713, -28.89893590501002, -119.79540169517932, -35.90843478723304, -116.09492854467277, -21.28194454554536, -42.60636960365147, -54.34616085073287, -51.50266937912103, -45.62923144788693, -30.072555583484434, -32.21274073841765, -25.25779679458743], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-19.951409338126986, -26.595446091460417, -12.562945285165933, -22.10440668435401, -23.764753878500294, -540.1022877212662, -34.17179836805838, -17.279768306283525, -16.538174859439216, -39.82733682217074, -105.34641548715862, -39.66822137291833, -19.67500826465795, -25.59606377305552, -29.12524557100195, -524.9674559001049, -36.47982892442921, -27.59821970212838, -61.65294950914698, -33.82765211252379, -19.40512508787034, -19.432699925197138, -15.796427232082685, -8.809899868336908, -24.816976906322335, -35.11357665557915, -11.080658873865456, -10.784236776787422, -39.967243919227656, -18.954733077475957, -13.580259754432358, -197.5962566176477, -390.6119993168592, -33.81980702246156, -35.110491831893334, -35.67938514493914, -60.923310496219436, -16.99815048279172, -33.23205526050868, -50.91527627365333, -18.55143955973478, -20.2197990940667, -108.02234507063042, -103.94286108026617, -33.59115925352741, -33.31931211417811, -18.194536099986703, -45.490604746343, -22.665931603165454, -19.446100496880046, -35.668263391961624, -16.48404306716454, -32.588522186993096, -32.12773920627723, -18.029722324899378, -14.077268269941337, -21.760243910908642, -2121.6919212172197, -22.99222626965996, -35.73012782471864, -34.970464128168175, -1792.496384315576, -16.863854886807793, -25.093559617009028, -56.398557952963685, -15.449432818022068, -39.068940993225524, -27.892760688296164, -38.32652429327798, -12.738385653620222, -219.666558144741, -27.996058038608346, -13.115124231634985, -35.81435156903055, -12.35094618178002, -58.80946997763657, -3738.674516789818, -37.914395457933445, -24.688627400208592, -25.63795344775887, -37.27939797000974, -38.69761048348349, -37.114555298457056, -14.478202680708144, -20.825313741041942, -8.884778406847735, -990.4422164509485, -26.730650376186784, -27.119928823160734, -119.36041020003387, -35.083103206789524, -115.86500329762323, -16.246170784647017, -41.921925412120245, -15.648687795944213, -20.31292832384606, -40.16669613469782, -27.67163341117477, -13.374290649966206, -19.28970823929346], "policy_pol1_reward": [-1.8362334407420822, -4.819327657504991, -14.192434997093859, -33.80027840018973, -12.63425569614588, -2.492577425872742, -50.314072821070646, -0.18664587830709192, -17.201584443025364, -0.2205308082972369, -88.76250869789135, -55.70117764825989, -26.25720150306359, -5.87903315295006, -12.063866268038865, -0.3229689913316595, -2.435191159296137, -37.73942468611886, -5.709648092158213, -3.3180804940911774, -9.035831176402406, -4.682563669924696, -0.5048436852972985, -10.511586564075468, -33.92926662623072, -47.64631249715813, -4.691777659174108, -6.015504047801425, -0.7993754824149543, -3.6901757723088635, -0.14979769979847146, -5.791110563801663, -1.4721137095579233, -30.174672372727102, -53.472969575492165, -19.654185432929534, -39.59744146242118, -17.79624710967067, -17.715409122402512, -51.670755531378305, -12.864672502639426, -0.619743842942456, -105.45274933917288, -10.686714985145256, -0.3716660330508036, -3.455250868761699, -4.441382025919497, -24.739849965240513, -35.62093169910025, -10.389655716956742, -4.067406457529922, -8.562583231666384, -25.928180472392548, -0.19362600573100622, -3.697446967662814, -2.613114926785112, -2.8544859404312564, -3.2486468283946337, -1.0675369403134334, -0.5694093703254464, -0.42821130084955855, -2.0160915592810165, -28.248439943456418, -5.6986750513736695, -0.35188827132960404, -17.370699557664285, -37.762986707456584, -4.795641303482234, -16.892170873654642, -15.329702061615942, -6.063023593059015, -1.596839587589603, -17.699294029773394, -3.2488014907116387, -16.949514332159794, -0.41572591199580944, -0.5729541377675601, -0.34519550544255967, -41.014170721667746, -1.2070720244658657, -21.531098897250384, -1.077887511202534, -0.4000116016994149, -7.810483655507712, -1.695549771759439, -2.472509649501371, -3.9714657643741704, -5.179214924704943, -1.7790070818492834, -0.43499149514545243, -0.8253315804435557, -0.22992524704956818, -5.03577376089834, -0.6844441915312105, -38.697473054788674, -31.18974105527492, -5.462535313189107, -2.400922172309668, -18.838450088451463, -5.968088555293984]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18603212792816443, "mean_inference_ms": 0.6580546873850958, "mean_action_processing_ms": 0.044953872931931586, "mean_env_wait_ms": 0.27877372662715477, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 37026, "timesteps_this_iter": 0, "agent_timesteps_total": 74052, "timers": {"sample_time_ms": 9368.413, "sample_throughput": 439.135, "load_time_ms": 0.16, "load_throughput": 25694622.75, "learn_time_ms": 5128.223, "learn_throughput": 802.227}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.16875000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 8531.65882024765, "policy_loss": -0.001443566024924318, "vf_loss": 8531.659780669212, "vf_explained_var": -0.27968001309782264, "kl": 0.003024770657683954, "entropy": 1.272963996976614, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 14.789973141990291, "policy_loss": -0.0018312075893239428, "vf_loss": 14.791772821902608, "vf_explained_var": -0.28020198016117015, "kl": 0.0067046145920964285, "entropy": 1.405125135431687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 37026, "num_agent_steps_sampled": 74052, "num_steps_trained": 37026, "num_agent_steps_trained": 74052, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 153, "training_iteration": 9, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-31-06", "timestamp": 1674487866, "time_this_iter_s": 9.94872498512268, "time_total_s": 89.41157650947571, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d770940>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29daceaf0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 89.41157650947571, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 25.9, "ram_util_percent": 64.63333333333334}}
{"episode_reward_max": -11.357288056349114, "episode_reward_min": -3739.2474709275853, "episode_reward_mean": -139.46730190439493, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -3738.674516789818, "pol1": -105.45274933917288}, "policy_reward_max": {"pol0": -8.809899868336908, "pol1": -0.07577986667737328}, "policy_reward_mean": {"pol0": -127.91445237999767, "pol1": -11.552849524397283}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-65.33764438824724, -67.36259760130518, -37.14573260661498, -28.44095626427275, -24.115263595121835, -16.30127091737998, -19.321486432412335, -58.74624353255305, -82.75988915273729, -15.772436533039565, -16.79974082458883, -40.76661940164259, -22.644908849784787, -13.73005745423083, -203.38736718144938, -392.0841130264171, -63.99447939518865, -88.58346140738549, -55.33357057786868, -100.52075195864066, -34.79439759246238, -50.94746438291117, -102.5860318050316, -31.416112062374214, -20.83954293700915, -213.47509440980323, -114.6295760654115, -33.96282528657823, -36.77456298293979, -22.63591812590621, -70.23045471158356, -58.28686330226573, -29.83575621383677, -39.73566984949155, -25.046626298830926, -58.51670265938564, -32.32136521200822, -21.727169292562188, -16.690383196726465, -24.61472985133992, -2124.940568045615, -24.059763209973386, -36.299537195044124, -35.398675429017736, -1794.5124758748568, -45.11229483026421, -30.79223466838268, -56.7504462242933, -32.82013237568637, -76.83192770068214, -32.68840199177839, -55.218695166932605, -28.068087715236146, -225.72958173780003, -29.592897626197953, -30.81441826140837, -39.06315305974218, -29.300460513939807, -59.225195889632424, -3739.2474709275853, -38.25959096337602, -65.70279812187636, -26.84502547222475, -58.81049686726013, -39.77549799468603, -37.51456690015647, -22.288686336215886, -22.520863512801366, -11.357288056349114, -994.4136822153226, -31.909865300891713, -28.89893590501002, -119.79540169517932, -35.90843478723304, -116.09492854467277, -21.28194454554536, -42.60636960365147, -54.34616085073287, -51.50266937912103, -45.62923144788693, -30.072555583484434, -32.21274073841765, -25.25779679458743, -22.8918907697962, -92.61992888929635, -18.964351267194093, -29.063487527128416, -24.372822121460786, -36.47260202236706, -44.31230730815977, -18.40929475655898, -13.996826448683418, -24.773848809450538, -49.33494409977525, -26.882867586728352, -41.68199543905691, -399.69874746464575, -52.02966776519293, -53.426634717366, -66.11018604654186], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-27.59821970212838, -61.65294950914698, -33.82765211252379, -19.40512508787034, -19.432699925197138, -15.796427232082685, -8.809899868336908, -24.816976906322335, -35.11357665557915, -11.080658873865456, -10.784236776787422, -39.967243919227656, -18.954733077475957, -13.580259754432358, -197.5962566176477, -390.6119993168592, -33.81980702246156, -35.110491831893334, -35.67938514493914, -60.923310496219436, -16.99815048279172, -33.23205526050868, -50.91527627365333, -18.55143955973478, -20.2197990940667, -108.02234507063042, -103.94286108026617, -33.59115925352741, -33.31931211417811, -18.194536099986703, -45.490604746343, -22.665931603165454, -19.446100496880046, -35.668263391961624, -16.48404306716454, -32.588522186993096, -32.12773920627723, -18.029722324899378, -14.077268269941337, -21.760243910908642, -2121.6919212172197, -22.99222626965996, -35.73012782471864, -34.970464128168175, -1792.496384315576, -16.863854886807793, -25.093559617009028, -56.398557952963685, -15.449432818022068, -39.068940993225524, -27.892760688296164, -38.32652429327798, -12.738385653620222, -219.666558144741, -27.996058038608346, -13.115124231634985, -35.81435156903055, -12.35094618178002, -58.80946997763657, -3738.674516789818, -37.914395457933445, -24.688627400208592, -25.63795344775887, -37.27939797000974, -38.69761048348349, -37.114555298457056, -14.478202680708144, -20.825313741041942, -8.884778406847735, -990.4422164509485, -26.730650376186784, -27.119928823160734, -119.36041020003387, -35.083103206789524, -115.86500329762323, -16.246170784647017, -41.921925412120245, -15.648687795944213, -20.31292832384606, -40.16669613469782, -27.67163341117477, -13.374290649966206, -19.28970823929346, -9.742804303801124, -92.39438485780589, -16.61819888859476, -28.91190106154374, -20.972535704965225, -19.909133774863307, -41.96906299682648, -17.23354847467919, -13.682873929748625, -19.930299697102182, -46.890054952526405, -13.735476268992397, -41.27994529279439, -398.109496193806, -24.0630377364556, -53.35085485068864, -41.86999210500049], "policy_pol1_reward": [-37.73942468611886, -5.709648092158213, -3.3180804940911774, -9.035831176402406, -4.682563669924696, -0.5048436852972985, -10.511586564075468, -33.92926662623072, -47.64631249715813, -4.691777659174108, -6.015504047801425, -0.7993754824149543, -3.6901757723088635, -0.14979769979847146, -5.791110563801663, -1.4721137095579233, -30.174672372727102, -53.472969575492165, -19.654185432929534, -39.59744146242118, -17.79624710967067, -17.715409122402512, -51.670755531378305, -12.864672502639426, -0.619743842942456, -105.45274933917288, -10.686714985145256, -0.3716660330508036, -3.455250868761699, -4.441382025919497, -24.739849965240513, -35.62093169910025, -10.389655716956742, -4.067406457529922, -8.562583231666384, -25.928180472392548, -0.19362600573100622, -3.697446967662814, -2.613114926785112, -2.8544859404312564, -3.2486468283946337, -1.0675369403134334, -0.5694093703254464, -0.42821130084955855, -2.0160915592810165, -28.248439943456418, -5.6986750513736695, -0.35188827132960404, -17.370699557664285, -37.762986707456584, -4.795641303482234, -16.892170873654642, -15.329702061615942, -6.063023593059015, -1.596839587589603, -17.699294029773394, -3.2488014907116387, -16.949514332159794, -0.41572591199580944, -0.5729541377675601, -0.34519550544255967, -41.014170721667746, -1.2070720244658657, -21.531098897250384, -1.077887511202534, -0.4000116016994149, -7.810483655507712, -1.695549771759439, -2.472509649501371, -3.9714657643741704, -5.179214924704943, -1.7790070818492834, -0.43499149514545243, -0.8253315804435557, -0.22992524704956818, -5.03577376089834, -0.6844441915312105, -38.697473054788674, -31.18974105527492, -5.462535313189107, -2.400922172309668, -18.838450088451463, -5.968088555293984, -13.14908646599508, -0.2255440314904388, -2.3461523785993053, -0.15158646558469027, -3.4002864164955673, -16.563468247503767, -2.3432443113332946, -1.1757462818797761, -0.3139525189347932, -4.843549112348368, -2.444889147248816, -13.147391317735941, -0.40205014626252483, -1.5892512708397828, -27.96663002873732, -0.07577986667737328, -24.24019394154133]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18595038046636528, "mean_inference_ms": 0.6580878866050154, "mean_action_processing_ms": 0.044943315991787997, "mean_env_wait_ms": 0.2785516772561424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 41140, "timesteps_this_iter": 0, "agent_timesteps_total": 82280, "timers": {"sample_time_ms": 9429.408, "sample_throughput": 436.295, "load_time_ms": 0.159, "load_throughput": 25823655.576, "learn_time_ms": 5131.947, "learn_throughput": 801.645}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.08437500000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1346.472938068708, "policy_loss": 0.00048577727284282446, "vf_loss": 1346.4723050117493, "vf_explained_var": -0.2422630506878098, "kl": 0.001694393631900463, "entropy": 1.2312201511114835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 10.357659491617232, "policy_loss": -0.006591107762263467, "vf_loss": 10.364233454999825, "vf_explained_var": -0.38729122672230004, "kl": 0.003664580131779379, "entropy": 1.3895576401303211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 41140, "num_agent_steps_sampled": 82280, "num_steps_trained": 41140, "num_agent_steps_trained": 82280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 170, "training_iteration": 10, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-31-15", "timestamp": 1674487875, "time_this_iter_s": 9.945806741714478, "time_total_s": 99.35738325119019, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d7a9ee0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dace160>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 99.35738325119019, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 25.75714285714286, "ram_util_percent": 64.55714285714286}}
{"episode_reward_max": -11.357288056349114, "episode_reward_min": -3739.2474709275853, "episode_reward_mean": -135.6101104352354, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -3738.674516789818, "pol1": -105.45274933917288}, "policy_reward_max": {"pol0": -8.884778406847735, "pol1": -0.07577986667737328}, "policy_reward_mean": {"pol0": -124.6050007390149, "pol1": -11.005109696220519}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-88.58346140738549, -55.33357057786868, -100.52075195864066, -34.79439759246238, -50.94746438291117, -102.5860318050316, -31.416112062374214, -20.83954293700915, -213.47509440980323, -114.6295760654115, -33.96282528657823, -36.77456298293979, -22.63591812590621, -70.23045471158356, -58.28686330226573, -29.83575621383677, -39.73566984949155, -25.046626298830926, -58.51670265938564, -32.32136521200822, -21.727169292562188, -16.690383196726465, -24.61472985133992, -2124.940568045615, -24.059763209973386, -36.299537195044124, -35.398675429017736, -1794.5124758748568, -45.11229483026421, -30.79223466838268, -56.7504462242933, -32.82013237568637, -76.83192770068214, -32.68840199177839, -55.218695166932605, -28.068087715236146, -225.72958173780003, -29.592897626197953, -30.81441826140837, -39.06315305974218, -29.300460513939807, -59.225195889632424, -3739.2474709275853, -38.25959096337602, -65.70279812187636, -26.84502547222475, -58.81049686726013, -39.77549799468603, -37.51456690015647, -22.288686336215886, -22.520863512801366, -11.357288056349114, -994.4136822153226, -31.909865300891713, -28.89893590501002, -119.79540169517932, -35.90843478723304, -116.09492854467277, -21.28194454554536, -42.60636960365147, -54.34616085073287, -51.50266937912103, -45.62923144788693, -30.072555583484434, -32.21274073841765, -25.25779679458743, -22.8918907697962, -92.61992888929635, -18.964351267194093, -29.063487527128416, -24.372822121460786, -36.47260202236706, -44.31230730815977, -18.40929475655898, -13.996826448683418, -24.773848809450538, -49.33494409977525, -26.882867586728352, -41.68199543905691, -399.69874746464575, -52.02966776519293, -53.426634717366, -66.11018604654186, -36.29201554316554, -21.173486220331405, -26.840450104737528, -273.35406954766233, -48.99976801974316, -46.39448404029582, -21.37638830765166, -45.96460744041919, -30.2633263160318, -28.36477664867284, -18.070504587506992, -22.855420199929878, -18.386707550483816, -45.54406408023343, -27.84435320727111, -25.500544208199486, -45.766694218699485], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-35.110491831893334, -35.67938514493914, -60.923310496219436, -16.99815048279172, -33.23205526050868, -50.91527627365333, -18.55143955973478, -20.2197990940667, -108.02234507063042, -103.94286108026617, -33.59115925352741, -33.31931211417811, -18.194536099986703, -45.490604746343, -22.665931603165454, -19.446100496880046, -35.668263391961624, -16.48404306716454, -32.588522186993096, -32.12773920627723, -18.029722324899378, -14.077268269941337, -21.760243910908642, -2121.6919212172197, -22.99222626965996, -35.73012782471864, -34.970464128168175, -1792.496384315576, -16.863854886807793, -25.093559617009028, -56.398557952963685, -15.449432818022068, -39.068940993225524, -27.892760688296164, -38.32652429327798, -12.738385653620222, -219.666558144741, -27.996058038608346, -13.115124231634985, -35.81435156903055, -12.35094618178002, -58.80946997763657, -3738.674516789818, -37.914395457933445, -24.688627400208592, -25.63795344775887, -37.27939797000974, -38.69761048348349, -37.114555298457056, -14.478202680708144, -20.825313741041942, -8.884778406847735, -990.4422164509485, -26.730650376186784, -27.119928823160734, -119.36041020003387, -35.083103206789524, -115.86500329762323, -16.246170784647017, -41.921925412120245, -15.648687795944213, -20.31292832384606, -40.16669613469782, -27.67163341117477, -13.374290649966206, -19.28970823929346, -9.742804303801124, -92.39438485780589, -16.61819888859476, -28.91190106154374, -20.972535704965225, -19.909133774863307, -41.96906299682648, -17.23354847467919, -13.682873929748625, -19.930299697102182, -46.890054952526405, -13.735476268992397, -41.27994529279439, -398.109496193806, -24.0630377364556, -53.35085485068864, -41.86999210500049, -15.528238513457769, -17.178207468981, -16.915506169838626, -269.02372649979657, -47.482412343147374, -22.233329911820505, -10.871326582979497, -18.38528527809879, -18.74446503157039, -25.57916408093543, -14.39533483671573, -17.025000219114272, -14.859942714235764, -45.299146191900995, -17.066428238485056, -16.227075647022474, -45.08896853157011], "policy_pol1_reward": [-53.472969575492165, -19.654185432929534, -39.59744146242118, -17.79624710967067, -17.715409122402512, -51.670755531378305, -12.864672502639426, -0.619743842942456, -105.45274933917288, -10.686714985145256, -0.3716660330508036, -3.455250868761699, -4.441382025919497, -24.739849965240513, -35.62093169910025, -10.389655716956742, -4.067406457529922, -8.562583231666384, -25.928180472392548, -0.19362600573100622, -3.697446967662814, -2.613114926785112, -2.8544859404312564, -3.2486468283946337, -1.0675369403134334, -0.5694093703254464, -0.42821130084955855, -2.0160915592810165, -28.248439943456418, -5.6986750513736695, -0.35188827132960404, -17.370699557664285, -37.762986707456584, -4.795641303482234, -16.892170873654642, -15.329702061615942, -6.063023593059015, -1.596839587589603, -17.699294029773394, -3.2488014907116387, -16.949514332159794, -0.41572591199580944, -0.5729541377675601, -0.34519550544255967, -41.014170721667746, -1.2070720244658657, -21.531098897250384, -1.077887511202534, -0.4000116016994149, -7.810483655507712, -1.695549771759439, -2.472509649501371, -3.9714657643741704, -5.179214924704943, -1.7790070818492834, -0.43499149514545243, -0.8253315804435557, -0.22992524704956818, -5.03577376089834, -0.6844441915312105, -38.697473054788674, -31.18974105527492, -5.462535313189107, -2.400922172309668, -18.838450088451463, -5.968088555293984, -13.14908646599508, -0.2255440314904388, -2.3461523785993053, -0.15158646558469027, -3.4002864164955673, -16.563468247503767, -2.3432443113332946, -1.1757462818797761, -0.3139525189347932, -4.843549112348368, -2.444889147248816, -13.147391317735941, -0.40205014626252483, -1.5892512708397828, -27.96663002873732, -0.07577986667737328, -24.24019394154133, -20.763777029707732, -3.995278751350412, -9.924943934898934, -4.330343047865919, -1.5173556765957943, -24.161154128475317, -10.505061724672174, -27.57932216232041, -11.5188612844614, -2.7856125677373966, -3.675169750791249, -5.830419980815612, -3.5267648362480672, -0.24491788833241523, -10.77792496878607, -9.273468561177038, -0.6777256871293584]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18579051408154207, "mean_inference_ms": 0.6579748077225667, "mean_action_processing_ms": 0.04492143122284015, "mean_env_wait_ms": 0.2783323799936369, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 45254, "timesteps_this_iter": 0, "agent_timesteps_total": 90508, "timers": {"sample_time_ms": 9942.009, "sample_throughput": 413.8, "load_time_ms": 0.16, "load_throughput": 25673808.445, "learn_time_ms": 5131.147, "learn_throughput": 801.77}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.04218750000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 633.640802526474, "policy_loss": -0.002198278576543089, "vf_loss": 633.6428109765053, "vf_explained_var": -0.3904185293863217, "kl": 0.00451865714669566, "entropy": 1.3567437959214053, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0023437499999999995, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.667466884292662, "policy_loss": -0.012688772337666403, "vf_loss": 7.68006585529074, "vf_explained_var": -0.23260764653484026, "kl": 0.03830484325740902, "entropy": 1.401938733831048, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 45254, "num_agent_steps_sampled": 90508, "num_steps_trained": 45254, "num_agent_steps_trained": 90508, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 187, "training_iteration": 11, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-31-25", "timestamp": 1674487885, "time_this_iter_s": 9.983100175857544, "time_total_s": 109.34048342704773, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d29e0d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dac81f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 109.34048342704773, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 25.807142857142857, "ram_util_percent": 64.60000000000001}}
{"episode_reward_max": -11.357288056349114, "episode_reward_min": -3739.2474709275853, "episode_reward_mean": -129.728199827456, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -3738.674516789818, "pol1": -41.014170721667746}, "policy_reward_max": {"pol0": -8.884778406847735, "pol1": -0.07142950865268564}, "policy_reward_mean": {"pol0": -121.49551276609691, "pol1": -8.232687061359114}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.046626298830926, -58.51670265938564, -32.32136521200822, -21.727169292562188, -16.690383196726465, -24.61472985133992, -2124.940568045615, -24.059763209973386, -36.299537195044124, -35.398675429017736, -1794.5124758748568, -45.11229483026421, -30.79223466838268, -56.7504462242933, -32.82013237568637, -76.83192770068214, -32.68840199177839, -55.218695166932605, -28.068087715236146, -225.72958173780003, -29.592897626197953, -30.81441826140837, -39.06315305974218, -29.300460513939807, -59.225195889632424, -3739.2474709275853, -38.25959096337602, -65.70279812187636, -26.84502547222475, -58.81049686726013, -39.77549799468603, -37.51456690015647, -22.288686336215886, -22.520863512801366, -11.357288056349114, -994.4136822153226, -31.909865300891713, -28.89893590501002, -119.79540169517932, -35.90843478723304, -116.09492854467277, -21.28194454554536, -42.60636960365147, -54.34616085073287, -51.50266937912103, -45.62923144788693, -30.072555583484434, -32.21274073841765, -25.25779679458743, -22.8918907697962, -92.61992888929635, -18.964351267194093, -29.063487527128416, -24.372822121460786, -36.47260202236706, -44.31230730815977, -18.40929475655898, -13.996826448683418, -24.773848809450538, -49.33494409977525, -26.882867586728352, -41.68199543905691, -399.69874746464575, -52.02966776519293, -53.426634717366, -66.11018604654186, -36.29201554316554, -21.173486220331405, -26.840450104737528, -273.35406954766233, -48.99976801974316, -46.39448404029582, -21.37638830765166, -45.96460744041919, -30.2633263160318, -28.36477664867284, -18.070504587506992, -22.855420199929878, -18.386707550483816, -45.54406408023343, -27.84435320727111, -25.500544208199486, -45.766694218699485, -17.800304597124835, -26.075477110863723, -39.97268670211753, -49.37647155661462, -22.79727619735808, -44.90763977065561, -25.328306696488852, -36.8029894572366, -25.524994386266602, -32.280920000284844, -26.713265988561925, -34.64251252841926, -31.703129667027817, -15.405211108599232, -23.524252315921945, -44.968231746128275, -18.573323063890566], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-16.48404306716454, -32.588522186993096, -32.12773920627723, -18.029722324899378, -14.077268269941337, -21.760243910908642, -2121.6919212172197, -22.99222626965996, -35.73012782471864, -34.970464128168175, -1792.496384315576, -16.863854886807793, -25.093559617009028, -56.398557952963685, -15.449432818022068, -39.068940993225524, -27.892760688296164, -38.32652429327798, -12.738385653620222, -219.666558144741, -27.996058038608346, -13.115124231634985, -35.81435156903055, -12.35094618178002, -58.80946997763657, -3738.674516789818, -37.914395457933445, -24.688627400208592, -25.63795344775887, -37.27939797000974, -38.69761048348349, -37.114555298457056, -14.478202680708144, -20.825313741041942, -8.884778406847735, -990.4422164509485, -26.730650376186784, -27.119928823160734, -119.36041020003387, -35.083103206789524, -115.86500329762323, -16.246170784647017, -41.921925412120245, -15.648687795944213, -20.31292832384606, -40.16669613469782, -27.67163341117477, -13.374290649966206, -19.28970823929346, -9.742804303801124, -92.39438485780589, -16.61819888859476, -28.91190106154374, -20.972535704965225, -19.909133774863307, -41.96906299682648, -17.23354847467919, -13.682873929748625, -19.930299697102182, -46.890054952526405, -13.735476268992397, -41.27994529279439, -398.109496193806, -24.0630377364556, -53.35085485068864, -41.86999210500049, -15.528238513457769, -17.178207468981, -16.915506169838626, -269.02372649979657, -47.482412343147374, -22.233329911820505, -10.871326582979497, -18.38528527809879, -18.74446503157039, -25.57916408093543, -14.39533483671573, -17.025000219114272, -14.859942714235764, -45.299146191900995, -17.066428238485056, -16.227075647022474, -45.08896853157011, -13.292424296838675, -24.261039848843684, -36.52164697632977, -27.842073561813017, -18.708299670692718, -39.324433153549954, -21.498063192577106, -16.900584161524666, -23.4713684093393, -27.489804308951943, -19.723137031495643, -21.289042351376434, -31.631700158375118, -11.311772543944997, -19.008079037528983, -14.25167787017905, -14.497078135586023], "policy_pol1_reward": [-8.562583231666384, -25.928180472392548, -0.19362600573100622, -3.697446967662814, -2.613114926785112, -2.8544859404312564, -3.2486468283946337, -1.0675369403134334, -0.5694093703254464, -0.42821130084955855, -2.0160915592810165, -28.248439943456418, -5.6986750513736695, -0.35188827132960404, -17.370699557664285, -37.762986707456584, -4.795641303482234, -16.892170873654642, -15.329702061615942, -6.063023593059015, -1.596839587589603, -17.699294029773394, -3.2488014907116387, -16.949514332159794, -0.41572591199580944, -0.5729541377675601, -0.34519550544255967, -41.014170721667746, -1.2070720244658657, -21.531098897250384, -1.077887511202534, -0.4000116016994149, -7.810483655507712, -1.695549771759439, -2.472509649501371, -3.9714657643741704, -5.179214924704943, -1.7790070818492834, -0.43499149514545243, -0.8253315804435557, -0.22992524704956818, -5.03577376089834, -0.6844441915312105, -38.697473054788674, -31.18974105527492, -5.462535313189107, -2.400922172309668, -18.838450088451463, -5.968088555293984, -13.14908646599508, -0.2255440314904388, -2.3461523785993053, -0.15158646558469027, -3.4002864164955673, -16.563468247503767, -2.3432443113332946, -1.1757462818797761, -0.3139525189347932, -4.843549112348368, -2.444889147248816, -13.147391317735941, -0.40205014626252483, -1.5892512708397828, -27.96663002873732, -0.07577986667737328, -24.24019394154133, -20.763777029707732, -3.995278751350412, -9.924943934898934, -4.330343047865919, -1.5173556765957943, -24.161154128475317, -10.505061724672174, -27.57932216232041, -11.5188612844614, -2.7856125677373966, -3.675169750791249, -5.830419980815612, -3.5267648362480672, -0.24491788833241523, -10.77792496878607, -9.273468561177038, -0.6777256871293584, -4.507880300286165, -1.8144372620200386, -3.451039725787778, -21.534397994801623, -4.0889765266653395, -5.583206617105641, -3.8302435039117366, -19.902405295711926, -2.0536259769273135, -4.791115691332888, -6.9901289570662835, -13.353470177042809, -0.07142950865268564, -4.093438564654228, -4.516173278392957, -30.716553875949213, -4.076244928304542]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.185524392838827, "mean_inference_ms": 0.6577550325778891, "mean_action_processing_ms": 0.04488723150645074, "mean_env_wait_ms": 0.27814699893491074, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 49368, "timesteps_this_iter": 0, "agent_timesteps_total": 98736, "timers": {"sample_time_ms": 9936.933, "sample_throughput": 414.011, "load_time_ms": 0.159, "load_throughput": 25912849.761, "learn_time_ms": 5128.683, "learn_throughput": 802.155}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.021093750000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 111.64997586011887, "policy_loss": -0.0030266673071309923, "vf_loss": 111.6528118982911, "vf_explained_var": -0.5609019692987204, "kl": 0.00902851449782247, "entropy": 1.1837428239484629, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.589549980277662, "policy_loss": 0.0001894693976889054, "vf_loss": 7.589329822446841, "vf_explained_var": -0.3856398665656646, "kl": 0.008734971127463116, "entropy": 1.3508554014066856, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 49368, "num_agent_steps_sampled": 98736, "num_steps_trained": 49368, "num_agent_steps_trained": 98736, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 204, "training_iteration": 12, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-31-35", "timestamp": 1674487895, "time_this_iter_s": 9.92584490776062, "time_total_s": 119.26632833480835, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d770940>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x17f2cf940>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 119.26632833480835, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 26.428571428571427, "ram_util_percent": 64.65000000000002}}
{"episode_reward_max": -11.357288056349114, "episode_reward_min": -3739.2474709275853, "episode_reward_mean": -90.51959706202422, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -3738.674516789818, "pol1": -55.67691427488832}, "policy_reward_max": {"pol0": -8.884778406847735, "pol1": -0.07142950865268564}, "policy_reward_mean": {"pol0": -81.6431398823952, "pol1": -8.876457179629051}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-55.218695166932605, -28.068087715236146, -225.72958173780003, -29.592897626197953, -30.81441826140837, -39.06315305974218, -29.300460513939807, -59.225195889632424, -3739.2474709275853, -38.25959096337602, -65.70279812187636, -26.84502547222475, -58.81049686726013, -39.77549799468603, -37.51456690015647, -22.288686336215886, -22.520863512801366, -11.357288056349114, -994.4136822153226, -31.909865300891713, -28.89893590501002, -119.79540169517932, -35.90843478723304, -116.09492854467277, -21.28194454554536, -42.60636960365147, -54.34616085073287, -51.50266937912103, -45.62923144788693, -30.072555583484434, -32.21274073841765, -25.25779679458743, -22.8918907697962, -92.61992888929635, -18.964351267194093, -29.063487527128416, -24.372822121460786, -36.47260202236706, -44.31230730815977, -18.40929475655898, -13.996826448683418, -24.773848809450538, -49.33494409977525, -26.882867586728352, -41.68199543905691, -399.69874746464575, -52.02966776519293, -53.426634717366, -66.11018604654186, -36.29201554316554, -21.173486220331405, -26.840450104737528, -273.35406954766233, -48.99976801974316, -46.39448404029582, -21.37638830765166, -45.96460744041919, -30.2633263160318, -28.36477664867284, -18.070504587506992, -22.855420199929878, -18.386707550483816, -45.54406408023343, -27.84435320727111, -25.500544208199486, -45.766694218699485, -17.800304597124835, -26.075477110863723, -39.97268670211753, -49.37647155661462, -22.79727619735808, -44.90763977065561, -25.328306696488852, -36.8029894572366, -25.524994386266602, -32.280920000284844, -26.713265988561925, -34.64251252841926, -31.703129667027817, -15.405211108599232, -23.524252315921945, -44.968231746128275, -18.573323063890566, -21.165607478662185, -34.505321140909885, -92.14352673715663, -48.47003447070555, -24.254321890520355, -18.71989876519827, -21.749412759616835, -17.379398028164207, -19.11696744161234, -22.85067746489413, -20.083869344876476, -16.723938280960358, -45.470357258216055, -26.07680788537805, -61.134849850585645, -18.872287209028176, -39.54588150678173], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-38.32652429327798, -12.738385653620222, -219.666558144741, -27.996058038608346, -13.115124231634985, -35.81435156903055, -12.35094618178002, -58.80946997763657, -3738.674516789818, -37.914395457933445, -24.688627400208592, -25.63795344775887, -37.27939797000974, -38.69761048348349, -37.114555298457056, -14.478202680708144, -20.825313741041942, -8.884778406847735, -990.4422164509485, -26.730650376186784, -27.119928823160734, -119.36041020003387, -35.083103206789524, -115.86500329762323, -16.246170784647017, -41.921925412120245, -15.648687795944213, -20.31292832384606, -40.16669613469782, -27.67163341117477, -13.374290649966206, -19.28970823929346, -9.742804303801124, -92.39438485780589, -16.61819888859476, -28.91190106154374, -20.972535704965225, -19.909133774863307, -41.96906299682648, -17.23354847467919, -13.682873929748625, -19.930299697102182, -46.890054952526405, -13.735476268992397, -41.27994529279439, -398.109496193806, -24.0630377364556, -53.35085485068864, -41.86999210500049, -15.528238513457769, -17.178207468981, -16.915506169838626, -269.02372649979657, -47.482412343147374, -22.233329911820505, -10.871326582979497, -18.38528527809879, -18.74446503157039, -25.57916408093543, -14.39533483671573, -17.025000219114272, -14.859942714235764, -45.299146191900995, -17.066428238485056, -16.227075647022474, -45.08896853157011, -13.292424296838675, -24.261039848843684, -36.52164697632977, -27.842073561813017, -18.708299670692718, -39.324433153549954, -21.498063192577106, -16.900584161524666, -23.4713684093393, -27.489804308951943, -19.723137031495643, -21.289042351376434, -31.631700158375118, -11.311772543944997, -19.008079037528983, -14.25167787017905, -14.497078135586023, -14.751928148071089, -33.6017744258267, -36.466612462268394, -17.52148453265851, -12.982944628390122, -13.84944501579948, -11.999748519877139, -14.186898206616751, -11.193581669986688, -19.138566154234663, -15.59144807127326, -14.767389885665148, -24.60507774661097, -17.652198011933855, -24.715281296541956, -16.5230076680182, -38.93109486390414], "policy_pol1_reward": [-16.892170873654642, -15.329702061615942, -6.063023593059015, -1.596839587589603, -17.699294029773394, -3.2488014907116387, -16.949514332159794, -0.41572591199580944, -0.5729541377675601, -0.34519550544255967, -41.014170721667746, -1.2070720244658657, -21.531098897250384, -1.077887511202534, -0.4000116016994149, -7.810483655507712, -1.695549771759439, -2.472509649501371, -3.9714657643741704, -5.179214924704943, -1.7790070818492834, -0.43499149514545243, -0.8253315804435557, -0.22992524704956818, -5.03577376089834, -0.6844441915312105, -38.697473054788674, -31.18974105527492, -5.462535313189107, -2.400922172309668, -18.838450088451463, -5.968088555293984, -13.14908646599508, -0.2255440314904388, -2.3461523785993053, -0.15158646558469027, -3.4002864164955673, -16.563468247503767, -2.3432443113332946, -1.1757462818797761, -0.3139525189347932, -4.843549112348368, -2.444889147248816, -13.147391317735941, -0.40205014626252483, -1.5892512708397828, -27.96663002873732, -0.07577986667737328, -24.24019394154133, -20.763777029707732, -3.995278751350412, -9.924943934898934, -4.330343047865919, -1.5173556765957943, -24.161154128475317, -10.505061724672174, -27.57932216232041, -11.5188612844614, -2.7856125677373966, -3.675169750791249, -5.830419980815612, -3.5267648362480672, -0.24491788833241523, -10.77792496878607, -9.273468561177038, -0.6777256871293584, -4.507880300286165, -1.8144372620200386, -3.451039725787778, -21.534397994801623, -4.0889765266653395, -5.583206617105641, -3.8302435039117366, -19.902405295711926, -2.0536259769273135, -4.791115691332888, -6.9901289570662835, -13.353470177042809, -0.07142950865268564, -4.093438564654228, -4.516173278392957, -30.716553875949213, -4.076244928304542, -6.413679330591105, -0.9035467150831741, -55.67691427488832, -30.948549938047034, -11.271377262130228, -4.870453749398807, -9.7496642397397, -3.192499821547457, -7.92338577162561, -3.712111310659468, -4.4924212736031945, -1.9565483952951939, -20.86527951160505, -8.424609873444199, -36.419568554043714, -2.349279541009968, -0.6147866428775839]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1852838535691577, "mean_inference_ms": 0.6574909980707646, "mean_action_processing_ms": 0.044851814380058634, "mean_env_wait_ms": 0.27798112288396426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 53482, "timesteps_this_iter": 0, "agent_timesteps_total": 106964, "timers": {"sample_time_ms": 9938.695, "sample_throughput": 413.938, "load_time_ms": 0.158, "load_throughput": 26093099.434, "learn_time_ms": 5140.992, "learn_throughput": 800.235}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.021093750000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 41.080490513518455, "policy_loss": -0.0018868421825269858, "vf_loss": 41.08228879297773, "vf_explained_var": -0.37717165270199376, "kl": 0.004186279029818251, "entropy": 1.1576973586032788, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 25.642005991053885, "policy_loss": -0.001240640024965008, "vf_loss": 25.64321033253024, "vf_explained_var": -0.38846925292164086, "kl": 0.010350196792175363, "entropy": 1.3792871586978435, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 53482, "num_agent_steps_sampled": 106964, "num_steps_trained": 53482, "num_agent_steps_trained": 106964, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 221, "training_iteration": 13, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-31-45", "timestamp": 1674487905, "time_this_iter_s": 9.978793859481812, "time_total_s": 129.24512219429016, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x17f53f430>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dad7f70>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 129.24512219429016, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 25.957142857142856, "ram_util_percent": 64.7785714285714}}
{"episode_reward_max": -11.357288056349114, "episode_reward_min": -994.4136822153226, "episode_reward_mean": -50.38509244613897, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -990.4422164509485, "pol1": -55.67691427488832}, "policy_reward_max": {"pol0": -8.591335636665619, "pol1": -0.07142950865268564}, "policy_reward_mean": {"pol0": -41.16773965762666, "pol1": -9.217352788512304}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.357288056349114, -994.4136822153226, -31.909865300891713, -28.89893590501002, -119.79540169517932, -35.90843478723304, -116.09492854467277, -21.28194454554536, -42.60636960365147, -54.34616085073287, -51.50266937912103, -45.62923144788693, -30.072555583484434, -32.21274073841765, -25.25779679458743, -22.8918907697962, -92.61992888929635, -18.964351267194093, -29.063487527128416, -24.372822121460786, -36.47260202236706, -44.31230730815977, -18.40929475655898, -13.996826448683418, -24.773848809450538, -49.33494409977525, -26.882867586728352, -41.68199543905691, -399.69874746464575, -52.02966776519293, -53.426634717366, -66.11018604654186, -36.29201554316554, -21.173486220331405, -26.840450104737528, -273.35406954766233, -48.99976801974316, -46.39448404029582, -21.37638830765166, -45.96460744041919, -30.2633263160318, -28.36477664867284, -18.070504587506992, -22.855420199929878, -18.386707550483816, -45.54406408023343, -27.84435320727111, -25.500544208199486, -45.766694218699485, -17.800304597124835, -26.075477110863723, -39.97268670211753, -49.37647155661462, -22.79727619735808, -44.90763977065561, -25.328306696488852, -36.8029894572366, -25.524994386266602, -32.280920000284844, -26.713265988561925, -34.64251252841926, -31.703129667027817, -15.405211108599232, -23.524252315921945, -44.968231746128275, -18.573323063890566, -21.165607478662185, -34.505321140909885, -92.14352673715663, -48.47003447070555, -24.254321890520355, -18.71989876519827, -21.749412759616835, -17.379398028164207, -19.11696744161234, -22.85067746489413, -20.083869344876476, -16.723938280960358, -45.470357258216055, -26.07680788537805, -61.134849850585645, -18.872287209028176, -39.54588150678173, -44.734718128544465, -25.18790839028302, -18.599089966210837, -18.049655827535034, -74.1007286036802, -21.906916952874727, -23.933769087325544, -24.202584320582634, -81.61311103055378, -31.37994429394173, -38.52567112794281, -16.70021507628338, -16.90999373080723, -31.643185436045524, -17.799655663902925, -23.072317210264, -26.167560631767987], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-8.884778406847735, -990.4422164509485, -26.730650376186784, -27.119928823160734, -119.36041020003387, -35.083103206789524, -115.86500329762323, -16.246170784647017, -41.921925412120245, -15.648687795944213, -20.31292832384606, -40.16669613469782, -27.67163341117477, -13.374290649966206, -19.28970823929346, -9.742804303801124, -92.39438485780589, -16.61819888859476, -28.91190106154374, -20.972535704965225, -19.909133774863307, -41.96906299682648, -17.23354847467919, -13.682873929748625, -19.930299697102182, -46.890054952526405, -13.735476268992397, -41.27994529279439, -398.109496193806, -24.0630377364556, -53.35085485068864, -41.86999210500049, -15.528238513457769, -17.178207468981, -16.915506169838626, -269.02372649979657, -47.482412343147374, -22.233329911820505, -10.871326582979497, -18.38528527809879, -18.74446503157039, -25.57916408093543, -14.39533483671573, -17.025000219114272, -14.859942714235764, -45.299146191900995, -17.066428238485056, -16.227075647022474, -45.08896853157011, -13.292424296838675, -24.261039848843684, -36.52164697632977, -27.842073561813017, -18.708299670692718, -39.324433153549954, -21.498063192577106, -16.900584161524666, -23.4713684093393, -27.489804308951943, -19.723137031495643, -21.289042351376434, -31.631700158375118, -11.311772543944997, -19.008079037528983, -14.25167787017905, -14.497078135586023, -14.751928148071089, -33.6017744258267, -36.466612462268394, -17.52148453265851, -12.982944628390122, -13.84944501579948, -11.999748519877139, -14.186898206616751, -11.193581669986688, -19.138566154234663, -15.59144807127326, -14.767389885665148, -24.60507774661097, -17.652198011933855, -24.715281296541956, -16.5230076680182, -38.93109486390414, -31.981470914966255, -11.636188848836152, -8.591335636665619, -16.60763706436268, -30.09574974279532, -18.63356486289575, -19.5624794029486, -17.252138825953658, -55.09098499805132, -27.04770184511824, -22.49634374721273, -10.900088473826731, -14.109986768442987, -12.54064346631624, -15.104117169065297, -19.863618768454796, -15.073918346985135], "policy_pol1_reward": [-2.472509649501371, -3.9714657643741704, -5.179214924704943, -1.7790070818492834, -0.43499149514545243, -0.8253315804435557, -0.22992524704956818, -5.03577376089834, -0.6844441915312105, -38.697473054788674, -31.18974105527492, -5.462535313189107, -2.400922172309668, -18.838450088451463, -5.968088555293984, -13.14908646599508, -0.2255440314904388, -2.3461523785993053, -0.15158646558469027, -3.4002864164955673, -16.563468247503767, -2.3432443113332946, -1.1757462818797761, -0.3139525189347932, -4.843549112348368, -2.444889147248816, -13.147391317735941, -0.40205014626252483, -1.5892512708397828, -27.96663002873732, -0.07577986667737328, -24.24019394154133, -20.763777029707732, -3.995278751350412, -9.924943934898934, -4.330343047865919, -1.5173556765957943, -24.161154128475317, -10.505061724672174, -27.57932216232041, -11.5188612844614, -2.7856125677373966, -3.675169750791249, -5.830419980815612, -3.5267648362480672, -0.24491788833241523, -10.77792496878607, -9.273468561177038, -0.6777256871293584, -4.507880300286165, -1.8144372620200386, -3.451039725787778, -21.534397994801623, -4.0889765266653395, -5.583206617105641, -3.8302435039117366, -19.902405295711926, -2.0536259769273135, -4.791115691332888, -6.9901289570662835, -13.353470177042809, -0.07142950865268564, -4.093438564654228, -4.516173278392957, -30.716553875949213, -4.076244928304542, -6.413679330591105, -0.9035467150831741, -55.67691427488832, -30.948549938047034, -11.271377262130228, -4.870453749398807, -9.7496642397397, -3.192499821547457, -7.92338577162561, -3.712111310659468, -4.4924212736031945, -1.9565483952951939, -20.86527951160505, -8.424609873444199, -36.419568554043714, -2.349279541009968, -0.6147866428775839, -12.753247213578156, -13.551719541446884, -10.007754329545214, -1.442018763172343, -44.00497886088494, -3.2733520899789577, -4.371289684376962, -6.950445494628971, -26.522126032502477, -4.3322424488235, -16.029327380730056, -5.800126602456652, -2.800006962364243, -19.102541969729295, -2.695538494837607, -3.2086984418091906, -11.093642284782844]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18510145271483636, "mean_inference_ms": 0.657280257214611, "mean_action_processing_ms": 0.04481980411710707, "mean_env_wait_ms": 0.27781785577908136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 57596, "timesteps_this_iter": 0, "agent_timesteps_total": 115192, "timers": {"sample_time_ms": 9948.124, "sample_throughput": 413.545, "load_time_ms": 0.158, "load_throughput": 26077326.063, "learn_time_ms": 5140.571, "learn_throughput": 800.3}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 29.47345945443958, "policy_loss": 0.0017715018223195026, "vf_loss": 29.47161059541007, "vf_explained_var": -0.19462741985917092, "kl": 0.007331506676928256, "entropy": 1.0599713186733424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 14.709132003225386, "policy_loss": -0.0007457733930399021, "vf_loss": 14.709817133223018, "vf_explained_var": -0.36532537726064523, "kl": 0.01722510885635226, "entropy": 1.3597368768105904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 57596, "num_agent_steps_sampled": 115192, "num_steps_trained": 57596, "num_agent_steps_trained": 115192, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 238, "training_iteration": 14, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-31-55", "timestamp": 1674487915, "time_this_iter_s": 9.917572975158691, "time_total_s": 139.16269516944885, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dac81f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dae0940>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 139.16269516944885, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 26.064285714285713, "ram_util_percent": 64.69285714285714}}
{"episode_reward_max": -13.996826448683418, "episode_reward_min": -399.69874746464575, "episode_reward_mean": -39.070504548677356, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -398.109496193806, "pol1": -55.67691427488832}, "policy_reward_max": {"pol0": -8.591335636665619, "pol1": -0.07142950865268564}, "policy_reward_mean": {"pol0": -29.159471523608897, "pol1": -9.91103302506846}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.964351267194093, -29.063487527128416, -24.372822121460786, -36.47260202236706, -44.31230730815977, -18.40929475655898, -13.996826448683418, -24.773848809450538, -49.33494409977525, -26.882867586728352, -41.68199543905691, -399.69874746464575, -52.02966776519293, -53.426634717366, -66.11018604654186, -36.29201554316554, -21.173486220331405, -26.840450104737528, -273.35406954766233, -48.99976801974316, -46.39448404029582, -21.37638830765166, -45.96460744041919, -30.2633263160318, -28.36477664867284, -18.070504587506992, -22.855420199929878, -18.386707550483816, -45.54406408023343, -27.84435320727111, -25.500544208199486, -45.766694218699485, -17.800304597124835, -26.075477110863723, -39.97268670211753, -49.37647155661462, -22.79727619735808, -44.90763977065561, -25.328306696488852, -36.8029894572366, -25.524994386266602, -32.280920000284844, -26.713265988561925, -34.64251252841926, -31.703129667027817, -15.405211108599232, -23.524252315921945, -44.968231746128275, -18.573323063890566, -21.165607478662185, -34.505321140909885, -92.14352673715663, -48.47003447070555, -24.254321890520355, -18.71989876519827, -21.749412759616835, -17.379398028164207, -19.11696744161234, -22.85067746489413, -20.083869344876476, -16.723938280960358, -45.470357258216055, -26.07680788537805, -61.134849850585645, -18.872287209028176, -39.54588150678173, -44.734718128544465, -25.18790839028302, -18.599089966210837, -18.049655827535034, -74.1007286036802, -21.906916952874727, -23.933769087325544, -24.202584320582634, -81.61311103055378, -31.37994429394173, -38.52567112794281, -16.70021507628338, -16.90999373080723, -31.643185436045524, -17.799655663902925, -23.072317210264, -26.167560631767987, -31.972457564835075, -109.91469517097299, -24.40471975325186, -57.225101288830075, -65.32887196507451, -18.51150697853853, -38.66412553000017, -49.086228375035795, -29.870084395134676, -17.11905022243152, -32.77879275510993, -25.038946015235116, -22.78442047391749, -20.725551908699018, -18.463881529616803, -25.254360842552753, -38.19824059178073], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-16.61819888859476, -28.91190106154374, -20.972535704965225, -19.909133774863307, -41.96906299682648, -17.23354847467919, -13.682873929748625, -19.930299697102182, -46.890054952526405, -13.735476268992397, -41.27994529279439, -398.109496193806, -24.0630377364556, -53.35085485068864, -41.86999210500049, -15.528238513457769, -17.178207468981, -16.915506169838626, -269.02372649979657, -47.482412343147374, -22.233329911820505, -10.871326582979497, -18.38528527809879, -18.74446503157039, -25.57916408093543, -14.39533483671573, -17.025000219114272, -14.859942714235764, -45.299146191900995, -17.066428238485056, -16.227075647022474, -45.08896853157011, -13.292424296838675, -24.261039848843684, -36.52164697632977, -27.842073561813017, -18.708299670692718, -39.324433153549954, -21.498063192577106, -16.900584161524666, -23.4713684093393, -27.489804308951943, -19.723137031495643, -21.289042351376434, -31.631700158375118, -11.311772543944997, -19.008079037528983, -14.25167787017905, -14.497078135586023, -14.751928148071089, -33.6017744258267, -36.466612462268394, -17.52148453265851, -12.982944628390122, -13.84944501579948, -11.999748519877139, -14.186898206616751, -11.193581669986688, -19.138566154234663, -15.59144807127326, -14.767389885665148, -24.60507774661097, -17.652198011933855, -24.715281296541956, -16.5230076680182, -38.93109486390414, -31.981470914966255, -11.636188848836152, -8.591335636665619, -16.60763706436268, -30.09574974279532, -18.63356486289575, -19.5624794029486, -17.252138825953658, -55.09098499805132, -27.04770184511824, -22.49634374721273, -10.900088473826731, -14.109986768442987, -12.54064346631624, -15.104117169065297, -19.863618768454796, -15.073918346985135, -17.914388696301383, -95.98665145173503, -22.365439763674605, -22.406872429108244, -26.401497372684805, -17.674101906386348, -12.666080329029992, -47.18379246447307, -11.943126654759979, -10.058088020114976, -31.006302903126777, -14.37416000116055, -19.32623575072512, -11.977740282773912, -17.028821915884613, -24.49585685417496, -16.619350476995848], "policy_pol1_reward": [-2.3461523785993053, -0.15158646558469027, -3.4002864164955673, -16.563468247503767, -2.3432443113332946, -1.1757462818797761, -0.3139525189347932, -4.843549112348368, -2.444889147248816, -13.147391317735941, -0.40205014626252483, -1.5892512708397828, -27.96663002873732, -0.07577986667737328, -24.24019394154133, -20.763777029707732, -3.995278751350412, -9.924943934898934, -4.330343047865919, -1.5173556765957943, -24.161154128475317, -10.505061724672174, -27.57932216232041, -11.5188612844614, -2.7856125677373966, -3.675169750791249, -5.830419980815612, -3.5267648362480672, -0.24491788833241523, -10.77792496878607, -9.273468561177038, -0.6777256871293584, -4.507880300286165, -1.8144372620200386, -3.451039725787778, -21.534397994801623, -4.0889765266653395, -5.583206617105641, -3.8302435039117366, -19.902405295711926, -2.0536259769273135, -4.791115691332888, -6.9901289570662835, -13.353470177042809, -0.07142950865268564, -4.093438564654228, -4.516173278392957, -30.716553875949213, -4.076244928304542, -6.413679330591105, -0.9035467150831741, -55.67691427488832, -30.948549938047034, -11.271377262130228, -4.870453749398807, -9.7496642397397, -3.192499821547457, -7.92338577162561, -3.712111310659468, -4.4924212736031945, -1.9565483952951939, -20.86527951160505, -8.424609873444199, -36.419568554043714, -2.349279541009968, -0.6147866428775839, -12.753247213578156, -13.551719541446884, -10.007754329545214, -1.442018763172343, -44.00497886088494, -3.2733520899789577, -4.371289684376962, -6.950445494628971, -26.522126032502477, -4.3322424488235, -16.029327380730056, -5.800126602456652, -2.800006962364243, -19.102541969729295, -2.695538494837607, -3.2086984418091906, -11.093642284782844, -14.058068868533677, -13.928043719238023, -2.0392799895772447, -34.81822885972182, -38.927374592389704, -0.8374050721521912, -25.9980452009702, -1.9024359105626942, -17.926957740374696, -7.060962202316554, -1.772489851983156, -10.664786014074558, -3.4581847231923577, -8.747811625925094, -1.4350596137321754, -0.758503988377785, -21.578890114784894]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18498919429850175, "mean_inference_ms": 0.6571317461574375, "mean_action_processing_ms": 0.044794065700517346, "mean_env_wait_ms": 0.2776477302382537, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 61710, "timesteps_this_iter": 0, "agent_timesteps_total": 123420, "timers": {"sample_time_ms": 9941.762, "sample_throughput": 413.81, "load_time_ms": 0.158, "load_throughput": 26061571.75, "learn_time_ms": 5142.662, "learn_throughput": 799.975}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 39.42981263647477, "policy_loss": -0.002135132605326362, "vf_loss": 39.43178781196475, "vf_explained_var": -0.07028174760440985, "kl": 0.015183376629647683, "entropy": 1.2916956429680189, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 12.7742045582893, "policy_loss": 0.0032616983749903738, "vf_loss": 12.770913753844798, "vf_explained_var": -0.17044977092494568, "kl": 0.008256988314648576, "entropy": 1.3829418692737818, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 61710, "num_agent_steps_sampled": 123420, "num_steps_trained": 61710, "num_agent_steps_trained": 123420, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 255, "training_iteration": 15, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-32-05", "timestamp": 1674487925, "time_this_iter_s": 9.885844945907593, "time_total_s": 149.04854011535645, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x17f2cf940>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dae0b80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 149.04854011535645, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 19.646666666666665, "ram_util_percent": 63.67333333333335}}
{"episode_reward_max": -15.405211108599232, "episode_reward_min": -273.35406954766233, "episode_reward_mean": -43.46027362819859, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -269.02372649979657, "pol1": -64.01635743938189}, "policy_reward_max": {"pol0": -8.591335636665619, "pol1": -0.07142950865268564}, "policy_reward_mean": {"pol0": -29.451723926068357, "pol1": -14.008549702130235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-26.840450104737528, -273.35406954766233, -48.99976801974316, -46.39448404029582, -21.37638830765166, -45.96460744041919, -30.2633263160318, -28.36477664867284, -18.070504587506992, -22.855420199929878, -18.386707550483816, -45.54406408023343, -27.84435320727111, -25.500544208199486, -45.766694218699485, -17.800304597124835, -26.075477110863723, -39.97268670211753, -49.37647155661462, -22.79727619735808, -44.90763977065561, -25.328306696488852, -36.8029894572366, -25.524994386266602, -32.280920000284844, -26.713265988561925, -34.64251252841926, -31.703129667027817, -15.405211108599232, -23.524252315921945, -44.968231746128275, -18.573323063890566, -21.165607478662185, -34.505321140909885, -92.14352673715663, -48.47003447070555, -24.254321890520355, -18.71989876519827, -21.749412759616835, -17.379398028164207, -19.11696744161234, -22.85067746489413, -20.083869344876476, -16.723938280960358, -45.470357258216055, -26.07680788537805, -61.134849850585645, -18.872287209028176, -39.54588150678173, -44.734718128544465, -25.18790839028302, -18.599089966210837, -18.049655827535034, -74.1007286036802, -21.906916952874727, -23.933769087325544, -24.202584320582634, -81.61311103055378, -31.37994429394173, -38.52567112794281, -16.70021507628338, -16.90999373080723, -31.643185436045524, -17.799655663902925, -23.072317210264, -26.167560631767987, -31.972457564835075, -109.91469517097299, -24.40471975325186, -57.225101288830075, -65.32887196507451, -18.51150697853853, -38.66412553000017, -49.086228375035795, -29.870084395134676, -17.11905022243152, -32.77879275510993, -25.038946015235116, -22.78442047391749, -20.725551908699018, -18.463881529616803, -25.254360842552753, -38.19824059178073, -91.02641737882989, -87.45471781261675, -120.58444162605012, -168.51852583902755, -85.56450136332363, -93.45550916960322, -100.74338069886058, -75.48315635453658, -81.05765644193781, -42.85451564005673, -51.630516991675215, -28.404688462722362, -50.850832656789954, -100.67580891617428, -54.39326720926663, -37.25261989312801, -126.02243664133174], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-16.915506169838626, -269.02372649979657, -47.482412343147374, -22.233329911820505, -10.871326582979497, -18.38528527809879, -18.74446503157039, -25.57916408093543, -14.39533483671573, -17.025000219114272, -14.859942714235764, -45.299146191900995, -17.066428238485056, -16.227075647022474, -45.08896853157011, -13.292424296838675, -24.261039848843684, -36.52164697632977, -27.842073561813017, -18.708299670692718, -39.324433153549954, -21.498063192577106, -16.900584161524666, -23.4713684093393, -27.489804308951943, -19.723137031495643, -21.289042351376434, -31.631700158375118, -11.311772543944997, -19.008079037528983, -14.25167787017905, -14.497078135586023, -14.751928148071089, -33.6017744258267, -36.466612462268394, -17.52148453265851, -12.982944628390122, -13.84944501579948, -11.999748519877139, -14.186898206616751, -11.193581669986688, -19.138566154234663, -15.59144807127326, -14.767389885665148, -24.60507774661097, -17.652198011933855, -24.715281296541956, -16.5230076680182, -38.93109486390414, -31.981470914966255, -11.636188848836152, -8.591335636665619, -16.60763706436268, -30.09574974279532, -18.63356486289575, -19.5624794029486, -17.252138825953658, -55.09098499805132, -27.04770184511824, -22.49634374721273, -10.900088473826731, -14.109986768442987, -12.54064346631624, -15.104117169065297, -19.863618768454796, -15.073918346985135, -17.914388696301383, -95.98665145173503, -22.365439763674605, -22.406872429108244, -26.401497372684805, -17.674101906386348, -12.666080329029992, -47.18379246447307, -11.943126654759979, -10.058088020114976, -31.006302903126777, -14.37416000116055, -19.32623575072512, -11.977740282773912, -17.028821915884613, -24.49585685417496, -16.619350476995848, -81.73016901520234, -38.8699179472409, -83.78645158885985, -104.50216839964568, -49.14494827412648, -51.3310334758381, -42.375281241741696, -56.129835999688176, -34.19603594101811, -30.802965822081344, -32.329884875237106, -25.49256158718524, -44.08291125663932, -51.03071044985381, -33.13792397356996, -34.09495343009348, -67.42034487895096], "policy_pol1_reward": [-9.924943934898934, -4.330343047865919, -1.5173556765957943, -24.161154128475317, -10.505061724672174, -27.57932216232041, -11.5188612844614, -2.7856125677373966, -3.675169750791249, -5.830419980815612, -3.5267648362480672, -0.24491788833241523, -10.77792496878607, -9.273468561177038, -0.6777256871293584, -4.507880300286165, -1.8144372620200386, -3.451039725787778, -21.534397994801623, -4.0889765266653395, -5.583206617105641, -3.8302435039117366, -19.902405295711926, -2.0536259769273135, -4.791115691332888, -6.9901289570662835, -13.353470177042809, -0.07142950865268564, -4.093438564654228, -4.516173278392957, -30.716553875949213, -4.076244928304542, -6.413679330591105, -0.9035467150831741, -55.67691427488832, -30.948549938047034, -11.271377262130228, -4.870453749398807, -9.7496642397397, -3.192499821547457, -7.92338577162561, -3.712111310659468, -4.4924212736031945, -1.9565483952951939, -20.86527951160505, -8.424609873444199, -36.419568554043714, -2.349279541009968, -0.6147866428775839, -12.753247213578156, -13.551719541446884, -10.007754329545214, -1.442018763172343, -44.00497886088494, -3.2733520899789577, -4.371289684376962, -6.950445494628971, -26.522126032502477, -4.3322424488235, -16.029327380730056, -5.800126602456652, -2.800006962364243, -19.102541969729295, -2.695538494837607, -3.2086984418091906, -11.093642284782844, -14.058068868533677, -13.928043719238023, -2.0392799895772447, -34.81822885972182, -38.927374592389704, -0.8374050721521912, -25.9980452009702, -1.9024359105626942, -17.926957740374696, -7.060962202316554, -1.772489851983156, -10.664786014074558, -3.4581847231923577, -8.747811625925094, -1.4350596137321754, -0.758503988377785, -21.578890114784894, -9.296248363627548, -48.58479986537583, -36.79799003719028, -64.01635743938189, -36.41955308919714, -42.12447569376508, -58.368099457118866, -19.353320354848364, -46.861620500919656, -12.05154981797538, -19.30063211643812, -2.912126875537116, -6.767921400150621, -49.64509846632052, -21.255343235696678, -3.1576664630345346, -58.60209176238083]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18496776165300155, "mean_inference_ms": 0.6572355577224327, "mean_action_processing_ms": 0.044793136846172546, "mean_env_wait_ms": 0.277557057224376, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 65824, "timesteps_this_iter": 0, "agent_timesteps_total": 131648, "timers": {"sample_time_ms": 9953.262, "sample_throughput": 413.332, "load_time_ms": 0.159, "load_throughput": 25862360.096, "learn_time_ms": 5155.814, "learn_throughput": 797.934}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 142.61893217762312, "policy_loss": -0.0010177622413417946, "vf_loss": 142.61984958400328, "vf_explained_var": -0.16844565322001775, "kl": 0.009479125794920643, "entropy": 0.9803608164812128, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 49.82011542318699, "policy_loss": 0.0023471635572301845, "vf_loss": 49.81774505799015, "vf_explained_var": -0.18048012144863607, "kl": 0.006557688358861924, "entropy": 1.3080323791131376, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 65824, "num_agent_steps_sampled": 131648, "num_steps_trained": 65824, "num_agent_steps_trained": 131648, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 272, "training_iteration": 16, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-32-15", "timestamp": 1674487935, "time_this_iter_s": 10.204813003540039, "time_total_s": 159.25335311889648, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dad7f70>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dadf3a0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 159.25335311889648, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 21.264285714285716, "ram_util_percent": 63.678571428571445}}
{"episode_reward_max": -15.405211108599232, "episode_reward_min": -168.51852583902755, "episode_reward_mean": -43.16177630915792, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -104.50216839964568, "pol1": -64.01635743938189}, "policy_reward_max": {"pol0": -8.591335636665619, "pol1": -0.07142950865268564}, "policy_reward_mean": {"pol0": -28.073396094687872, "pol1": -15.088380214470067}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-39.97268670211753, -49.37647155661462, -22.79727619735808, -44.90763977065561, -25.328306696488852, -36.8029894572366, -25.524994386266602, -32.280920000284844, -26.713265988561925, -34.64251252841926, -31.703129667027817, -15.405211108599232, -23.524252315921945, -44.968231746128275, -18.573323063890566, -21.165607478662185, -34.505321140909885, -92.14352673715663, -48.47003447070555, -24.254321890520355, -18.71989876519827, -21.749412759616835, -17.379398028164207, -19.11696744161234, -22.85067746489413, -20.083869344876476, -16.723938280960358, -45.470357258216055, -26.07680788537805, -61.134849850585645, -18.872287209028176, -39.54588150678173, -44.734718128544465, -25.18790839028302, -18.599089966210837, -18.049655827535034, -74.1007286036802, -21.906916952874727, -23.933769087325544, -24.202584320582634, -81.61311103055378, -31.37994429394173, -38.52567112794281, -16.70021507628338, -16.90999373080723, -31.643185436045524, -17.799655663902925, -23.072317210264, -26.167560631767987, -31.972457564835075, -109.91469517097299, -24.40471975325186, -57.225101288830075, -65.32887196507451, -18.51150697853853, -38.66412553000017, -49.086228375035795, -29.870084395134676, -17.11905022243152, -32.77879275510993, -25.038946015235116, -22.78442047391749, -20.725551908699018, -18.463881529616803, -25.254360842552753, -38.19824059178073, -91.02641737882989, -87.45471781261675, -120.58444162605012, -168.51852583902755, -85.56450136332363, -93.45550916960322, -100.74338069886058, -75.48315635453658, -81.05765644193781, -42.85451564005673, -51.630516991675215, -28.404688462722362, -50.850832656789954, -100.67580891617428, -54.39326720926663, -37.25261989312801, -126.02243664133174, -38.118748744257466, -35.18123840573173, -18.776864622535516, -31.69738711156468, -49.18131667880659, -68.92039211044045, -45.042114220441, -36.264913904347765, -41.35298486541953, -83.01759904863157, -36.842179640290745, -25.563147098123597, -19.953375581165425, -77.31165097161595, -47.938669335803226, -27.306167256917874, -57.08345868536836], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-36.52164697632977, -27.842073561813017, -18.708299670692718, -39.324433153549954, -21.498063192577106, -16.900584161524666, -23.4713684093393, -27.489804308951943, -19.723137031495643, -21.289042351376434, -31.631700158375118, -11.311772543944997, -19.008079037528983, -14.25167787017905, -14.497078135586023, -14.751928148071089, -33.6017744258267, -36.466612462268394, -17.52148453265851, -12.982944628390122, -13.84944501579948, -11.999748519877139, -14.186898206616751, -11.193581669986688, -19.138566154234663, -15.59144807127326, -14.767389885665148, -24.60507774661097, -17.652198011933855, -24.715281296541956, -16.5230076680182, -38.93109486390414, -31.981470914966255, -11.636188848836152, -8.591335636665619, -16.60763706436268, -30.09574974279532, -18.63356486289575, -19.5624794029486, -17.252138825953658, -55.09098499805132, -27.04770184511824, -22.49634374721273, -10.900088473826731, -14.109986768442987, -12.54064346631624, -15.104117169065297, -19.863618768454796, -15.073918346985135, -17.914388696301383, -95.98665145173503, -22.365439763674605, -22.406872429108244, -26.401497372684805, -17.674101906386348, -12.666080329029992, -47.18379246447307, -11.943126654759979, -10.058088020114976, -31.006302903126777, -14.37416000116055, -19.32623575072512, -11.977740282773912, -17.028821915884613, -24.49585685417496, -16.619350476995848, -81.73016901520234, -38.8699179472409, -83.78645158885985, -104.50216839964568, -49.14494827412648, -51.3310334758381, -42.375281241741696, -56.129835999688176, -34.19603594101811, -30.802965822081344, -32.329884875237106, -25.49256158718524, -44.08291125663932, -51.03071044985381, -33.13792397356996, -34.09495343009348, -67.42034487895096, -25.15597841338711, -14.938524351751756, -13.415360470378005, -27.054469672749715, -46.10950815485294, -34.331082377613086, -28.212867393403062, -29.88660811507659, -37.371461517663455, -70.72114522734213, -20.611462619528194, -14.459498658766101, -13.554536786781544, -40.17836669187473, -31.133697544917077, -22.225464090414388, -29.557761198365533], "policy_pol1_reward": [-3.451039725787778, -21.534397994801623, -4.0889765266653395, -5.583206617105641, -3.8302435039117366, -19.902405295711926, -2.0536259769273135, -4.791115691332888, -6.9901289570662835, -13.353470177042809, -0.07142950865268564, -4.093438564654228, -4.516173278392957, -30.716553875949213, -4.076244928304542, -6.413679330591105, -0.9035467150831741, -55.67691427488832, -30.948549938047034, -11.271377262130228, -4.870453749398807, -9.7496642397397, -3.192499821547457, -7.92338577162561, -3.712111310659468, -4.4924212736031945, -1.9565483952951939, -20.86527951160505, -8.424609873444199, -36.419568554043714, -2.349279541009968, -0.6147866428775839, -12.753247213578156, -13.551719541446884, -10.007754329545214, -1.442018763172343, -44.00497886088494, -3.2733520899789577, -4.371289684376962, -6.950445494628971, -26.522126032502477, -4.3322424488235, -16.029327380730056, -5.800126602456652, -2.800006962364243, -19.102541969729295, -2.695538494837607, -3.2086984418091906, -11.093642284782844, -14.058068868533677, -13.928043719238023, -2.0392799895772447, -34.81822885972182, -38.927374592389704, -0.8374050721521912, -25.9980452009702, -1.9024359105626942, -17.926957740374696, -7.060962202316554, -1.772489851983156, -10.664786014074558, -3.4581847231923577, -8.747811625925094, -1.4350596137321754, -0.758503988377785, -21.578890114784894, -9.296248363627548, -48.58479986537583, -36.79799003719028, -64.01635743938189, -36.41955308919714, -42.12447569376508, -58.368099457118866, -19.353320354848364, -46.861620500919656, -12.05154981797538, -19.30063211643812, -2.912126875537116, -6.767921400150621, -49.64509846632052, -21.255343235696678, -3.1576664630345346, -58.60209176238083, -12.962770330870343, -20.242714053979984, -5.361504152157523, -4.642917438814993, -3.071808523953666, -34.58930973282739, -16.82924682703796, -6.378305789271188, -3.981523347756064, -12.296453821289388, -16.23071702076256, -11.103648439357519, -6.398838794383891, -37.13328427974121, -16.804971790886206, -5.080703166503498, -27.52569748700281]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18495487759602505, "mean_inference_ms": 0.6573602057524323, "mean_action_processing_ms": 0.04479502621615584, "mean_env_wait_ms": 0.2774607714302579, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 69938, "timesteps_this_iter": 0, "agent_timesteps_total": 139876, "timers": {"sample_time_ms": 9963.288, "sample_throughput": 412.916, "load_time_ms": 0.157, "load_throughput": 26164316.385, "learn_time_ms": 5159.587, "learn_throughput": 797.351}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 36.297342043618364, "policy_loss": -0.002859403673210181, "vf_loss": 36.3000554556648, "vf_explained_var": -0.1662113329395652, "kl": 0.013840351317655101, "entropy": 0.9272003615275025, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 14.415662791517873, "policy_loss": 0.0014539273969906693, "vf_loss": 14.414164321683348, "vf_explained_var": -0.5434478759765625, "kl": 0.012674581957010862, "entropy": 1.231185018395384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 69938, "num_agent_steps_sampled": 139876, "num_steps_trained": 69938, "num_agent_steps_trained": 139876, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 289, "training_iteration": 17, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-32-25", "timestamp": 1674487945, "time_this_iter_s": 9.919342994689941, "time_total_s": 169.17269611358643, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x17f53f430>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29d770940>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 169.17269611358643, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 16.90714285714286, "ram_util_percent": 63.60000000000001}}
{"episode_reward_max": -14.88406368396049, "episode_reward_min": -168.51852583902755, "episode_reward_mean": -42.73586924588487, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -104.50216839964568, "pol1": -64.01635743938189}, "policy_reward_max": {"pol0": -8.591335636665619, "pol1": -0.6147866428775839}, "policy_reward_mean": {"pol0": -26.889527289963326, "pol1": -15.846341955921538}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-92.14352673715663, -48.47003447070555, -24.254321890520355, -18.71989876519827, -21.749412759616835, -17.379398028164207, -19.11696744161234, -22.85067746489413, -20.083869344876476, -16.723938280960358, -45.470357258216055, -26.07680788537805, -61.134849850585645, -18.872287209028176, -39.54588150678173, -44.734718128544465, -25.18790839028302, -18.599089966210837, -18.049655827535034, -74.1007286036802, -21.906916952874727, -23.933769087325544, -24.202584320582634, -81.61311103055378, -31.37994429394173, -38.52567112794281, -16.70021507628338, -16.90999373080723, -31.643185436045524, -17.799655663902925, -23.072317210264, -26.167560631767987, -31.972457564835075, -109.91469517097299, -24.40471975325186, -57.225101288830075, -65.32887196507451, -18.51150697853853, -38.66412553000017, -49.086228375035795, -29.870084395134676, -17.11905022243152, -32.77879275510993, -25.038946015235116, -22.78442047391749, -20.725551908699018, -18.463881529616803, -25.254360842552753, -38.19824059178073, -91.02641737882989, -87.45471781261675, -120.58444162605012, -168.51852583902755, -85.56450136332363, -93.45550916960322, -100.74338069886058, -75.48315635453658, -81.05765644193781, -42.85451564005673, -51.630516991675215, -28.404688462722362, -50.850832656789954, -100.67580891617428, -54.39326720926663, -37.25261989312801, -126.02243664133174, -38.118748744257466, -35.18123840573173, -18.776864622535516, -31.69738711156468, -49.18131667880659, -68.92039211044045, -45.042114220441, -36.264913904347765, -41.35298486541953, -83.01759904863157, -36.842179640290745, -25.563147098123597, -19.953375581165425, -77.31165097161595, -47.938669335803226, -27.306167256917874, -57.08345868536836, -19.34004966155121, -23.860029956877966, -42.4136865589754, -20.484652215855103, -14.88406368396049, -27.555755363791466, -38.46520869676067, -35.338995032184684, -28.885256222255524, -25.604843856176487, -42.703903561265754, -64.6598202619595, -18.619573547029248, -20.810385197953607, -17.35736334278012, -16.999297941817655, -27.618548376641773], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-36.466612462268394, -17.52148453265851, -12.982944628390122, -13.84944501579948, -11.999748519877139, -14.186898206616751, -11.193581669986688, -19.138566154234663, -15.59144807127326, -14.767389885665148, -24.60507774661097, -17.652198011933855, -24.715281296541956, -16.5230076680182, -38.93109486390414, -31.981470914966255, -11.636188848836152, -8.591335636665619, -16.60763706436268, -30.09574974279532, -18.63356486289575, -19.5624794029486, -17.252138825953658, -55.09098499805132, -27.04770184511824, -22.49634374721273, -10.900088473826731, -14.109986768442987, -12.54064346631624, -15.104117169065297, -19.863618768454796, -15.073918346985135, -17.914388696301383, -95.98665145173503, -22.365439763674605, -22.406872429108244, -26.401497372684805, -17.674101906386348, -12.666080329029992, -47.18379246447307, -11.943126654759979, -10.058088020114976, -31.006302903126777, -14.37416000116055, -19.32623575072512, -11.977740282773912, -17.028821915884613, -24.49585685417496, -16.619350476995848, -81.73016901520234, -38.8699179472409, -83.78645158885985, -104.50216839964568, -49.14494827412648, -51.3310334758381, -42.375281241741696, -56.129835999688176, -34.19603594101811, -30.802965822081344, -32.329884875237106, -25.49256158718524, -44.08291125663932, -51.03071044985381, -33.13792397356996, -34.09495343009348, -67.42034487895096, -25.15597841338711, -14.938524351751756, -13.415360470378005, -27.054469672749715, -46.10950815485294, -34.331082377613086, -28.212867393403062, -29.88660811507659, -37.371461517663455, -70.72114522734213, -20.611462619528194, -14.459498658766101, -13.554536786781544, -40.17836669187473, -31.133697544917077, -22.225464090414388, -29.557761198365533, -17.91424325434781, -20.798995994439014, -19.041233983269915, -16.840274732964076, -8.891811554982834, -12.719358123633846, -14.012840171301278, -17.951727292708483, -16.27994457450995, -13.253553453981812, -23.362092502043243, -14.006372170047012, -12.835181931206785, -18.357837142783644, -14.44751281310596, -10.582859674831077, -22.139743294550943], "policy_pol1_reward": [-55.67691427488832, -30.948549938047034, -11.271377262130228, -4.870453749398807, -9.7496642397397, -3.192499821547457, -7.92338577162561, -3.712111310659468, -4.4924212736031945, -1.9565483952951939, -20.86527951160505, -8.424609873444199, -36.419568554043714, -2.349279541009968, -0.6147866428775839, -12.753247213578156, -13.551719541446884, -10.007754329545214, -1.442018763172343, -44.00497886088494, -3.2733520899789577, -4.371289684376962, -6.950445494628971, -26.522126032502477, -4.3322424488235, -16.029327380730056, -5.800126602456652, -2.800006962364243, -19.102541969729295, -2.695538494837607, -3.2086984418091906, -11.093642284782844, -14.058068868533677, -13.928043719238023, -2.0392799895772447, -34.81822885972182, -38.927374592389704, -0.8374050721521912, -25.9980452009702, -1.9024359105626942, -17.926957740374696, -7.060962202316554, -1.772489851983156, -10.664786014074558, -3.4581847231923577, -8.747811625925094, -1.4350596137321754, -0.758503988377785, -21.578890114784894, -9.296248363627548, -48.58479986537583, -36.79799003719028, -64.01635743938189, -36.41955308919714, -42.12447569376508, -58.368099457118866, -19.353320354848364, -46.861620500919656, -12.05154981797538, -19.30063211643812, -2.912126875537116, -6.767921400150621, -49.64509846632052, -21.255343235696678, -3.1576664630345346, -58.60209176238083, -12.962770330870343, -20.242714053979984, -5.361504152157523, -4.642917438814993, -3.071808523953666, -34.58930973282739, -16.82924682703796, -6.378305789271188, -3.981523347756064, -12.296453821289388, -16.23071702076256, -11.103648439357519, -6.398838794383891, -37.13328427974121, -16.804971790886206, -5.080703166503498, -27.52569748700281, -1.4258064072033871, -3.0610339624389358, -23.372452575705466, -3.644377482891018, -5.992252128977643, -14.836397240157622, -24.452368525459388, -17.387267739476208, -12.605311647745566, -12.35129040219466, -19.341811059222444, -50.65344809191254, -5.784391615822456, -2.452548055169973, -2.909850529674177, -6.416438266986571, -5.478805082090835]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18496760899997264, "mean_inference_ms": 0.6575228601884882, "mean_action_processing_ms": 0.044800064568314646, "mean_env_wait_ms": 0.2773750803155997, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 74052, "timesteps_this_iter": 0, "agent_timesteps_total": 148104, "timers": {"sample_time_ms": 9969.569, "sample_throughput": 412.656, "load_time_ms": 0.156, "load_throughput": 26400499.78, "learn_time_ms": 5176.009, "learn_throughput": 794.821}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 10.491820262708158, "policy_loss": 0.0011429631490803634, "vf_loss": 10.490519271045923, "vf_explained_var": -0.06365780793130398, "kl": 0.014987003685685825, "entropy": 0.8232674778749546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 33.39803480564927, "policy_loss": -0.000598802223491172, "vf_loss": 33.398583368522424, "vf_explained_var": -0.4819518156970541, "kl": 0.014304775075773553, "entropy": 1.1115967944885294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 74052, "num_agent_steps_sampled": 148104, "num_steps_trained": 74052, "num_agent_steps_trained": 148104, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 306, "training_iteration": 18, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-32-35", "timestamp": 1674487955, "time_this_iter_s": 9.992625951766968, "time_total_s": 179.1653220653534, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x17f2cf940>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dae0a60>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 179.1653220653534, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 19.828571428571426, "ram_util_percent": 63.60000000000001}}
{"episode_reward_max": -12.384281450509718, "episode_reward_min": -168.51852583902755, "episode_reward_mean": -42.11304069872602, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -104.50216839964568, "pol1": -64.01635743938189}, "policy_reward_max": {"pol0": -8.591335636665619, "pol1": -0.758503988377785}, "policy_reward_mean": {"pol0": -26.88531736228109, "pol1": -15.227723336444937}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.599089966210837, -18.049655827535034, -74.1007286036802, -21.906916952874727, -23.933769087325544, -24.202584320582634, -81.61311103055378, -31.37994429394173, -38.52567112794281, -16.70021507628338, -16.90999373080723, -31.643185436045524, -17.799655663902925, -23.072317210264, -26.167560631767987, -31.972457564835075, -109.91469517097299, -24.40471975325186, -57.225101288830075, -65.32887196507451, -18.51150697853853, -38.66412553000017, -49.086228375035795, -29.870084395134676, -17.11905022243152, -32.77879275510993, -25.038946015235116, -22.78442047391749, -20.725551908699018, -18.463881529616803, -25.254360842552753, -38.19824059178073, -91.02641737882989, -87.45471781261675, -120.58444162605012, -168.51852583902755, -85.56450136332363, -93.45550916960322, -100.74338069886058, -75.48315635453658, -81.05765644193781, -42.85451564005673, -51.630516991675215, -28.404688462722362, -50.850832656789954, -100.67580891617428, -54.39326720926663, -37.25261989312801, -126.02243664133174, -38.118748744257466, -35.18123840573173, -18.776864622535516, -31.69738711156468, -49.18131667880659, -68.92039211044045, -45.042114220441, -36.264913904347765, -41.35298486541953, -83.01759904863157, -36.842179640290745, -25.563147098123597, -19.953375581165425, -77.31165097161595, -47.938669335803226, -27.306167256917874, -57.08345868536836, -19.34004966155121, -23.860029956877966, -42.4136865589754, -20.484652215855103, -14.88406368396049, -27.555755363791466, -38.46520869676067, -35.338995032184684, -28.885256222255524, -25.604843856176487, -42.703903561265754, -64.6598202619595, -18.619573547029248, -20.810385197953607, -17.35736334278012, -16.999297941817655, -27.618548376641773, -21.20581864813048, -28.89454150774236, -49.891529081866395, -24.419304297982503, -28.746581008336005, -38.02272193885811, -25.130497677525753, -12.384281450509718, -19.941406393220667, -24.757300105790925, -28.848341830577372, -65.73766841129932, -30.081815626397436, -17.738304996241002, -32.223520801329386, -33.97199670030143, -18.236370220529068], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-8.591335636665619, -16.60763706436268, -30.09574974279532, -18.63356486289575, -19.5624794029486, -17.252138825953658, -55.09098499805132, -27.04770184511824, -22.49634374721273, -10.900088473826731, -14.109986768442987, -12.54064346631624, -15.104117169065297, -19.863618768454796, -15.073918346985135, -17.914388696301383, -95.98665145173503, -22.365439763674605, -22.406872429108244, -26.401497372684805, -17.674101906386348, -12.666080329029992, -47.18379246447307, -11.943126654759979, -10.058088020114976, -31.006302903126777, -14.37416000116055, -19.32623575072512, -11.977740282773912, -17.028821915884613, -24.49585685417496, -16.619350476995848, -81.73016901520234, -38.8699179472409, -83.78645158885985, -104.50216839964568, -49.14494827412648, -51.3310334758381, -42.375281241741696, -56.129835999688176, -34.19603594101811, -30.802965822081344, -32.329884875237106, -25.49256158718524, -44.08291125663932, -51.03071044985381, -33.13792397356996, -34.09495343009348, -67.42034487895096, -25.15597841338711, -14.938524351751756, -13.415360470378005, -27.054469672749715, -46.10950815485294, -34.331082377613086, -28.212867393403062, -29.88660811507659, -37.371461517663455, -70.72114522734213, -20.611462619528194, -14.459498658766101, -13.554536786781544, -40.17836669187473, -31.133697544917077, -22.225464090414388, -29.557761198365533, -17.91424325434781, -20.798995994439014, -19.041233983269915, -16.840274732964076, -8.891811554982834, -12.719358123633846, -14.012840171301278, -17.951727292708483, -16.27994457450995, -13.253553453981812, -23.362092502043243, -14.006372170047012, -12.835181931206785, -18.357837142783644, -14.44751281310596, -10.582859674831077, -22.139743294550943, -15.255656819330964, -23.79367701314522, -24.215722317979953, -15.335713150753573, -23.55278544217046, -18.94378164683051, -16.712042764012484, -10.096774972423729, -14.370331915823717, -21.443261396139572, -13.719699668736324, -25.550668249971913, -22.939878007225087, -13.733527031899976, -26.276480774128242, -30.957451546641497, -16.423993012144674], "policy_pol1_reward": [-10.007754329545214, -1.442018763172343, -44.00497886088494, -3.2733520899789577, -4.371289684376962, -6.950445494628971, -26.522126032502477, -4.3322424488235, -16.029327380730056, -5.800126602456652, -2.800006962364243, -19.102541969729295, -2.695538494837607, -3.2086984418091906, -11.093642284782844, -14.058068868533677, -13.928043719238023, -2.0392799895772447, -34.81822885972182, -38.927374592389704, -0.8374050721521912, -25.9980452009702, -1.9024359105626942, -17.926957740374696, -7.060962202316554, -1.772489851983156, -10.664786014074558, -3.4581847231923577, -8.747811625925094, -1.4350596137321754, -0.758503988377785, -21.578890114784894, -9.296248363627548, -48.58479986537583, -36.79799003719028, -64.01635743938189, -36.41955308919714, -42.12447569376508, -58.368099457118866, -19.353320354848364, -46.861620500919656, -12.05154981797538, -19.30063211643812, -2.912126875537116, -6.767921400150621, -49.64509846632052, -21.255343235696678, -3.1576664630345346, -58.60209176238083, -12.962770330870343, -20.242714053979984, -5.361504152157523, -4.642917438814993, -3.071808523953666, -34.58930973282739, -16.82924682703796, -6.378305789271188, -3.981523347756064, -12.296453821289388, -16.23071702076256, -11.103648439357519, -6.398838794383891, -37.13328427974121, -16.804971790886206, -5.080703166503498, -27.52569748700281, -1.4258064072033871, -3.0610339624389358, -23.372452575705466, -3.644377482891018, -5.992252128977643, -14.836397240157622, -24.452368525459388, -17.387267739476208, -12.605311647745566, -12.35129040219466, -19.341811059222444, -50.65344809191254, -5.784391615822456, -2.452548055169973, -2.909850529674177, -6.416438266986571, -5.478805082090835, -5.950161828799521, -5.100864494597131, -25.67580676388642, -9.083591147228951, -5.193795566165527, -19.078940292027628, -8.418454913513273, -2.2875064780859806, -5.571074477396952, -3.314038709651337, -15.128642161841038, -40.187000161327425, -7.141937619172369, -4.004777964341028, -5.947040027201147, -3.014545153659908, -1.8123772083843768]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18497797518785522, "mean_inference_ms": 0.6576837862932777, "mean_action_processing_ms": 0.044806046001762724, "mean_env_wait_ms": 0.2772876410107347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 78166, "timesteps_this_iter": 0, "agent_timesteps_total": 156332, "timers": {"sample_time_ms": 9987.114, "sample_throughput": 411.931, "load_time_ms": 0.156, "load_throughput": 26400499.78, "learn_time_ms": 5180.092, "learn_throughput": 794.194}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.946242526918649, "policy_loss": 0.0028691002322981753, "vf_loss": 8.943252564252665, "vf_explained_var": -0.10635027065873146, "kl": 0.011459093963518777, "entropy": 0.7252072529867292, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 13.379833548205594, "policy_loss": -0.0045525273046223445, "vf_loss": 13.384331191362191, "vf_explained_var": -0.3210673845062653, "kl": 0.015603988453707036, "entropy": 1.124321530510982, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 78166, "num_agent_steps_sampled": 156332, "num_steps_trained": 78166, "num_agent_steps_trained": 156332, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 323, "training_iteration": 19, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-32-45", "timestamp": 1674487965, "time_this_iter_s": 10.001770973205566, "time_total_s": 189.16709303855896, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dae0160>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29d28b9d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 189.16709303855896, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 20.146666666666665, "ram_util_percent": 63.66666666666669}}
{"episode_reward_max": -12.384281450509718, "episode_reward_min": -168.51852583902755, "episode_reward_mean": -40.40894835593984, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -104.50216839964568, "pol1": -64.01635743938189}, "policy_reward_max": {"pol0": -8.891811554982834, "pol1": -0.758503988377785}, "policy_reward_mean": {"pol0": -24.879851284023584, "pol1": -15.529097071916262}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.40471975325186, -57.225101288830075, -65.32887196507451, -18.51150697853853, -38.66412553000017, -49.086228375035795, -29.870084395134676, -17.11905022243152, -32.77879275510993, -25.038946015235116, -22.78442047391749, -20.725551908699018, -18.463881529616803, -25.254360842552753, -38.19824059178073, -91.02641737882989, -87.45471781261675, -120.58444162605012, -168.51852583902755, -85.56450136332363, -93.45550916960322, -100.74338069886058, -75.48315635453658, -81.05765644193781, -42.85451564005673, -51.630516991675215, -28.404688462722362, -50.850832656789954, -100.67580891617428, -54.39326720926663, -37.25261989312801, -126.02243664133174, -38.118748744257466, -35.18123840573173, -18.776864622535516, -31.69738711156468, -49.18131667880659, -68.92039211044045, -45.042114220441, -36.264913904347765, -41.35298486541953, -83.01759904863157, -36.842179640290745, -25.563147098123597, -19.953375581165425, -77.31165097161595, -47.938669335803226, -27.306167256917874, -57.08345868536836, -19.34004966155121, -23.860029956877966, -42.4136865589754, -20.484652215855103, -14.88406368396049, -27.555755363791466, -38.46520869676067, -35.338995032184684, -28.885256222255524, -25.604843856176487, -42.703903561265754, -64.6598202619595, -18.619573547029248, -20.810385197953607, -17.35736334278012, -16.999297941817655, -27.618548376641773, -21.20581864813048, -28.89454150774236, -49.891529081866395, -24.419304297982503, -28.746581008336005, -38.02272193885811, -25.130497677525753, -12.384281450509718, -19.941406393220667, -24.757300105790925, -28.848341830577372, -65.73766841129932, -30.081815626397436, -17.738304996241002, -32.223520801329386, -33.97199670030143, -18.236370220529068, -25.060165537666006, -22.090507471962503, -26.589818525123437, -20.396667550301892, -23.47843937874901, -27.374485587009453, -18.15022530947204, -17.729852260999174, -32.21920748707139, -31.36112696975832, -17.337112176806013, -22.589307569347362, -25.02431556657163, -32.37533811160638, -26.29956110881011, -35.115227581730494, -32.89095922392349], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-22.365439763674605, -22.406872429108244, -26.401497372684805, -17.674101906386348, -12.666080329029992, -47.18379246447307, -11.943126654759979, -10.058088020114976, -31.006302903126777, -14.37416000116055, -19.32623575072512, -11.977740282773912, -17.028821915884613, -24.49585685417496, -16.619350476995848, -81.73016901520234, -38.8699179472409, -83.78645158885985, -104.50216839964568, -49.14494827412648, -51.3310334758381, -42.375281241741696, -56.129835999688176, -34.19603594101811, -30.802965822081344, -32.329884875237106, -25.49256158718524, -44.08291125663932, -51.03071044985381, -33.13792397356996, -34.09495343009348, -67.42034487895096, -25.15597841338711, -14.938524351751756, -13.415360470378005, -27.054469672749715, -46.10950815485294, -34.331082377613086, -28.212867393403062, -29.88660811507659, -37.371461517663455, -70.72114522734213, -20.611462619528194, -14.459498658766101, -13.554536786781544, -40.17836669187473, -31.133697544917077, -22.225464090414388, -29.557761198365533, -17.91424325434781, -20.798995994439014, -19.041233983269915, -16.840274732964076, -8.891811554982834, -12.719358123633846, -14.012840171301278, -17.951727292708483, -16.27994457450995, -13.253553453981812, -23.362092502043243, -14.006372170047012, -12.835181931206785, -18.357837142783644, -14.44751281310596, -10.582859674831077, -22.139743294550943, -15.255656819330964, -23.79367701314522, -24.215722317979953, -15.335713150753573, -23.55278544217046, -18.94378164683051, -16.712042764012484, -10.096774972423729, -14.370331915823717, -21.443261396139572, -13.719699668736324, -25.550668249971913, -22.939878007225087, -13.733527031899976, -26.276480774128242, -30.957451546641497, -16.423993012144674, -11.248690135543884, -15.674446677733886, -15.121856648467409, -12.009063402425936, -10.41661465351816, -13.876054498389923, -10.344393249877237, -11.480682008679912, -12.873567549999759, -13.994311190751768, -14.686444848039036, -9.50878491819103, -15.855313655269265, -10.30346144790079, -12.451898009015597, -13.017803836920704, -13.46135471065671], "policy_pol1_reward": [-2.0392799895772447, -34.81822885972182, -38.927374592389704, -0.8374050721521912, -25.9980452009702, -1.9024359105626942, -17.926957740374696, -7.060962202316554, -1.772489851983156, -10.664786014074558, -3.4581847231923577, -8.747811625925094, -1.4350596137321754, -0.758503988377785, -21.578890114784894, -9.296248363627548, -48.58479986537583, -36.79799003719028, -64.01635743938189, -36.41955308919714, -42.12447569376508, -58.368099457118866, -19.353320354848364, -46.861620500919656, -12.05154981797538, -19.30063211643812, -2.912126875537116, -6.767921400150621, -49.64509846632052, -21.255343235696678, -3.1576664630345346, -58.60209176238083, -12.962770330870343, -20.242714053979984, -5.361504152157523, -4.642917438814993, -3.071808523953666, -34.58930973282739, -16.82924682703796, -6.378305789271188, -3.981523347756064, -12.296453821289388, -16.23071702076256, -11.103648439357519, -6.398838794383891, -37.13328427974121, -16.804971790886206, -5.080703166503498, -27.52569748700281, -1.4258064072033871, -3.0610339624389358, -23.372452575705466, -3.644377482891018, -5.992252128977643, -14.836397240157622, -24.452368525459388, -17.387267739476208, -12.605311647745566, -12.35129040219466, -19.341811059222444, -50.65344809191254, -5.784391615822456, -2.452548055169973, -2.909850529674177, -6.416438266986571, -5.478805082090835, -5.950161828799521, -5.100864494597131, -25.67580676388642, -9.083591147228951, -5.193795566165527, -19.078940292027628, -8.418454913513273, -2.2875064780859806, -5.571074477396952, -3.314038709651337, -15.128642161841038, -40.187000161327425, -7.141937619172369, -4.004777964341028, -5.947040027201147, -3.014545153659908, -1.8123772083843768, -13.811475402122138, -6.416060794228624, -11.467961876656021, -8.387604147875955, -13.061824725230831, -13.49843108861954, -7.8058320595948025, -6.249170252319264, -19.345639937071624, -17.366815779006533, -2.650667328766975, -13.080522651156333, -9.169001911302363, -22.071876663705595, -13.84766309979451, -22.097423744809763, -19.429604513266792]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.185037706367275, "mean_inference_ms": 0.6578847289124005, "mean_action_processing_ms": 0.04481674547305969, "mean_env_wait_ms": 0.2772195075422189, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 82280, "timesteps_this_iter": 0, "agent_timesteps_total": 164560, "timers": {"sample_time_ms": 9995.202, "sample_throughput": 411.597, "load_time_ms": 0.158, "load_throughput": 26030120.163, "learn_time_ms": 5176.141, "learn_throughput": 794.801}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2089174123325694, "policy_loss": 0.0009820910907971361, "vf_loss": 3.2078141735556227, "vf_explained_var": -0.1440854177499811, "kl": 0.011486466259520966, "entropy": 0.639225535839796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.0806722569279374, "policy_loss": 0.0031350201277139905, "vf_loss": 5.077500256213049, "vf_explained_var": -0.19044366671393315, "kl": 0.010521693610614117, "entropy": 1.176298785644273, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 82280, "num_agent_steps_sampled": 164560, "num_steps_trained": 82280, "num_agent_steps_trained": 164560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 340, "training_iteration": 20, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-32-55", "timestamp": 1674487975, "time_this_iter_s": 9.945936918258667, "time_total_s": 199.11302995681763, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d28b820>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dac8280>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 199.11302995681763, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 20.164285714285715, "ram_util_percent": 63.70714285714287}}
{"episode_reward_max": -12.384281450509718, "episode_reward_min": -168.51852583902755, "episode_reward_mean": -37.1207236387797, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -104.50216839964568, "pol1": -64.01635743938189}, "policy_reward_max": {"pol0": -8.618551653069298, "pol1": -1.4258064072033871}, "policy_reward_mean": {"pol0": -22.666038954289878, "pol1": -14.454684684489818}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-120.58444162605012, -168.51852583902755, -85.56450136332363, -93.45550916960322, -100.74338069886058, -75.48315635453658, -81.05765644193781, -42.85451564005673, -51.630516991675215, -28.404688462722362, -50.850832656789954, -100.67580891617428, -54.39326720926663, -37.25261989312801, -126.02243664133174, -38.118748744257466, -35.18123840573173, -18.776864622535516, -31.69738711156468, -49.18131667880659, -68.92039211044045, -45.042114220441, -36.264913904347765, -41.35298486541953, -83.01759904863157, -36.842179640290745, -25.563147098123597, -19.953375581165425, -77.31165097161595, -47.938669335803226, -27.306167256917874, -57.08345868536836, -19.34004966155121, -23.860029956877966, -42.4136865589754, -20.484652215855103, -14.88406368396049, -27.555755363791466, -38.46520869676067, -35.338995032184684, -28.885256222255524, -25.604843856176487, -42.703903561265754, -64.6598202619595, -18.619573547029248, -20.810385197953607, -17.35736334278012, -16.999297941817655, -27.618548376641773, -21.20581864813048, -28.89454150774236, -49.891529081866395, -24.419304297982503, -28.746581008336005, -38.02272193885811, -25.130497677525753, -12.384281450509718, -19.941406393220667, -24.757300105790925, -28.848341830577372, -65.73766841129932, -30.081815626397436, -17.738304996241002, -32.223520801329386, -33.97199670030143, -18.236370220529068, -25.060165537666006, -22.090507471962503, -26.589818525123437, -20.396667550301892, -23.47843937874901, -27.374485587009453, -18.15022530947204, -17.729852260999174, -32.21920748707139, -31.36112696975832, -17.337112176806013, -22.589307569347362, -25.02431556657163, -32.37533811160638, -26.29956110881011, -35.115227581730494, -32.89095922392349, -25.27414342448304, -22.22418188980984, -18.824917359945054, -17.07784934562673, -18.97114111218771, -13.244492868948225, -25.01117078435815, -16.61423616488761, -26.36635196695866, -14.49160417181911, -27.590725817743323, -17.442945356840944, -16.978142917135777, -15.77554157887714, -16.486304511470458, -17.00946327773029, -23.729333551818787], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-83.78645158885985, -104.50216839964568, -49.14494827412648, -51.3310334758381, -42.375281241741696, -56.129835999688176, -34.19603594101811, -30.802965822081344, -32.329884875237106, -25.49256158718524, -44.08291125663932, -51.03071044985381, -33.13792397356996, -34.09495343009348, -67.42034487895096, -25.15597841338711, -14.938524351751756, -13.415360470378005, -27.054469672749715, -46.10950815485294, -34.331082377613086, -28.212867393403062, -29.88660811507659, -37.371461517663455, -70.72114522734213, -20.611462619528194, -14.459498658766101, -13.554536786781544, -40.17836669187473, -31.133697544917077, -22.225464090414388, -29.557761198365533, -17.91424325434781, -20.798995994439014, -19.041233983269915, -16.840274732964076, -8.891811554982834, -12.719358123633846, -14.012840171301278, -17.951727292708483, -16.27994457450995, -13.253553453981812, -23.362092502043243, -14.006372170047012, -12.835181931206785, -18.357837142783644, -14.44751281310596, -10.582859674831077, -22.139743294550943, -15.255656819330964, -23.79367701314522, -24.215722317979953, -15.335713150753573, -23.55278544217046, -18.94378164683051, -16.712042764012484, -10.096774972423729, -14.370331915823717, -21.443261396139572, -13.719699668736324, -25.550668249971913, -22.939878007225087, -13.733527031899976, -26.276480774128242, -30.957451546641497, -16.423993012144674, -11.248690135543884, -15.674446677733886, -15.121856648467409, -12.009063402425936, -10.41661465351816, -13.876054498389923, -10.344393249877237, -11.480682008679912, -12.873567549999759, -13.994311190751768, -14.686444848039036, -9.50878491819103, -15.855313655269265, -10.30346144790079, -12.451898009015597, -13.017803836920704, -13.46135471065671, -11.639645762053744, -9.927720528881792, -15.671226972558953, -12.008939581890822, -12.215091880153162, -10.528891775091731, -13.83604119941837, -11.444293337003641, -14.158717542647976, -10.365448017005072, -16.569306084531203, -8.618551653069298, -9.858719758861435, -11.299813861700947, -9.764859025621877, -9.640623275559971, -17.198430858096827], "policy_pol1_reward": [-36.79799003719028, -64.01635743938189, -36.41955308919714, -42.12447569376508, -58.368099457118866, -19.353320354848364, -46.861620500919656, -12.05154981797538, -19.30063211643812, -2.912126875537116, -6.767921400150621, -49.64509846632052, -21.255343235696678, -3.1576664630345346, -58.60209176238083, -12.962770330870343, -20.242714053979984, -5.361504152157523, -4.642917438814993, -3.071808523953666, -34.58930973282739, -16.82924682703796, -6.378305789271188, -3.981523347756064, -12.296453821289388, -16.23071702076256, -11.103648439357519, -6.398838794383891, -37.13328427974121, -16.804971790886206, -5.080703166503498, -27.52569748700281, -1.4258064072033871, -3.0610339624389358, -23.372452575705466, -3.644377482891018, -5.992252128977643, -14.836397240157622, -24.452368525459388, -17.387267739476208, -12.605311647745566, -12.35129040219466, -19.341811059222444, -50.65344809191254, -5.784391615822456, -2.452548055169973, -2.909850529674177, -6.416438266986571, -5.478805082090835, -5.950161828799521, -5.100864494597131, -25.67580676388642, -9.083591147228951, -5.193795566165527, -19.078940292027628, -8.418454913513273, -2.2875064780859806, -5.571074477396952, -3.314038709651337, -15.128642161841038, -40.187000161327425, -7.141937619172369, -4.004777964341028, -5.947040027201147, -3.014545153659908, -1.8123772083843768, -13.811475402122138, -6.416060794228624, -11.467961876656021, -8.387604147875955, -13.061824725230831, -13.49843108861954, -7.8058320595948025, -6.249170252319264, -19.345639937071624, -17.366815779006533, -2.650667328766975, -13.080522651156333, -9.169001911302363, -22.071876663705595, -13.84766309979451, -22.097423744809763, -19.429604513266792, -13.634497662429307, -12.296461360928053, -3.1536903873861033, -5.068909763735902, -6.756049232034548, -2.7156010938564865, -11.175129584939791, -5.169942827883984, -12.207634424310681, -4.126156154814051, -11.021419733212108, -8.824393703771628, -7.119423158274379, -4.475727717176195, -6.721445485848578, -7.368840002170308, -6.530902693721973]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18511428651422562, "mean_inference_ms": 0.6580714986268174, "mean_action_processing_ms": 0.04482569815720687, "mean_env_wait_ms": 0.27716355584978286, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 86394, "timesteps_this_iter": 0, "agent_timesteps_total": 172788, "timers": {"sample_time_ms": 9992.125, "sample_throughput": 411.724, "load_time_ms": 0.157, "load_throughput": 26164316.385, "learn_time_ms": 5168.762, "learn_throughput": 795.935}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.481826781075991, "policy_loss": 0.0020729824080869246, "vf_loss": 3.4796554072294383, "vf_explained_var": 0.016633492273588974, "kl": 0.009328276801988977, "entropy": 0.6197380588079492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.815299729081744, "policy_loss": -0.0058495764242252335, "vf_loss": 3.8210969941923394, "vf_explained_var": -0.15989179636041323, "kl": 0.014876857826341924, "entropy": 1.0927053801715374, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 86394, "num_agent_steps_sampled": 172788, "num_steps_trained": 86394, "num_agent_steps_trained": 172788, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 357, "training_iteration": 21, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-33-05", "timestamp": 1674487985, "time_this_iter_s": 9.920241117477417, "time_total_s": 209.03327107429504, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dae0a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dadfe50>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 209.03327107429504, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 18.61428571428571, "ram_util_percent": 63.771428571428565}}
{"episode_reward_max": -12.384281450509718, "episode_reward_min": -83.01759904863157, "episode_reward_mean": -28.041571122627765, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -70.72114522734213, "pol1": -50.65344809191254}, "policy_reward_max": {"pol0": -8.618551653069298, "pol1": -1.4258064072033871}, "policy_reward_mean": {"pol0": -16.76503434279526, "pol1": -11.276536779832508}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.776864622535516, -31.69738711156468, -49.18131667880659, -68.92039211044045, -45.042114220441, -36.264913904347765, -41.35298486541953, -83.01759904863157, -36.842179640290745, -25.563147098123597, -19.953375581165425, -77.31165097161595, -47.938669335803226, -27.306167256917874, -57.08345868536836, -19.34004966155121, -23.860029956877966, -42.4136865589754, -20.484652215855103, -14.88406368396049, -27.555755363791466, -38.46520869676067, -35.338995032184684, -28.885256222255524, -25.604843856176487, -42.703903561265754, -64.6598202619595, -18.619573547029248, -20.810385197953607, -17.35736334278012, -16.999297941817655, -27.618548376641773, -21.20581864813048, -28.89454150774236, -49.891529081866395, -24.419304297982503, -28.746581008336005, -38.02272193885811, -25.130497677525753, -12.384281450509718, -19.941406393220667, -24.757300105790925, -28.848341830577372, -65.73766841129932, -30.081815626397436, -17.738304996241002, -32.223520801329386, -33.97199670030143, -18.236370220529068, -25.060165537666006, -22.090507471962503, -26.589818525123437, -20.396667550301892, -23.47843937874901, -27.374485587009453, -18.15022530947204, -17.729852260999174, -32.21920748707139, -31.36112696975832, -17.337112176806013, -22.589307569347362, -25.02431556657163, -32.37533811160638, -26.29956110881011, -35.115227581730494, -32.89095922392349, -25.27414342448304, -22.22418188980984, -18.824917359945054, -17.07784934562673, -18.97114111218771, -13.244492868948225, -25.01117078435815, -16.61423616488761, -26.36635196695866, -14.49160417181911, -27.590725817743323, -17.442945356840944, -16.978142917135777, -15.77554157887714, -16.486304511470458, -17.00946327773029, -23.729333551818787, -24.68854185337175, -18.00653954927049, -37.96105863169995, -21.882085483321752, -22.987089664716404, -26.99735216493048, -17.45652684836887, -22.360556802852198, -20.257282418294853, -17.185707898812606, -23.00592881581558, -14.090726497800564, -17.72601961975289, -32.199671077386206, -16.285596723488577, -15.65901944582212, -34.12688994357524], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-13.415360470378005, -27.054469672749715, -46.10950815485294, -34.331082377613086, -28.212867393403062, -29.88660811507659, -37.371461517663455, -70.72114522734213, -20.611462619528194, -14.459498658766101, -13.554536786781544, -40.17836669187473, -31.133697544917077, -22.225464090414388, -29.557761198365533, -17.91424325434781, -20.798995994439014, -19.041233983269915, -16.840274732964076, -8.891811554982834, -12.719358123633846, -14.012840171301278, -17.951727292708483, -16.27994457450995, -13.253553453981812, -23.362092502043243, -14.006372170047012, -12.835181931206785, -18.357837142783644, -14.44751281310596, -10.582859674831077, -22.139743294550943, -15.255656819330964, -23.79367701314522, -24.215722317979953, -15.335713150753573, -23.55278544217046, -18.94378164683051, -16.712042764012484, -10.096774972423729, -14.370331915823717, -21.443261396139572, -13.719699668736324, -25.550668249971913, -22.939878007225087, -13.733527031899976, -26.276480774128242, -30.957451546641497, -16.423993012144674, -11.248690135543884, -15.674446677733886, -15.121856648467409, -12.009063402425936, -10.41661465351816, -13.876054498389923, -10.344393249877237, -11.480682008679912, -12.873567549999759, -13.994311190751768, -14.686444848039036, -9.50878491819103, -15.855313655269265, -10.30346144790079, -12.451898009015597, -13.017803836920704, -13.46135471065671, -11.639645762053744, -9.927720528881792, -15.671226972558953, -12.008939581890822, -12.215091880153162, -10.528891775091731, -13.83604119941837, -11.444293337003641, -14.158717542647976, -10.365448017005072, -16.569306084531203, -8.618551653069298, -9.858719758861435, -11.299813861700947, -9.764859025621877, -9.640623275559971, -17.198430858096827, -10.635673669174944, -9.823019288102829, -11.031098229260746, -12.362040142675648, -11.71413501418362, -9.097893852201693, -10.356328845964498, -13.315051981149045, -9.368688762894314, -10.628951998212164, -13.178140090877633, -11.383557052861939, -12.669097480830064, -11.285188773196708, -10.127424173520991, -10.484170542041875, -12.391592913057439], "policy_pol1_reward": [-5.361504152157523, -4.642917438814993, -3.071808523953666, -34.58930973282739, -16.82924682703796, -6.378305789271188, -3.981523347756064, -12.296453821289388, -16.23071702076256, -11.103648439357519, -6.398838794383891, -37.13328427974121, -16.804971790886206, -5.080703166503498, -27.52569748700281, -1.4258064072033871, -3.0610339624389358, -23.372452575705466, -3.644377482891018, -5.992252128977643, -14.836397240157622, -24.452368525459388, -17.387267739476208, -12.605311647745566, -12.35129040219466, -19.341811059222444, -50.65344809191254, -5.784391615822456, -2.452548055169973, -2.909850529674177, -6.416438266986571, -5.478805082090835, -5.950161828799521, -5.100864494597131, -25.67580676388642, -9.083591147228951, -5.193795566165527, -19.078940292027628, -8.418454913513273, -2.2875064780859806, -5.571074477396952, -3.314038709651337, -15.128642161841038, -40.187000161327425, -7.141937619172369, -4.004777964341028, -5.947040027201147, -3.014545153659908, -1.8123772083843768, -13.811475402122138, -6.416060794228624, -11.467961876656021, -8.387604147875955, -13.061824725230831, -13.49843108861954, -7.8058320595948025, -6.249170252319264, -19.345639937071624, -17.366815779006533, -2.650667328766975, -13.080522651156333, -9.169001911302363, -22.071876663705595, -13.84766309979451, -22.097423744809763, -19.429604513266792, -13.634497662429307, -12.296461360928053, -3.1536903873861033, -5.068909763735902, -6.756049232034548, -2.7156010938564865, -11.175129584939791, -5.169942827883984, -12.207634424310681, -4.126156154814051, -11.021419733212108, -8.824393703771628, -7.119423158274379, -4.475727717176195, -6.721445485848578, -7.368840002170308, -6.530902693721973, -14.052868184196806, -8.183520261167637, -26.92996040243921, -9.52004534064613, -11.272954650532778, -17.89945831272879, -7.100198002404375, -9.045504821703148, -10.888593655400536, -6.556755900600432, -9.827788724937955, -2.707169444938623, -5.056922138922829, -20.914482304189505, -6.158172549967582, -5.17484890378025, -21.735297030517806]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1851152718746784, "mean_inference_ms": 0.6580859251313496, "mean_action_processing_ms": 0.044817844694366185, "mean_env_wait_ms": 0.27705373378824627, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 90508, "timesteps_this_iter": 0, "agent_timesteps_total": 181016, "timers": {"sample_time_ms": 9985.48, "sample_throughput": 411.998, "load_time_ms": 0.169, "load_throughput": 24413365.388, "learn_time_ms": 5172.591, "learn_throughput": 795.346}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6916295035625808, "policy_loss": 0.001913975039497018, "vf_loss": 1.6896141663348923, "vf_explained_var": 0.05658943230907122, "kl": 0.009611055188906903, "entropy": 0.5825370086046556, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.682480672430635, "policy_loss": 0.004903793594955156, "vf_loss": 5.677528291987255, "vf_explained_var": 0.002864732717474302, "kl": 0.01381059230552637, "entropy": 1.0634983067711195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 90508, "num_agent_steps_sampled": 181016, "num_steps_trained": 90508, "num_agent_steps_trained": 181016, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 374, "training_iteration": 22, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-33-15", "timestamp": 1674487995, "time_this_iter_s": 9.971763134002686, "time_total_s": 219.00503420829773, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dae0160>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dad95e0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 219.00503420829773, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 19.292857142857144, "ram_util_percent": 63.749999999999986}}
{"episode_reward_max": -12.384281450509718, "episode_reward_min": -65.73766841129932, "episode_reward_mean": -24.327626457536475, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -30.957451546641497, "pol1": -50.65344809191254}, "policy_reward_max": {"pol0": -8.618551653069298, "pol1": -1.8123772083843768}, "policy_reward_mean": {"pol0": -13.613044541322761, "pol1": -10.714581916213708}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.4136865589754, -20.484652215855103, -14.88406368396049, -27.555755363791466, -38.46520869676067, -35.338995032184684, -28.885256222255524, -25.604843856176487, -42.703903561265754, -64.6598202619595, -18.619573547029248, -20.810385197953607, -17.35736334278012, -16.999297941817655, -27.618548376641773, -21.20581864813048, -28.89454150774236, -49.891529081866395, -24.419304297982503, -28.746581008336005, -38.02272193885811, -25.130497677525753, -12.384281450509718, -19.941406393220667, -24.757300105790925, -28.848341830577372, -65.73766841129932, -30.081815626397436, -17.738304996241002, -32.223520801329386, -33.97199670030143, -18.236370220529068, -25.060165537666006, -22.090507471962503, -26.589818525123437, -20.396667550301892, -23.47843937874901, -27.374485587009453, -18.15022530947204, -17.729852260999174, -32.21920748707139, -31.36112696975832, -17.337112176806013, -22.589307569347362, -25.02431556657163, -32.37533811160638, -26.29956110881011, -35.115227581730494, -32.89095922392349, -25.27414342448304, -22.22418188980984, -18.824917359945054, -17.07784934562673, -18.97114111218771, -13.244492868948225, -25.01117078435815, -16.61423616488761, -26.36635196695866, -14.49160417181911, -27.590725817743323, -17.442945356840944, -16.978142917135777, -15.77554157887714, -16.486304511470458, -17.00946327773029, -23.729333551818787, -24.68854185337175, -18.00653954927049, -37.96105863169995, -21.882085483321752, -22.987089664716404, -26.99735216493048, -17.45652684836887, -22.360556802852198, -20.257282418294853, -17.185707898812606, -23.00592881581558, -14.090726497800564, -17.72601961975289, -32.199671077386206, -16.285596723488577, -15.65901944582212, -34.12688994357524, -23.997443695892716, -19.877798722174948, -17.113266860205798, -27.354892285032967, -27.633014049237282, -13.118351464993337, -21.5332047126187, -28.943561357231207, -18.2673987861688, -30.47320981062594, -15.326598297450634, -18.1490644279005, -17.359430593413922, -16.090655255612987, -12.744987611680541, -12.761064010434074, -17.31389230009732], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-19.041233983269915, -16.840274732964076, -8.891811554982834, -12.719358123633846, -14.012840171301278, -17.951727292708483, -16.27994457450995, -13.253553453981812, -23.362092502043243, -14.006372170047012, -12.835181931206785, -18.357837142783644, -14.44751281310596, -10.582859674831077, -22.139743294550943, -15.255656819330964, -23.79367701314522, -24.215722317979953, -15.335713150753573, -23.55278544217046, -18.94378164683051, -16.712042764012484, -10.096774972423729, -14.370331915823717, -21.443261396139572, -13.719699668736324, -25.550668249971913, -22.939878007225087, -13.733527031899976, -26.276480774128242, -30.957451546641497, -16.423993012144674, -11.248690135543884, -15.674446677733886, -15.121856648467409, -12.009063402425936, -10.41661465351816, -13.876054498389923, -10.344393249877237, -11.480682008679912, -12.873567549999759, -13.994311190751768, -14.686444848039036, -9.50878491819103, -15.855313655269265, -10.30346144790079, -12.451898009015597, -13.017803836920704, -13.46135471065671, -11.639645762053744, -9.927720528881792, -15.671226972558953, -12.008939581890822, -12.215091880153162, -10.528891775091731, -13.83604119941837, -11.444293337003641, -14.158717542647976, -10.365448017005072, -16.569306084531203, -8.618551653069298, -9.858719758861435, -11.299813861700947, -9.764859025621877, -9.640623275559971, -17.198430858096827, -10.635673669174944, -9.823019288102829, -11.031098229260746, -12.362040142675648, -11.71413501418362, -9.097893852201693, -10.356328845964498, -13.315051981149045, -9.368688762894314, -10.628951998212164, -13.178140090877633, -11.383557052861939, -12.669097480830064, -11.285188773196708, -10.127424173520991, -10.484170542041875, -12.391592913057439, -10.887444193284745, -10.857796924674268, -10.864806448637765, -10.450568763561797, -9.623219252980206, -10.193760704592457, -14.003634754904542, -9.781872246910167, -12.093750775898927, -10.194665816373142, -11.95198306709374, -8.751750590135135, -9.007351323176497, -12.239238358085194, -10.290409077787082, -9.959636460936686, -11.185660862231119], "policy_pol1_reward": [-23.372452575705466, -3.644377482891018, -5.992252128977643, -14.836397240157622, -24.452368525459388, -17.387267739476208, -12.605311647745566, -12.35129040219466, -19.341811059222444, -50.65344809191254, -5.784391615822456, -2.452548055169973, -2.909850529674177, -6.416438266986571, -5.478805082090835, -5.950161828799521, -5.100864494597131, -25.67580676388642, -9.083591147228951, -5.193795566165527, -19.078940292027628, -8.418454913513273, -2.2875064780859806, -5.571074477396952, -3.314038709651337, -15.128642161841038, -40.187000161327425, -7.141937619172369, -4.004777964341028, -5.947040027201147, -3.014545153659908, -1.8123772083843768, -13.811475402122138, -6.416060794228624, -11.467961876656021, -8.387604147875955, -13.061824725230831, -13.49843108861954, -7.8058320595948025, -6.249170252319264, -19.345639937071624, -17.366815779006533, -2.650667328766975, -13.080522651156333, -9.169001911302363, -22.071876663705595, -13.84766309979451, -22.097423744809763, -19.429604513266792, -13.634497662429307, -12.296461360928053, -3.1536903873861033, -5.068909763735902, -6.756049232034548, -2.7156010938564865, -11.175129584939791, -5.169942827883984, -12.207634424310681, -4.126156154814051, -11.021419733212108, -8.824393703771628, -7.119423158274379, -4.475727717176195, -6.721445485848578, -7.368840002170308, -6.530902693721973, -14.052868184196806, -8.183520261167637, -26.92996040243921, -9.52004534064613, -11.272954650532778, -17.89945831272879, -7.100198002404375, -9.045504821703148, -10.888593655400536, -6.556755900600432, -9.827788724937955, -2.707169444938623, -5.056922138922829, -20.914482304189505, -6.158172549967582, -5.17484890378025, -21.735297030517806, -13.10999950260797, -9.020001797500676, -6.248460411568029, -16.9043235214712, -18.009794796257083, -2.924590760400873, -7.529569957714155, -19.161689110321063, -6.173648010269876, -20.278543994252782, -3.3746152303568944, -9.39731383776536, -8.352079270237411, -3.851416897527795, -2.454578533893458, -2.8014275494973795, -6.128231437866191]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18511883733158907, "mean_inference_ms": 0.6580956357075988, "mean_action_processing_ms": 0.04481090792545876, "mean_env_wait_ms": 0.27695961336408936, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 94622, "timesteps_this_iter": 0, "agent_timesteps_total": 189244, "timers": {"sample_time_ms": 9987.402, "sample_throughput": 411.919, "load_time_ms": 0.169, "load_throughput": 24399556.923, "learn_time_ms": 5158.575, "learn_throughput": 797.507}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.61252466130148, "policy_loss": -0.0023068078982760197, "vf_loss": 1.6147331845966013, "vf_explained_var": 0.137656404885153, "kl": 0.009317843841442179, "entropy": 0.5783749176499744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.459940552120679, "policy_loss": -0.007624379929620772, "vf_loss": 4.467520939310392, "vf_explained_var": -0.27389661526928344, "kl": 0.012505998323210104, "entropy": 1.144454081604878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 94622, "num_agent_steps_sampled": 189244, "num_steps_trained": 94622, "num_agent_steps_trained": 189244, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 391, "training_iteration": 23, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-33-25", "timestamp": 1674488005, "time_this_iter_s": 9.836836099624634, "time_total_s": 228.84187030792236, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d28b820>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dada9d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 228.84187030792236, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 17.578571428571426, "ram_util_percent": 63.799999999999976}}
{"episode_reward_max": -12.384281450509718, "episode_reward_min": -65.73766841129932, "episode_reward_mean": -22.816404924607895, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -30.957451546641497, "pol1": -40.187000161327425}, "policy_reward_max": {"pol0": -8.51288480529414, "pol1": -1.8123772083843768}, "policy_reward_mean": {"pol0": -12.565269042710431, "pol1": -10.251135881897465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-49.891529081866395, -24.419304297982503, -28.746581008336005, -38.02272193885811, -25.130497677525753, -12.384281450509718, -19.941406393220667, -24.757300105790925, -28.848341830577372, -65.73766841129932, -30.081815626397436, -17.738304996241002, -32.223520801329386, -33.97199670030143, -18.236370220529068, -25.060165537666006, -22.090507471962503, -26.589818525123437, -20.396667550301892, -23.47843937874901, -27.374485587009453, -18.15022530947204, -17.729852260999174, -32.21920748707139, -31.36112696975832, -17.337112176806013, -22.589307569347362, -25.02431556657163, -32.37533811160638, -26.29956110881011, -35.115227581730494, -32.89095922392349, -25.27414342448304, -22.22418188980984, -18.824917359945054, -17.07784934562673, -18.97114111218771, -13.244492868948225, -25.01117078435815, -16.61423616488761, -26.36635196695866, -14.49160417181911, -27.590725817743323, -17.442945356840944, -16.978142917135777, -15.77554157887714, -16.486304511470458, -17.00946327773029, -23.729333551818787, -24.68854185337175, -18.00653954927049, -37.96105863169995, -21.882085483321752, -22.987089664716404, -26.99735216493048, -17.45652684836887, -22.360556802852198, -20.257282418294853, -17.185707898812606, -23.00592881581558, -14.090726497800564, -17.72601961975289, -32.199671077386206, -16.285596723488577, -15.65901944582212, -34.12688994357524, -23.997443695892716, -19.877798722174948, -17.113266860205798, -27.354892285032967, -27.633014049237282, -13.118351464993337, -21.5332047126187, -28.943561357231207, -18.2673987861688, -30.47320981062594, -15.326598297450634, -18.1490644279005, -17.359430593413922, -16.090655255612987, -12.744987611680541, -12.761064010434074, -17.31389230009732, -14.318373138019146, -17.60017230505828, -27.36747325215353, -20.61483158460201, -17.045250030328372, -29.915976500053095, -26.158263302428285, -19.450169808451257, -12.421370199586294, -23.397573868289538, -18.83780082196523, -17.489028774514665, -20.076492849700724, -17.252736990981397, -28.964683418373728, -17.234769421476145, -13.234594456441316], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-24.215722317979953, -15.335713150753573, -23.55278544217046, -18.94378164683051, -16.712042764012484, -10.096774972423729, -14.370331915823717, -21.443261396139572, -13.719699668736324, -25.550668249971913, -22.939878007225087, -13.733527031899976, -26.276480774128242, -30.957451546641497, -16.423993012144674, -11.248690135543884, -15.674446677733886, -15.121856648467409, -12.009063402425936, -10.41661465351816, -13.876054498389923, -10.344393249877237, -11.480682008679912, -12.873567549999759, -13.994311190751768, -14.686444848039036, -9.50878491819103, -15.855313655269265, -10.30346144790079, -12.451898009015597, -13.017803836920704, -13.46135471065671, -11.639645762053744, -9.927720528881792, -15.671226972558953, -12.008939581890822, -12.215091880153162, -10.528891775091731, -13.83604119941837, -11.444293337003641, -14.158717542647976, -10.365448017005072, -16.569306084531203, -8.618551653069298, -9.858719758861435, -11.299813861700947, -9.764859025621877, -9.640623275559971, -17.198430858096827, -10.635673669174944, -9.823019288102829, -11.031098229260746, -12.362040142675648, -11.71413501418362, -9.097893852201693, -10.356328845964498, -13.315051981149045, -9.368688762894314, -10.628951998212164, -13.178140090877633, -11.383557052861939, -12.669097480830064, -11.285188773196708, -10.127424173520991, -10.484170542041875, -12.391592913057439, -10.887444193284745, -10.857796924674268, -10.864806448637765, -10.450568763561797, -9.623219252980206, -10.193760704592457, -14.003634754904542, -9.781872246910167, -12.093750775898927, -10.194665816373142, -11.95198306709374, -8.751750590135135, -9.007351323176497, -12.239238358085194, -10.290409077787082, -9.959636460936686, -11.185660862231119, -8.727597948199582, -9.381732197864173, -9.658957063918391, -10.068404326000715, -10.357614909680407, -9.865186978972494, -12.499669997128654, -10.559416336381055, -8.51288480529414, -10.025056669132159, -11.022529128813074, -9.939591710190692, -9.23856543862993, -8.948676000982765, -10.11595238552159, -9.994720455657733, -10.077571034796819], "policy_pol1_reward": [-25.67580676388642, -9.083591147228951, -5.193795566165527, -19.078940292027628, -8.418454913513273, -2.2875064780859806, -5.571074477396952, -3.314038709651337, -15.128642161841038, -40.187000161327425, -7.141937619172369, -4.004777964341028, -5.947040027201147, -3.014545153659908, -1.8123772083843768, -13.811475402122138, -6.416060794228624, -11.467961876656021, -8.387604147875955, -13.061824725230831, -13.49843108861954, -7.8058320595948025, -6.249170252319264, -19.345639937071624, -17.366815779006533, -2.650667328766975, -13.080522651156333, -9.169001911302363, -22.071876663705595, -13.84766309979451, -22.097423744809763, -19.429604513266792, -13.634497662429307, -12.296461360928053, -3.1536903873861033, -5.068909763735902, -6.756049232034548, -2.7156010938564865, -11.175129584939791, -5.169942827883984, -12.207634424310681, -4.126156154814051, -11.021419733212108, -8.824393703771628, -7.119423158274379, -4.475727717176195, -6.721445485848578, -7.368840002170308, -6.530902693721973, -14.052868184196806, -8.183520261167637, -26.92996040243921, -9.52004534064613, -11.272954650532778, -17.89945831272879, -7.100198002404375, -9.045504821703148, -10.888593655400536, -6.556755900600432, -9.827788724937955, -2.707169444938623, -5.056922138922829, -20.914482304189505, -6.158172549967582, -5.17484890378025, -21.735297030517806, -13.10999950260797, -9.020001797500676, -6.248460411568029, -16.9043235214712, -18.009794796257083, -2.924590760400873, -7.529569957714155, -19.161689110321063, -6.173648010269876, -20.278543994252782, -3.3746152303568944, -9.39731383776536, -8.352079270237411, -3.851416897527795, -2.454578533893458, -2.8014275494973795, -6.128231437866191, -5.590775189819552, -8.218440107194084, -17.70851618823514, -10.546427258601305, -6.687635120647953, -20.050789521080617, -13.658593305299608, -8.890753472070186, -3.908485394292159, -13.372517199157384, -7.815271693152149, -7.549437064323969, -10.837927411070776, -8.304060989998659, -18.84873103285215, -7.240048965818415, -3.157023421644495]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18510526650385714, "mean_inference_ms": 0.6581052317953673, "mean_action_processing_ms": 0.04480507143136089, "mean_env_wait_ms": 0.2768739095066207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 98736, "timesteps_this_iter": 0, "agent_timesteps_total": 197472, "timers": {"sample_time_ms": 9975.472, "sample_throughput": 412.412, "load_time_ms": 0.169, "load_throughput": 24296489.237, "learn_time_ms": 5154.53, "learn_throughput": 798.133}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6546951186370279, "policy_loss": -0.003895735441862295, "vf_loss": 0.6584688004746567, "vf_explained_var": 0.24565514797965685, "kl": 0.011572348878568542, "entropy": 0.5098494433797895, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.17708243689558, "policy_loss": 0.0005577276261950222, "vf_loss": 4.176479599221299, "vf_explained_var": -0.19893765908976396, "kl": 0.012829677053802394, "entropy": 1.1336979917561014, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 98736, "num_agent_steps_sampled": 197472, "num_steps_trained": 98736, "num_agent_steps_trained": 197472, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 408, "training_iteration": 24, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-33-35", "timestamp": 1674488015, "time_this_iter_s": 9.898752927780151, "time_total_s": 238.74062323570251, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dae0a60>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dadad30>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 238.74062323570251, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 17.900000000000002, "ram_util_percent": 63.807142857142836}}
{"episode_reward_max": -11.878543132915095, "episode_reward_min": -39.638400145351774, "episode_reward_mean": -21.711547022691658, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -17.198430858096827, "pol1": -30.273306838383544}, "policy_reward_max": {"pol0": -7.805017534892439, "pol1": -2.454578533893458}, "policy_reward_mean": {"pol0": -10.925154011756296, "pol1": -10.786393010935363}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-26.589818525123437, -20.396667550301892, -23.47843937874901, -27.374485587009453, -18.15022530947204, -17.729852260999174, -32.21920748707139, -31.36112696975832, -17.337112176806013, -22.589307569347362, -25.02431556657163, -32.37533811160638, -26.29956110881011, -35.115227581730494, -32.89095922392349, -25.27414342448304, -22.22418188980984, -18.824917359945054, -17.07784934562673, -18.97114111218771, -13.244492868948225, -25.01117078435815, -16.61423616488761, -26.36635196695866, -14.49160417181911, -27.590725817743323, -17.442945356840944, -16.978142917135777, -15.77554157887714, -16.486304511470458, -17.00946327773029, -23.729333551818787, -24.68854185337175, -18.00653954927049, -37.96105863169995, -21.882085483321752, -22.987089664716404, -26.99735216493048, -17.45652684836887, -22.360556802852198, -20.257282418294853, -17.185707898812606, -23.00592881581558, -14.090726497800564, -17.72601961975289, -32.199671077386206, -16.285596723488577, -15.65901944582212, -34.12688994357524, -23.997443695892716, -19.877798722174948, -17.113266860205798, -27.354892285032967, -27.633014049237282, -13.118351464993337, -21.5332047126187, -28.943561357231207, -18.2673987861688, -30.47320981062594, -15.326598297450634, -18.1490644279005, -17.359430593413922, -16.090655255612987, -12.744987611680541, -12.761064010434074, -17.31389230009732, -14.318373138019146, -17.60017230505828, -27.36747325215353, -20.61483158460201, -17.045250030328372, -29.915976500053095, -26.158263302428285, -19.450169808451257, -12.421370199586294, -23.397573868289538, -18.83780082196523, -17.489028774514665, -20.076492849700724, -17.252736990981397, -28.964683418373728, -17.234769421476145, -13.234594456441316, -31.5985648909537, -26.869821676673492, -21.177206439038397, -14.3361264118026, -15.530241561138665, -12.260685712214183, -18.70602018005523, -14.816760883617718, -26.04497985635243, -11.878543132915095, -26.055415259544755, -32.00138987085324, -18.644435675077332, -37.16101185830426, -18.281308901176164, -21.79561090370046, -39.638400145351774], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-15.121856648467409, -12.009063402425936, -10.41661465351816, -13.876054498389923, -10.344393249877237, -11.480682008679912, -12.873567549999759, -13.994311190751768, -14.686444848039036, -9.50878491819103, -15.855313655269265, -10.30346144790079, -12.451898009015597, -13.017803836920704, -13.46135471065671, -11.639645762053744, -9.927720528881792, -15.671226972558953, -12.008939581890822, -12.215091880153162, -10.528891775091731, -13.83604119941837, -11.444293337003641, -14.158717542647976, -10.365448017005072, -16.569306084531203, -8.618551653069298, -9.858719758861435, -11.299813861700947, -9.764859025621877, -9.640623275559971, -17.198430858096827, -10.635673669174944, -9.823019288102829, -11.031098229260746, -12.362040142675648, -11.71413501418362, -9.097893852201693, -10.356328845964498, -13.315051981149045, -9.368688762894314, -10.628951998212164, -13.178140090877633, -11.383557052861939, -12.669097480830064, -11.285188773196708, -10.127424173520991, -10.484170542041875, -12.391592913057439, -10.887444193284745, -10.857796924674268, -10.864806448637765, -10.450568763561797, -9.623219252980206, -10.193760704592457, -14.003634754904542, -9.781872246910167, -12.093750775898927, -10.194665816373142, -11.95198306709374, -8.751750590135135, -9.007351323176497, -12.239238358085194, -10.290409077787082, -9.959636460936686, -11.185660862231119, -8.727597948199582, -9.381732197864173, -9.658957063918391, -10.068404326000715, -10.357614909680407, -9.865186978972494, -12.499669997128654, -10.559416336381055, -8.51288480529414, -10.025056669132159, -11.022529128813074, -9.939591710190692, -9.23856543862993, -8.948676000982765, -10.11595238552159, -9.994720455657733, -10.077571034796819, -8.08422116194545, -11.291287801644984, -7.846791126460852, -11.319135492167405, -8.30941574101197, -7.805017534892439, -7.897166250480295, -10.483147091731983, -9.797200507726643, -9.375016304483719, -9.319716943433104, -9.683534659317344, -8.251551127924937, -9.784544789922316, -9.014592073648236, -9.556313700985607, -9.365093306968271], "policy_pol1_reward": [-11.467961876656021, -8.387604147875955, -13.061824725230831, -13.49843108861954, -7.8058320595948025, -6.249170252319264, -19.345639937071624, -17.366815779006533, -2.650667328766975, -13.080522651156333, -9.169001911302363, -22.071876663705595, -13.84766309979451, -22.097423744809763, -19.429604513266792, -13.634497662429307, -12.296461360928053, -3.1536903873861033, -5.068909763735902, -6.756049232034548, -2.7156010938564865, -11.175129584939791, -5.169942827883984, -12.207634424310681, -4.126156154814051, -11.021419733212108, -8.824393703771628, -7.119423158274379, -4.475727717176195, -6.721445485848578, -7.368840002170308, -6.530902693721973, -14.052868184196806, -8.183520261167637, -26.92996040243921, -9.52004534064613, -11.272954650532778, -17.89945831272879, -7.100198002404375, -9.045504821703148, -10.888593655400536, -6.556755900600432, -9.827788724937955, -2.707169444938623, -5.056922138922829, -20.914482304189505, -6.158172549967582, -5.17484890378025, -21.735297030517806, -13.10999950260797, -9.020001797500676, -6.248460411568029, -16.9043235214712, -18.009794796257083, -2.924590760400873, -7.529569957714155, -19.161689110321063, -6.173648010269876, -20.278543994252782, -3.3746152303568944, -9.39731383776536, -8.352079270237411, -3.851416897527795, -2.454578533893458, -2.8014275494973795, -6.128231437866191, -5.590775189819552, -8.218440107194084, -17.70851618823514, -10.546427258601305, -6.687635120647953, -20.050789521080617, -13.658593305299608, -8.890753472070186, -3.908485394292159, -13.372517199157384, -7.815271693152149, -7.549437064323969, -10.837927411070776, -8.304060989998659, -18.84873103285215, -7.240048965818415, -3.157023421644495, -23.51434372900823, -15.57853387502853, -13.330415312577557, -3.0169909196351923, -7.2208258201266995, -4.455668177321746, -10.808853929574916, -4.3336137918857265, -16.2477793486258, -2.50352682843136, -16.73569831611166, -22.317855211535903, -10.392884547152393, -27.37646706838197, -9.266716827527945, -12.23929720271485, -30.273306838383544]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18508702923114817, "mean_inference_ms": 0.6581337315349737, "mean_action_processing_ms": 0.044800713424473476, "mean_env_wait_ms": 0.27680578369886977, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 102850, "timesteps_this_iter": 0, "agent_timesteps_total": 205700, "timers": {"sample_time_ms": 9973.609, "sample_throughput": 412.489, "load_time_ms": 0.17, "load_throughput": 24221457.967, "learn_time_ms": 5159.043, "learn_throughput": 797.435}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7861529688501226, "policy_loss": -0.007092211855342612, "vf_loss": 0.793117131475204, "vf_explained_var": 0.3589175187672178, "kl": 0.012140269455388382, "entropy": 0.49944292986765504, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 11.733971405743311, "policy_loss": -0.004403997894648152, "vf_loss": 11.738338011161735, "vf_explained_var": -0.24669921572009723, "kl": 0.010636217162633936, "entropy": 1.1586199320852757, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 102850, "num_agent_steps_sampled": 205700, "num_steps_trained": 102850, "num_agent_steps_trained": 205700, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 425, "training_iteration": 25, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-33-45", "timestamp": 1674488025, "time_this_iter_s": 9.95370101928711, "time_total_s": 248.69432425498962, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dada9d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dadab80>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 248.69432425498962, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 16.742857142857144, "ram_util_percent": 63.799999999999976}}
{"episode_reward_max": -11.878543132915095, "episode_reward_min": -39.638400145351774, "episode_reward_mean": -20.594826311187582, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -17.198430858096827, "pol1": -30.273306838383544}, "policy_reward_max": {"pol0": -6.659806733067634, "pol1": -2.454578533893458}, "policy_reward_mean": {"pol0": -10.098001900303977, "pol1": -10.496824410883601}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.824917359945054, -17.07784934562673, -18.97114111218771, -13.244492868948225, -25.01117078435815, -16.61423616488761, -26.36635196695866, -14.49160417181911, -27.590725817743323, -17.442945356840944, -16.978142917135777, -15.77554157887714, -16.486304511470458, -17.00946327773029, -23.729333551818787, -24.68854185337175, -18.00653954927049, -37.96105863169995, -21.882085483321752, -22.987089664716404, -26.99735216493048, -17.45652684836887, -22.360556802852198, -20.257282418294853, -17.185707898812606, -23.00592881581558, -14.090726497800564, -17.72601961975289, -32.199671077386206, -16.285596723488577, -15.65901944582212, -34.12688994357524, -23.997443695892716, -19.877798722174948, -17.113266860205798, -27.354892285032967, -27.633014049237282, -13.118351464993337, -21.5332047126187, -28.943561357231207, -18.2673987861688, -30.47320981062594, -15.326598297450634, -18.1490644279005, -17.359430593413922, -16.090655255612987, -12.744987611680541, -12.761064010434074, -17.31389230009732, -14.318373138019146, -17.60017230505828, -27.36747325215353, -20.61483158460201, -17.045250030328372, -29.915976500053095, -26.158263302428285, -19.450169808451257, -12.421370199586294, -23.397573868289538, -18.83780082196523, -17.489028774514665, -20.076492849700724, -17.252736990981397, -28.964683418373728, -17.234769421476145, -13.234594456441316, -31.5985648909537, -26.869821676673492, -21.177206439038397, -14.3361264118026, -15.530241561138665, -12.260685712214183, -18.70602018005523, -14.816760883617718, -26.04497985635243, -11.878543132915095, -26.055415259544755, -32.00138987085324, -18.644435675077332, -37.16101185830426, -18.281308901176164, -21.79561090370046, -39.638400145351774, -22.639376925808325, -12.248359789287054, -36.4077974542145, -26.46544959854524, -17.39243305815001, -18.761125995239638, -23.718745396727364, -12.514644419911093, -19.80271333562043, -12.033742052186593, -22.007479558080153, -12.343459232003779, -15.796061554799328, -23.296266759468544, -20.011279043925594, -13.878437492887242, -15.440526904310081], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-15.671226972558953, -12.008939581890822, -12.215091880153162, -10.528891775091731, -13.83604119941837, -11.444293337003641, -14.158717542647976, -10.365448017005072, -16.569306084531203, -8.618551653069298, -9.858719758861435, -11.299813861700947, -9.764859025621877, -9.640623275559971, -17.198430858096827, -10.635673669174944, -9.823019288102829, -11.031098229260746, -12.362040142675648, -11.71413501418362, -9.097893852201693, -10.356328845964498, -13.315051981149045, -9.368688762894314, -10.628951998212164, -13.178140090877633, -11.383557052861939, -12.669097480830064, -11.285188773196708, -10.127424173520991, -10.484170542041875, -12.391592913057439, -10.887444193284745, -10.857796924674268, -10.864806448637765, -10.450568763561797, -9.623219252980206, -10.193760704592457, -14.003634754904542, -9.781872246910167, -12.093750775898927, -10.194665816373142, -11.95198306709374, -8.751750590135135, -9.007351323176497, -12.239238358085194, -10.290409077787082, -9.959636460936686, -11.185660862231119, -8.727597948199582, -9.381732197864173, -9.658957063918391, -10.068404326000715, -10.357614909680407, -9.865186978972494, -12.499669997128654, -10.559416336381055, -8.51288480529414, -10.025056669132159, -11.022529128813074, -9.939591710190692, -9.23856543862993, -8.948676000982765, -10.11595238552159, -9.994720455657733, -10.077571034796819, -8.08422116194545, -11.291287801644984, -7.846791126460852, -11.319135492167405, -8.30941574101197, -7.805017534892439, -7.897166250480295, -10.483147091731983, -9.797200507726643, -9.375016304483719, -9.319716943433104, -9.683534659317344, -8.251551127924937, -9.784544789922316, -9.014592073648236, -9.556313700985607, -9.365093306968271, -7.746660146421508, -7.443024134973296, -6.659806733067634, -6.892966149708492, -6.9904779175401135, -7.801755759385281, -8.327046893990822, -8.60957650926709, -6.869539738426219, -7.419282171438643, -6.969572453557024, -6.732508201704235, -9.123220304973868, -8.980945277424848, -7.302763839308889, -7.043367881143196, -7.34124566147556], "policy_pol1_reward": [-3.1536903873861033, -5.068909763735902, -6.756049232034548, -2.7156010938564865, -11.175129584939791, -5.169942827883984, -12.207634424310681, -4.126156154814051, -11.021419733212108, -8.824393703771628, -7.119423158274379, -4.475727717176195, -6.721445485848578, -7.368840002170308, -6.530902693721973, -14.052868184196806, -8.183520261167637, -26.92996040243921, -9.52004534064613, -11.272954650532778, -17.89945831272879, -7.100198002404375, -9.045504821703148, -10.888593655400536, -6.556755900600432, -9.827788724937955, -2.707169444938623, -5.056922138922829, -20.914482304189505, -6.158172549967582, -5.17484890378025, -21.735297030517806, -13.10999950260797, -9.020001797500676, -6.248460411568029, -16.9043235214712, -18.009794796257083, -2.924590760400873, -7.529569957714155, -19.161689110321063, -6.173648010269876, -20.278543994252782, -3.3746152303568944, -9.39731383776536, -8.352079270237411, -3.851416897527795, -2.454578533893458, -2.8014275494973795, -6.128231437866191, -5.590775189819552, -8.218440107194084, -17.70851618823514, -10.546427258601305, -6.687635120647953, -20.050789521080617, -13.658593305299608, -8.890753472070186, -3.908485394292159, -13.372517199157384, -7.815271693152149, -7.549437064323969, -10.837927411070776, -8.304060989998659, -18.84873103285215, -7.240048965818415, -3.157023421644495, -23.51434372900823, -15.57853387502853, -13.330415312577557, -3.0169909196351923, -7.2208258201266995, -4.455668177321746, -10.808853929574916, -4.3336137918857265, -16.2477793486258, -2.50352682843136, -16.73569831611166, -22.317855211535903, -10.392884547152393, -27.37646706838197, -9.266716827527945, -12.23929720271485, -30.273306838383544, -14.892716779386813, -4.805335654313769, -29.74799072114687, -19.572483448836735, -10.401955140609882, -10.959370235854353, -15.391698502736512, -3.905067910643995, -12.933173597194205, -4.614459880747938, -15.037907104523121, -5.610951030299533, -6.672841249825464, -14.315321482043695, -12.708515204616706, -6.835069611744036, -8.099281242834527]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18503285372819117, "mean_inference_ms": 0.6581421825516395, "mean_action_processing_ms": 0.04479444428003594, "mean_env_wait_ms": 0.2767372932906054, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 106964, "timesteps_this_iter": 0, "agent_timesteps_total": 213928, "timers": {"sample_time_ms": 9963.601, "sample_throughput": 412.903, "load_time_ms": 0.167, "load_throughput": 24703459.78, "learn_time_ms": 5142.773, "learn_throughput": 799.958}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.36842022158167914, "policy_loss": 0.007655751513084397, "vf_loss": 0.36067695603123867, "vf_explained_var": 0.24206503337870042, "kl": 0.0082973664453372, "entropy": 0.45910842061663665, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.86413035892571, "policy_loss": 0.0039111404311067115, "vf_loss": 6.8601787853986025, "vf_explained_var": -0.2423725200196107, "kl": 0.011500707456161764, "entropy": 1.0367120906089744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 106964, "num_agent_steps_sampled": 213928, "num_steps_trained": 106964, "num_agent_steps_trained": 213928, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 442, "training_iteration": 26, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-33-55", "timestamp": 1674488035, "time_this_iter_s": 9.897108316421509, "time_total_s": 258.59143257141113, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dada1f0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dadfd30>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 258.59143257141113, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 17.928571428571427, "ram_util_percent": 63.814285714285695}}
{"episode_reward_max": -11.878543132915095, "episode_reward_min": -39.638400145351774, "episode_reward_mean": -20.728537476941845, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -14.003634754904542, "pol1": -30.273306838383544}, "policy_reward_max": {"pol0": -6.268836745289068, "pol1": -2.454578533893458}, "policy_reward_mean": {"pol0": -9.332373367307593, "pol1": -11.396164109634256}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-37.96105863169995, -21.882085483321752, -22.987089664716404, -26.99735216493048, -17.45652684836887, -22.360556802852198, -20.257282418294853, -17.185707898812606, -23.00592881581558, -14.090726497800564, -17.72601961975289, -32.199671077386206, -16.285596723488577, -15.65901944582212, -34.12688994357524, -23.997443695892716, -19.877798722174948, -17.113266860205798, -27.354892285032967, -27.633014049237282, -13.118351464993337, -21.5332047126187, -28.943561357231207, -18.2673987861688, -30.47320981062594, -15.326598297450634, -18.1490644279005, -17.359430593413922, -16.090655255612987, -12.744987611680541, -12.761064010434074, -17.31389230009732, -14.318373138019146, -17.60017230505828, -27.36747325215353, -20.61483158460201, -17.045250030328372, -29.915976500053095, -26.158263302428285, -19.450169808451257, -12.421370199586294, -23.397573868289538, -18.83780082196523, -17.489028774514665, -20.076492849700724, -17.252736990981397, -28.964683418373728, -17.234769421476145, -13.234594456441316, -31.5985648909537, -26.869821676673492, -21.177206439038397, -14.3361264118026, -15.530241561138665, -12.260685712214183, -18.70602018005523, -14.816760883617718, -26.04497985635243, -11.878543132915095, -26.055415259544755, -32.00138987085324, -18.644435675077332, -37.16101185830426, -18.281308901176164, -21.79561090370046, -39.638400145351774, -22.639376925808325, -12.248359789287054, -36.4077974542145, -26.46544959854524, -17.39243305815001, -18.761125995239638, -23.718745396727364, -12.514644419911093, -19.80271333562043, -12.033742052186593, -22.007479558080153, -12.343459232003779, -15.796061554799328, -23.296266759468544, -20.011279043925594, -13.878437492887242, -15.440526904310081, -33.32713417473907, -35.65385507105935, -16.532562301693556, -33.06023253880141, -12.846227162619966, -11.91174993554732, -16.09250037520565, -15.892373393391345, -12.97775710691883, -12.886946539407774, -33.86658157887057, -18.50946012016252, -21.210617219777873, -19.45125036725593, -19.08877782816463, -13.44588422543841, -14.926508825363264], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-11.031098229260746, -12.362040142675648, -11.71413501418362, -9.097893852201693, -10.356328845964498, -13.315051981149045, -9.368688762894314, -10.628951998212164, -13.178140090877633, -11.383557052861939, -12.669097480830064, -11.285188773196708, -10.127424173520991, -10.484170542041875, -12.391592913057439, -10.887444193284745, -10.857796924674268, -10.864806448637765, -10.450568763561797, -9.623219252980206, -10.193760704592457, -14.003634754904542, -9.781872246910167, -12.093750775898927, -10.194665816373142, -11.95198306709374, -8.751750590135135, -9.007351323176497, -12.239238358085194, -10.290409077787082, -9.959636460936686, -11.185660862231119, -8.727597948199582, -9.381732197864173, -9.658957063918391, -10.068404326000715, -10.357614909680407, -9.865186978972494, -12.499669997128654, -10.559416336381055, -8.51288480529414, -10.025056669132159, -11.022529128813074, -9.939591710190692, -9.23856543862993, -8.948676000982765, -10.11595238552159, -9.994720455657733, -10.077571034796819, -8.08422116194545, -11.291287801644984, -7.846791126460852, -11.319135492167405, -8.30941574101197, -7.805017534892439, -7.897166250480295, -10.483147091731983, -9.797200507726643, -9.375016304483719, -9.319716943433104, -9.683534659317344, -8.251551127924937, -9.784544789922316, -9.014592073648236, -9.556313700985607, -9.365093306968271, -7.746660146421508, -7.443024134973296, -6.659806733067634, -6.892966149708492, -6.9904779175401135, -7.801755759385281, -8.327046893990822, -8.60957650926709, -6.869539738426219, -7.419282171438643, -6.969572453557024, -6.732508201704235, -9.123220304973868, -8.980945277424848, -7.302763839308889, -7.043367881143196, -7.34124566147556, -7.371422573164987, -6.641246788424725, -7.431899822326125, -6.268836745289068, -7.182053469538454, -6.639949004365706, -8.899888102386186, -7.820189379284986, -7.561800651056499, -8.285173561703354, -8.637604821362846, -7.556657357459166, -6.662747780505209, -7.8948211767775645, -7.397192451450233, -7.263986083540584, -7.559324712215076], "policy_pol1_reward": [-26.92996040243921, -9.52004534064613, -11.272954650532778, -17.89945831272879, -7.100198002404375, -9.045504821703148, -10.888593655400536, -6.556755900600432, -9.827788724937955, -2.707169444938623, -5.056922138922829, -20.914482304189505, -6.158172549967582, -5.17484890378025, -21.735297030517806, -13.10999950260797, -9.020001797500676, -6.248460411568029, -16.9043235214712, -18.009794796257083, -2.924590760400873, -7.529569957714155, -19.161689110321063, -6.173648010269876, -20.278543994252782, -3.3746152303568944, -9.39731383776536, -8.352079270237411, -3.851416897527795, -2.454578533893458, -2.8014275494973795, -6.128231437866191, -5.590775189819552, -8.218440107194084, -17.70851618823514, -10.546427258601305, -6.687635120647953, -20.050789521080617, -13.658593305299608, -8.890753472070186, -3.908485394292159, -13.372517199157384, -7.815271693152149, -7.549437064323969, -10.837927411070776, -8.304060989998659, -18.84873103285215, -7.240048965818415, -3.157023421644495, -23.51434372900823, -15.57853387502853, -13.330415312577557, -3.0169909196351923, -7.2208258201266995, -4.455668177321746, -10.808853929574916, -4.3336137918857265, -16.2477793486258, -2.50352682843136, -16.73569831611166, -22.317855211535903, -10.392884547152393, -27.37646706838197, -9.266716827527945, -12.23929720271485, -30.273306838383544, -14.892716779386813, -4.805335654313769, -29.74799072114687, -19.572483448836735, -10.401955140609882, -10.959370235854353, -15.391698502736512, -3.905067910643995, -12.933173597194205, -4.614459880747938, -15.037907104523121, -5.610951030299533, -6.672841249825464, -14.315321482043695, -12.708515204616706, -6.835069611744036, -8.099281242834527, -25.955711601574095, -29.012608282634623, -9.100662479367424, -26.79139579351233, -5.664173693081522, -5.271800931181613, -7.192612272819453, -8.072184014106348, -5.415956455862326, -4.601772977704422, -25.228976757507706, -10.952802762703351, -14.547869439272676, -11.55642919047836, -11.691585376714416, -6.1818981418978245, -7.367184113148193]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1849825827992376, "mean_inference_ms": 0.658248541186411, "mean_action_processing_ms": 0.04478759273383079, "mean_env_wait_ms": 0.2766744255096602, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 111078, "timesteps_this_iter": 0, "agent_timesteps_total": 222156, "timers": {"sample_time_ms": 9954.964, "sample_throughput": 413.261, "load_time_ms": 0.167, "load_throughput": 24657568.814, "learn_time_ms": 5148.598, "learn_throughput": 799.052}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3490195621595679, "policy_loss": -0.012342679479237026, "vf_loss": 0.3612365482370175, "vf_explained_var": 0.44174160963545245, "kl": 0.011917560544497973, "entropy": 0.546864787582308, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 12.548195613342008, "policy_loss": 0.002973066297514985, "vf_loss": 12.545186429579433, "vf_explained_var": -0.22241301741451025, "kl": 0.010259482908198454, "entropy": 1.1615867661312222, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 111078, "num_agent_steps_sampled": 222156, "num_steps_trained": 111078, "num_agent_steps_trained": 222156, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 459, "training_iteration": 27, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-34-05", "timestamp": 1674488045, "time_this_iter_s": 10.053700923919678, "time_total_s": 268.6451334953308, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dad9430>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dada9d0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 268.6451334953308, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 18.30666666666667, "ram_util_percent": 63.86666666666666}}
{"episode_reward_max": -11.32342881761473, "episode_reward_min": -39.997204864558846, "episode_reward_mean": -20.73944527569837, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -14.003634754904542, "pol1": -33.52602814204433}, "policy_reward_max": {"pol0": -5.326003671770462, "pol1": -2.454578533893458}, "policy_reward_mean": {"pol0": -8.456741379969738, "pol1": -12.282703895728627}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.113266860205798, -27.354892285032967, -27.633014049237282, -13.118351464993337, -21.5332047126187, -28.943561357231207, -18.2673987861688, -30.47320981062594, -15.326598297450634, -18.1490644279005, -17.359430593413922, -16.090655255612987, -12.744987611680541, -12.761064010434074, -17.31389230009732, -14.318373138019146, -17.60017230505828, -27.36747325215353, -20.61483158460201, -17.045250030328372, -29.915976500053095, -26.158263302428285, -19.450169808451257, -12.421370199586294, -23.397573868289538, -18.83780082196523, -17.489028774514665, -20.076492849700724, -17.252736990981397, -28.964683418373728, -17.234769421476145, -13.234594456441316, -31.5985648909537, -26.869821676673492, -21.177206439038397, -14.3361264118026, -15.530241561138665, -12.260685712214183, -18.70602018005523, -14.816760883617718, -26.04497985635243, -11.878543132915095, -26.055415259544755, -32.00138987085324, -18.644435675077332, -37.16101185830426, -18.281308901176164, -21.79561090370046, -39.638400145351774, -22.639376925808325, -12.248359789287054, -36.4077974542145, -26.46544959854524, -17.39243305815001, -18.761125995239638, -23.718745396727364, -12.514644419911093, -19.80271333562043, -12.033742052186593, -22.007479558080153, -12.343459232003779, -15.796061554799328, -23.296266759468544, -20.011279043925594, -13.878437492887242, -15.440526904310081, -33.32713417473907, -35.65385507105935, -16.532562301693556, -33.06023253880141, -12.846227162619966, -11.91174993554732, -16.09250037520565, -15.892373393391345, -12.97775710691883, -12.886946539407774, -33.86658157887057, -18.50946012016252, -21.210617219777873, -19.45125036725593, -19.08877782816463, -13.44588422543841, -14.926508825363264, -15.257799878974206, -24.11931778469028, -13.437704510117836, -29.42263671143201, -11.32342881761473, -25.966222787468524, -39.997204864558846, -15.542040782018475, -16.96527979313508, -19.657048734755673, -32.05168740404007, -23.189423281354138, -30.68779959269375, -24.046873594005334, -15.650320626141621, -24.4121790105281, -23.420566156829054], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-10.864806448637765, -10.450568763561797, -9.623219252980206, -10.193760704592457, -14.003634754904542, -9.781872246910167, -12.093750775898927, -10.194665816373142, -11.95198306709374, -8.751750590135135, -9.007351323176497, -12.239238358085194, -10.290409077787082, -9.959636460936686, -11.185660862231119, -8.727597948199582, -9.381732197864173, -9.658957063918391, -10.068404326000715, -10.357614909680407, -9.865186978972494, -12.499669997128654, -10.559416336381055, -8.51288480529414, -10.025056669132159, -11.022529128813074, -9.939591710190692, -9.23856543862993, -8.948676000982765, -10.11595238552159, -9.994720455657733, -10.077571034796819, -8.08422116194545, -11.291287801644984, -7.846791126460852, -11.319135492167405, -8.30941574101197, -7.805017534892439, -7.897166250480295, -10.483147091731983, -9.797200507726643, -9.375016304483719, -9.319716943433104, -9.683534659317344, -8.251551127924937, -9.784544789922316, -9.014592073648236, -9.556313700985607, -9.365093306968271, -7.746660146421508, -7.443024134973296, -6.659806733067634, -6.892966149708492, -6.9904779175401135, -7.801755759385281, -8.327046893990822, -8.60957650926709, -6.869539738426219, -7.419282171438643, -6.969572453557024, -6.732508201704235, -9.123220304973868, -8.980945277424848, -7.302763839308889, -7.043367881143196, -7.34124566147556, -7.371422573164987, -6.641246788424725, -7.431899822326125, -6.268836745289068, -7.182053469538454, -6.639949004365706, -8.899888102386186, -7.820189379284986, -7.561800651056499, -8.285173561703354, -8.637604821362846, -7.556657357459166, -6.662747780505209, -7.8948211767775645, -7.397192451450233, -7.263986083540584, -7.559324712215076, -6.72595780453497, -6.02439281490798, -6.310288982436182, -5.908558830753407, -5.84184997683197, -6.541849981790858, -6.471176722514496, -5.700212158357784, -5.961086529202813, -5.395866768841866, -5.900712165183848, -6.514869289467126, -7.2058624734056265, -5.326003671770462, -5.776772247178182, -6.118197329887989, -5.85174449003637], "policy_pol1_reward": [-6.248460411568029, -16.9043235214712, -18.009794796257083, -2.924590760400873, -7.529569957714155, -19.161689110321063, -6.173648010269876, -20.278543994252782, -3.3746152303568944, -9.39731383776536, -8.352079270237411, -3.851416897527795, -2.454578533893458, -2.8014275494973795, -6.128231437866191, -5.590775189819552, -8.218440107194084, -17.70851618823514, -10.546427258601305, -6.687635120647953, -20.050789521080617, -13.658593305299608, -8.890753472070186, -3.908485394292159, -13.372517199157384, -7.815271693152149, -7.549437064323969, -10.837927411070776, -8.304060989998659, -18.84873103285215, -7.240048965818415, -3.157023421644495, -23.51434372900823, -15.57853387502853, -13.330415312577557, -3.0169909196351923, -7.2208258201266995, -4.455668177321746, -10.808853929574916, -4.3336137918857265, -16.2477793486258, -2.50352682843136, -16.73569831611166, -22.317855211535903, -10.392884547152393, -27.37646706838197, -9.266716827527945, -12.23929720271485, -30.273306838383544, -14.892716779386813, -4.805335654313769, -29.74799072114687, -19.572483448836735, -10.401955140609882, -10.959370235854353, -15.391698502736512, -3.905067910643995, -12.933173597194205, -4.614459880747938, -15.037907104523121, -5.610951030299533, -6.672841249825464, -14.315321482043695, -12.708515204616706, -6.835069611744036, -8.099281242834527, -25.955711601574095, -29.012608282634623, -9.100662479367424, -26.79139579351233, -5.664173693081522, -5.271800931181613, -7.192612272819453, -8.072184014106348, -5.415956455862326, -4.601772977704422, -25.228976757507706, -10.952802762703351, -14.547869439272676, -11.55642919047836, -11.691585376714416, -6.1818981418978245, -7.367184113148193, -8.531842074439222, -18.094924969782294, -7.12741552768165, -23.514077880678606, -5.4815788407827615, -19.42437280567765, -33.52602814204433, -9.841828623660692, -11.004193263932272, -14.261181965913812, -26.150975238856212, -16.67455399188702, -23.48193711928812, -18.720869922234893, -9.873548378963443, -18.293981680640112, -17.568821666792694]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18502286552792482, "mean_inference_ms": 0.6586847153836071, "mean_action_processing_ms": 0.044813863223510796, "mean_env_wait_ms": 0.27675489375984486, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 115192, "timesteps_this_iter": 0, "agent_timesteps_total": 230384, "timers": {"sample_time_ms": 10000.825, "sample_throughput": 411.366, "load_time_ms": 0.17, "load_throughput": 24224858.425, "learn_time_ms": 5174.368, "learn_throughput": 795.073}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.16187522379574754, "policy_loss": -0.0015612837354031701, "vf_loss": 0.16335701788436077, "vf_explained_var": 0.3213220321883758, "kl": 0.007536825054436728, "entropy": 0.43799612453828257, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.0647631181404, "policy_loss": -0.010862031061454521, "vf_loss": 9.075487511915465, "vf_explained_var": -0.14191269216438135, "kl": 0.03915061539606389, "entropy": 1.2479230975732207, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 115192, "num_agent_steps_sampled": 230384, "num_steps_trained": 115192, "num_agent_steps_trained": 230384, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 476, "training_iteration": 28, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-34-16", "timestamp": 1674488056, "time_this_iter_s": 10.634567975997925, "time_total_s": 279.27970147132874, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29d28b700>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dae0160>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 279.27970147132874, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 24.706666666666663, "ram_util_percent": 63.95333333333333}}
{"episode_reward_max": -10.460514217162459, "episode_reward_min": -43.88713144376844, "episode_reward_mean": -21.098969289822712, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -12.499669997128654, "pol1": -38.45222031680856}, "policy_reward_max": {"pol0": -5.02864767523854, "pol1": -2.50352682843136}, "policy_reward_mean": {"pol0": -7.644482062235412, "pol1": -13.454487227587297}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.36747325215353, -20.61483158460201, -17.045250030328372, -29.915976500053095, -26.158263302428285, -19.450169808451257, -12.421370199586294, -23.397573868289538, -18.83780082196523, -17.489028774514665, -20.076492849700724, -17.252736990981397, -28.964683418373728, -17.234769421476145, -13.234594456441316, -31.5985648909537, -26.869821676673492, -21.177206439038397, -14.3361264118026, -15.530241561138665, -12.260685712214183, -18.70602018005523, -14.816760883617718, -26.04497985635243, -11.878543132915095, -26.055415259544755, -32.00138987085324, -18.644435675077332, -37.16101185830426, -18.281308901176164, -21.79561090370046, -39.638400145351774, -22.639376925808325, -12.248359789287054, -36.4077974542145, -26.46544959854524, -17.39243305815001, -18.761125995239638, -23.718745396727364, -12.514644419911093, -19.80271333562043, -12.033742052186593, -22.007479558080153, -12.343459232003779, -15.796061554799328, -23.296266759468544, -20.011279043925594, -13.878437492887242, -15.440526904310081, -33.32713417473907, -35.65385507105935, -16.532562301693556, -33.06023253880141, -12.846227162619966, -11.91174993554732, -16.09250037520565, -15.892373393391345, -12.97775710691883, -12.886946539407774, -33.86658157887057, -18.50946012016252, -21.210617219777873, -19.45125036725593, -19.08877782816463, -13.44588422543841, -14.926508825363264, -15.257799878974206, -24.11931778469028, -13.437704510117836, -29.42263671143201, -11.32342881761473, -25.966222787468524, -39.997204864558846, -15.542040782018475, -16.96527979313508, -19.657048734755673, -32.05168740404007, -23.189423281354138, -30.68779959269375, -24.046873594005334, -15.650320626141621, -24.4121790105281, -23.420566156829054, -10.460514217162459, -22.10968387774507, -12.904463461600317, -11.355890867467995, -19.123480664870506, -43.88713144376844, -27.73906779605338, -26.619488902006072, -11.268993157205657, -20.717600210762935, -17.29527891187059, -36.899489506234985, -18.557826602857023, -36.51328580682919, -12.664076279614926, -12.716874818270739, -21.220392153895155], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-9.658957063918391, -10.068404326000715, -10.357614909680407, -9.865186978972494, -12.499669997128654, -10.559416336381055, -8.51288480529414, -10.025056669132159, -11.022529128813074, -9.939591710190692, -9.23856543862993, -8.948676000982765, -10.11595238552159, -9.994720455657733, -10.077571034796819, -8.08422116194545, -11.291287801644984, -7.846791126460852, -11.319135492167405, -8.30941574101197, -7.805017534892439, -7.897166250480295, -10.483147091731983, -9.797200507726643, -9.375016304483719, -9.319716943433104, -9.683534659317344, -8.251551127924937, -9.784544789922316, -9.014592073648236, -9.556313700985607, -9.365093306968271, -7.746660146421508, -7.443024134973296, -6.659806733067634, -6.892966149708492, -6.9904779175401135, -7.801755759385281, -8.327046893990822, -8.60957650926709, -6.869539738426219, -7.419282171438643, -6.969572453557024, -6.732508201704235, -9.123220304973868, -8.980945277424848, -7.302763839308889, -7.043367881143196, -7.34124566147556, -7.371422573164987, -6.641246788424725, -7.431899822326125, -6.268836745289068, -7.182053469538454, -6.639949004365706, -8.899888102386186, -7.820189379284986, -7.561800651056499, -8.285173561703354, -8.637604821362846, -7.556657357459166, -6.662747780505209, -7.8948211767775645, -7.397192451450233, -7.263986083540584, -7.559324712215076, -6.72595780453497, -6.02439281490798, -6.310288982436182, -5.908558830753407, -5.84184997683197, -6.541849981790858, -6.471176722514496, -5.700212158357784, -5.961086529202813, -5.395866768841866, -5.900712165183848, -6.514869289467126, -7.2058624734056265, -5.326003671770462, -5.776772247178182, -6.118197329887989, -5.85174449003637, -5.210818619422389, -6.360933331372569, -5.02864767523854, -6.189939814806421, -5.141088016499125, -5.434911126959871, -6.026477728937243, -5.099847913420161, -6.081286058156101, -6.095159126778424, -5.716044883337863, -5.357186088831574, -6.082591309019681, -6.687962112117608, -5.742760618143134, -5.511967861326519, -5.708084591568361], "policy_pol1_reward": [-17.70851618823514, -10.546427258601305, -6.687635120647953, -20.050789521080617, -13.658593305299608, -8.890753472070186, -3.908485394292159, -13.372517199157384, -7.815271693152149, -7.549437064323969, -10.837927411070776, -8.304060989998659, -18.84873103285215, -7.240048965818415, -3.157023421644495, -23.51434372900823, -15.57853387502853, -13.330415312577557, -3.0169909196351923, -7.2208258201266995, -4.455668177321746, -10.808853929574916, -4.3336137918857265, -16.2477793486258, -2.50352682843136, -16.73569831611166, -22.317855211535903, -10.392884547152393, -27.37646706838197, -9.266716827527945, -12.23929720271485, -30.273306838383544, -14.892716779386813, -4.805335654313769, -29.74799072114687, -19.572483448836735, -10.401955140609882, -10.959370235854353, -15.391698502736512, -3.905067910643995, -12.933173597194205, -4.614459880747938, -15.037907104523121, -5.610951030299533, -6.672841249825464, -14.315321482043695, -12.708515204616706, -6.835069611744036, -8.099281242834527, -25.955711601574095, -29.012608282634623, -9.100662479367424, -26.79139579351233, -5.664173693081522, -5.271800931181613, -7.192612272819453, -8.072184014106348, -5.415956455862326, -4.601772977704422, -25.228976757507706, -10.952802762703351, -14.547869439272676, -11.55642919047836, -11.691585376714416, -6.1818981418978245, -7.367184113148193, -8.531842074439222, -18.094924969782294, -7.12741552768165, -23.514077880678606, -5.4815788407827615, -19.42437280567765, -33.52602814204433, -9.841828623660692, -11.004193263932272, -14.261181965913812, -26.150975238856212, -16.67455399188702, -23.48193711928812, -18.720869922234893, -9.873548378963443, -18.293981680640112, -17.568821666792694, -5.249695597740043, -15.748750546372515, -7.8758157863617555, -5.165951052661581, -13.982392648371365, -38.45222031680856, -21.71259006711612, -21.519640988585913, -5.18770709904955, -14.622441083984517, -11.579234028532731, -31.54230341740343, -12.475235293837336, -29.82532369471156, -6.921315661471793, -7.204906956944232, -15.51230756232679]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18506718195884592, "mean_inference_ms": 0.659110293028685, "mean_action_processing_ms": 0.044838907868174814, "mean_env_wait_ms": 0.27683663658646285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 119306, "timesteps_this_iter": 0, "agent_timesteps_total": 238612, "timers": {"sample_time_ms": 10027.943, "sample_throughput": 410.254, "load_time_ms": 0.169, "load_throughput": 24293068.641, "learn_time_ms": 5175.37, "learn_throughput": 794.919}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.010546875000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1383764380295664, "policy_loss": 0.005064808002983531, "vf_loss": 0.13326950632035733, "vf_explained_var": 0.3535869531954328, "kl": 0.003993920884083005, "entropy": 0.41887489597623545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.005273437500000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 14.728834670161207, "policy_loss": 0.002837752675016721, "vf_loss": 14.725957154358428, "vf_explained_var": -0.23841374379893143, "kl": 0.007544282094446923, "entropy": 1.1748297431195776, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 119306, "num_agent_steps_sampled": 238612, "num_steps_trained": 119306, "num_agent_steps_trained": 238612, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 493, "training_iteration": 29, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-34-26", "timestamp": 1674488066, "time_this_iter_s": 10.02596402168274, "time_total_s": 289.3056654930115, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dadfd30>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dae7dc0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 289.3056654930115, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 17.935714285714287, "ram_util_percent": 63.82142857142855}}
{"episode_reward_max": -10.460514217162459, "episode_reward_min": -43.88713144376844, "episode_reward_mean": -20.96068953803199, "episode_len_mean": 242.0, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"pol0": -11.319135492167405, "pol1": -38.45222031680856}, "policy_reward_max": {"pol0": -4.9794156477900335, "pol1": -2.50352682843136}, "policy_reward_mean": {"pol0": -6.902654085759211, "pol1": -14.058035452272781}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-21.177206439038397, -14.3361264118026, -15.530241561138665, -12.260685712214183, -18.70602018005523, -14.816760883617718, -26.04497985635243, -11.878543132915095, -26.055415259544755, -32.00138987085324, -18.644435675077332, -37.16101185830426, -18.281308901176164, -21.79561090370046, -39.638400145351774, -22.639376925808325, -12.248359789287054, -36.4077974542145, -26.46544959854524, -17.39243305815001, -18.761125995239638, -23.718745396727364, -12.514644419911093, -19.80271333562043, -12.033742052186593, -22.007479558080153, -12.343459232003779, -15.796061554799328, -23.296266759468544, -20.011279043925594, -13.878437492887242, -15.440526904310081, -33.32713417473907, -35.65385507105935, -16.532562301693556, -33.06023253880141, -12.846227162619966, -11.91174993554732, -16.09250037520565, -15.892373393391345, -12.97775710691883, -12.886946539407774, -33.86658157887057, -18.50946012016252, -21.210617219777873, -19.45125036725593, -19.08877782816463, -13.44588422543841, -14.926508825363264, -15.257799878974206, -24.11931778469028, -13.437704510117836, -29.42263671143201, -11.32342881761473, -25.966222787468524, -39.997204864558846, -15.542040782018475, -16.96527979313508, -19.657048734755673, -32.05168740404007, -23.189423281354138, -30.68779959269375, -24.046873594005334, -15.650320626141621, -24.4121790105281, -23.420566156829054, -10.460514217162459, -22.10968387774507, -12.904463461600317, -11.355890867467995, -19.123480664870506, -43.88713144376844, -27.73906779605338, -26.619488902006072, -11.268993157205657, -20.717600210762935, -17.29527891187059, -36.899489506234985, -18.557826602857023, -36.51328580682919, -12.664076279614926, -12.716874818270739, -21.220392153895155, -13.24255833373228, -31.1746640686753, -27.893268930381698, -13.766733978011729, -16.50219322669967, -27.877682329550705, -17.228803198909613, -20.840033362669836, -10.909339151172615, -25.803415327084757, -18.981169625074106, -28.486011532779393, -27.309110088999386, -24.296349332553632, -14.715172635965194, -12.089592991571571, -22.985328554069923], "episode_lengths": [242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242], "policy_pol0_reward": [-7.846791126460852, -11.319135492167405, -8.30941574101197, -7.805017534892439, -7.897166250480295, -10.483147091731983, -9.797200507726643, -9.375016304483719, -9.319716943433104, -9.683534659317344, -8.251551127924937, -9.784544789922316, -9.014592073648236, -9.556313700985607, -9.365093306968271, -7.746660146421508, -7.443024134973296, -6.659806733067634, -6.892966149708492, -6.9904779175401135, -7.801755759385281, -8.327046893990822, -8.60957650926709, -6.869539738426219, -7.419282171438643, -6.969572453557024, -6.732508201704235, -9.123220304973868, -8.980945277424848, -7.302763839308889, -7.043367881143196, -7.34124566147556, -7.371422573164987, -6.641246788424725, -7.431899822326125, -6.268836745289068, -7.182053469538454, -6.639949004365706, -8.899888102386186, -7.820189379284986, -7.561800651056499, -8.285173561703354, -8.637604821362846, -7.556657357459166, -6.662747780505209, -7.8948211767775645, -7.397192451450233, -7.263986083540584, -7.559324712215076, -6.72595780453497, -6.02439281490798, -6.310288982436182, -5.908558830753407, -5.84184997683197, -6.541849981790858, -6.471176722514496, -5.700212158357784, -5.961086529202813, -5.395866768841866, -5.900712165183848, -6.514869289467126, -7.2058624734056265, -5.326003671770462, -5.776772247178182, -6.118197329887989, -5.85174449003637, -5.210818619422389, -6.360933331372569, -5.02864767523854, -6.189939814806421, -5.141088016499125, -5.434911126959871, -6.026477728937243, -5.099847913420161, -6.081286058156101, -6.095159126778424, -5.716044883337863, -5.357186088831574, -6.082591309019681, -6.687962112117608, -5.742760618143134, -5.511967861326519, -5.708084591568361, -6.029111081536916, -5.438192989714707, -5.91875118355135, -5.948064608421931, -5.65660206419167, -5.900098447220577, -5.132190738787649, -5.844474925335499, -5.471124872667878, -6.433390099410817, -5.110242664134018, -5.393584031975816, -5.785945188667836, -6.210791371460181, -4.9794156477900335, -5.412609273817851, -5.412919368386244], "policy_pol1_reward": [-13.330415312577557, -3.0169909196351923, -7.2208258201266995, -4.455668177321746, -10.808853929574916, -4.3336137918857265, -16.2477793486258, -2.50352682843136, -16.73569831611166, -22.317855211535903, -10.392884547152393, -27.37646706838197, -9.266716827527945, -12.23929720271485, -30.273306838383544, -14.892716779386813, -4.805335654313769, -29.74799072114687, -19.572483448836735, -10.401955140609882, -10.959370235854353, -15.391698502736512, -3.905067910643995, -12.933173597194205, -4.614459880747938, -15.037907104523121, -5.610951030299533, -6.672841249825464, -14.315321482043695, -12.708515204616706, -6.835069611744036, -8.099281242834527, -25.955711601574095, -29.012608282634623, -9.100662479367424, -26.79139579351233, -5.664173693081522, -5.271800931181613, -7.192612272819453, -8.072184014106348, -5.415956455862326, -4.601772977704422, -25.228976757507706, -10.952802762703351, -14.547869439272676, -11.55642919047836, -11.691585376714416, -6.1818981418978245, -7.367184113148193, -8.531842074439222, -18.094924969782294, -7.12741552768165, -23.514077880678606, -5.4815788407827615, -19.42437280567765, -33.52602814204433, -9.841828623660692, -11.004193263932272, -14.261181965913812, -26.150975238856212, -16.67455399188702, -23.48193711928812, -18.720869922234893, -9.873548378963443, -18.293981680640112, -17.568821666792694, -5.249695597740043, -15.748750546372515, -7.8758157863617555, -5.165951052661581, -13.982392648371365, -38.45222031680856, -21.71259006711612, -21.519640988585913, -5.18770709904955, -14.622441083984517, -11.579234028532731, -31.54230341740343, -12.475235293837336, -29.82532369471156, -6.921315661471793, -7.204906956944232, -15.51230756232679, -7.21344725219535, -25.736471078960616, -21.974517746830365, -7.818669369589814, -10.845591162508013, -21.97758388233014, -12.096612460121976, -14.995558437334331, -5.438214278504738, -19.37002522767393, -13.870926960940096, -23.09242750080358, -21.523164900331555, -18.08555796109345, -9.735756988175156, -6.676983717753735, -17.572409185683686]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1851190677610719, "mean_inference_ms": 0.6595125486559642, "mean_action_processing_ms": 0.04486228017749514, "mean_env_wait_ms": 0.27693661976253686, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 0, "timesteps_total": 123420, "timesteps_this_iter": 0, "agent_timesteps_total": 246840, "timers": {"sample_time_ms": 10027.781, "sample_throughput": 410.26, "load_time_ms": 0.167, "load_throughput": 24604829.112, "learn_time_ms": 5177.143, "learn_throughput": 794.647}, "info": {"learner": {"pol0": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.005273437500000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.09785791864899997, "policy_loss": -0.001751859918780004, "vf_loss": 0.09955562251610293, "vf_explained_var": 0.36604195591062305, "kl": 0.010269479442649753, "entropy": 0.35386885795742273, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}, "pol1": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.005273437500000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.568284667655826, "policy_loss": -0.0030152488242796, "vf_loss": 8.57124655097723, "vf_explained_var": -0.24453493089725573, "kl": 0.010118114099096449, "entropy": 1.190937018332382, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 123420, "num_agent_steps_sampled": 246840, "num_steps_trained": 123420, "num_agent_steps_trained": 246840, "num_steps_trained_this_iter": 0}, "done": true, "episodes_total": 510, "training_iteration": 30, "trial_id": "bc3eb_00000", "experiment_id": "114bd762d9bc4665933b12e9f20f3289", "date": "2023-01-23_16-34-36", "timestamp": 1674488076, "time_this_iter_s": 9.95211386680603, "time_total_s": 299.2577793598175, "pid": 828, "hostname": "MacBook-Pro-de-Mhamed-2.local", "node_ip": "127.0.0.1", "config": {"num_workers": 0, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "cc_model", "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "this-aviary-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.FillInActions'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"pol0": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 0}], "pol1": [null, "Dict(opponent_action:Box([-1.], [1.], (1,), float32), opponent_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32), own_obs:Box([-1. -1.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (12,), float32))", "Box([-1.], [1.], (1,), float32)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x29dada9d0>", "policies_to_train": null, "observation_fn": "<function central_critic_observer at 0x29dae31f0>", "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 299.2577793598175, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 18.035714285714285, "ram_util_percent": 63.814285714285695}}
